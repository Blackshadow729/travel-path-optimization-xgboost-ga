{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0a8ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8376\\102336369.py:4: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sample_df = pd.read_csv(url)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400001</td>\n",
       "      <td>id0596752</td>\n",
       "      <td>2</td>\n",
       "      <td>14-03-2016 6:36</td>\n",
       "      <td>14-03-2016 7:50</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.776741</td>\n",
       "      <td>40.645241</td>\n",
       "      <td>-73.991867</td>\n",
       "      <td>40.742512</td>\n",
       "      <td>N</td>\n",
       "      <td>4392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400002</td>\n",
       "      <td>id0329966</td>\n",
       "      <td>2</td>\n",
       "      <td>30-04-2016 9:07</td>\n",
       "      <td>30-04-2016 9:10</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.001312</td>\n",
       "      <td>40.746628</td>\n",
       "      <td>-73.995064</td>\n",
       "      <td>40.739925</td>\n",
       "      <td>N</td>\n",
       "      <td>203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400003</td>\n",
       "      <td>id3281166</td>\n",
       "      <td>1</td>\n",
       "      <td>11-06-2016 1:46</td>\n",
       "      <td>11-06-2016 2:35</td>\n",
       "      <td>3</td>\n",
       "      <td>-73.994797</td>\n",
       "      <td>40.725075</td>\n",
       "      <td>-73.802750</td>\n",
       "      <td>40.588665</td>\n",
       "      <td>N</td>\n",
       "      <td>2965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400004</td>\n",
       "      <td>id3798985</td>\n",
       "      <td>2</td>\n",
       "      <td>11-02-2016 20:42</td>\n",
       "      <td>11-02-2016 21:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.008949</td>\n",
       "      <td>40.706249</td>\n",
       "      <td>-73.948730</td>\n",
       "      <td>40.784988</td>\n",
       "      <td>N</td>\n",
       "      <td>1078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400005</td>\n",
       "      <td>id0107658</td>\n",
       "      <td>1</td>\n",
       "      <td>01-01-2016 7:52</td>\n",
       "      <td>01-01-2016 8:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.981209</td>\n",
       "      <td>40.781635</td>\n",
       "      <td>-73.977676</td>\n",
       "      <td>40.753685</td>\n",
       "      <td>N</td>\n",
       "      <td>489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329316</th>\n",
       "      <td>729317</td>\n",
       "      <td>id3905982</td>\n",
       "      <td>2</td>\n",
       "      <td>21-05-2016 13:29</td>\n",
       "      <td>21-05-2016 13:34</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.965919</td>\n",
       "      <td>40.789780</td>\n",
       "      <td>-73.952637</td>\n",
       "      <td>40.789181</td>\n",
       "      <td>N</td>\n",
       "      <td>296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329317</th>\n",
       "      <td>729318</td>\n",
       "      <td>id0102861</td>\n",
       "      <td>1</td>\n",
       "      <td>22-02-2016 0:43</td>\n",
       "      <td>22-02-2016 0:48</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.996666</td>\n",
       "      <td>40.737434</td>\n",
       "      <td>-74.001320</td>\n",
       "      <td>40.731911</td>\n",
       "      <td>N</td>\n",
       "      <td>315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329318</th>\n",
       "      <td>729319</td>\n",
       "      <td>id0439699</td>\n",
       "      <td>1</td>\n",
       "      <td>15-04-2016 18:56</td>\n",
       "      <td>15-04-2016 19:08</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.997849</td>\n",
       "      <td>40.761696</td>\n",
       "      <td>-74.001488</td>\n",
       "      <td>40.741207</td>\n",
       "      <td>N</td>\n",
       "      <td>673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329319</th>\n",
       "      <td>729320</td>\n",
       "      <td>id2078912</td>\n",
       "      <td>1</td>\n",
       "      <td>19-06-2016 9:50</td>\n",
       "      <td>19-06-2016 9:58</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.006706</td>\n",
       "      <td>40.708244</td>\n",
       "      <td>-74.013550</td>\n",
       "      <td>40.713814</td>\n",
       "      <td>N</td>\n",
       "      <td>447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329320</th>\n",
       "      <td>729321</td>\n",
       "      <td>id1053441</td>\n",
       "      <td>2</td>\n",
       "      <td>01-01-2016 17:24</td>\n",
       "      <td>01-01-2016 17:44</td>\n",
       "      <td>4</td>\n",
       "      <td>-74.003342</td>\n",
       "      <td>40.743839</td>\n",
       "      <td>-73.945847</td>\n",
       "      <td>40.712841</td>\n",
       "      <td>N</td>\n",
       "      <td>1224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329321 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         id  vendor_id   pickup_datetime  dropoff_datetime  \\\n",
       "0           400001  id0596752          2   14-03-2016 6:36   14-03-2016 7:50   \n",
       "1           400002  id0329966          2   30-04-2016 9:07   30-04-2016 9:10   \n",
       "2           400003  id3281166          1   11-06-2016 1:46   11-06-2016 2:35   \n",
       "3           400004  id3798985          2  11-02-2016 20:42  11-02-2016 21:00   \n",
       "4           400005  id0107658          1   01-01-2016 7:52   01-01-2016 8:00   \n",
       "...            ...        ...        ...               ...               ...   \n",
       "329316      729317  id3905982          2  21-05-2016 13:29  21-05-2016 13:34   \n",
       "329317      729318  id0102861          1   22-02-2016 0:43   22-02-2016 0:48   \n",
       "329318      729319  id0439699          1  15-04-2016 18:56  15-04-2016 19:08   \n",
       "329319      729320  id2078912          1   19-06-2016 9:50   19-06-2016 9:58   \n",
       "329320      729321  id1053441          2  01-01-2016 17:24  01-01-2016 17:44   \n",
       "\n",
       "        passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                     1        -73.776741        40.645241         -73.991867   \n",
       "1                     1        -74.001312        40.746628         -73.995064   \n",
       "2                     3        -73.994797        40.725075         -73.802750   \n",
       "3                     1        -74.008949        40.706249         -73.948730   \n",
       "4                     1        -73.981209        40.781635         -73.977676   \n",
       "...                 ...               ...              ...                ...   \n",
       "329316                2        -73.965919        40.789780         -73.952637   \n",
       "329317                1        -73.996666        40.737434         -74.001320   \n",
       "329318                1        -73.997849        40.761696         -74.001488   \n",
       "329319                1        -74.006706        40.708244         -74.013550   \n",
       "329320                4        -74.003342        40.743839         -73.945847   \n",
       "\n",
       "        dropoff_latitude store_and_fwd_flag  trip_duration  Unnamed: 11  \\\n",
       "0              40.742512                  N           4392          NaN   \n",
       "1              40.739925                  N            203          NaN   \n",
       "2              40.588665                  N           2965          NaN   \n",
       "3              40.784988                  N           1078          NaN   \n",
       "4              40.753685                  N            489          NaN   \n",
       "...                  ...                ...            ...          ...   \n",
       "329316         40.789181                  N            296          NaN   \n",
       "329317         40.731911                  N            315          NaN   \n",
       "329318         40.741207                  N            673          NaN   \n",
       "329319         40.713814                  N            447          NaN   \n",
       "329320         40.712841                  N           1224          NaN   \n",
       "\n",
       "       Unnamed: 12  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "...            ...  \n",
       "329316         NaN  \n",
       "329317         NaN  \n",
       "329318         NaN  \n",
       "329319         NaN  \n",
       "329320         NaN  \n",
       "\n",
       "[329321 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "url = 'dataset2.csv'\n",
    "sample_df = pd.read_csv(url)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c0cad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>pickup_month</th>\n",
       "      <th>pickup_day</th>\n",
       "      <th>pickup_weekday</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>latitude_difference</th>\n",
       "      <th>longitude_difference</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400001</td>\n",
       "      <td>id0596752</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 06:36:00</td>\n",
       "      <td>2016-03-14 07:50:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.776741</td>\n",
       "      <td>40.645241</td>\n",
       "      <td>-73.991867</td>\n",
       "      <td>40.742512</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>0.097271</td>\n",
       "      <td>-0.215126</td>\n",
       "      <td>21.584541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400002</td>\n",
       "      <td>id0329966</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-30 09:07:00</td>\n",
       "      <td>2016-04-30 09:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.001312</td>\n",
       "      <td>40.746628</td>\n",
       "      <td>-73.995064</td>\n",
       "      <td>40.739925</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.006702</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.894821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400003</td>\n",
       "      <td>id3281166</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-11 01:46:00</td>\n",
       "      <td>2016-06-11 02:35:00</td>\n",
       "      <td>3</td>\n",
       "      <td>-73.994797</td>\n",
       "      <td>40.725075</td>\n",
       "      <td>-73.802750</td>\n",
       "      <td>40.588665</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.136410</td>\n",
       "      <td>0.192047</td>\n",
       "      <td>22.694171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400004</td>\n",
       "      <td>id3798985</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-11 20:42:00</td>\n",
       "      <td>2016-02-11 21:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.008949</td>\n",
       "      <td>40.706249</td>\n",
       "      <td>-73.948730</td>\n",
       "      <td>40.784988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>0.078739</td>\n",
       "      <td>0.060219</td>\n",
       "      <td>9.601065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400005</td>\n",
       "      <td>id0107658</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 07:52:00</td>\n",
       "      <td>2016-01-01 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.981209</td>\n",
       "      <td>40.781635</td>\n",
       "      <td>-73.977676</td>\n",
       "      <td>40.753685</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.027950</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>2.175243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>400006</td>\n",
       "      <td>id0668653</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-13 07:49:00</td>\n",
       "      <td>2016-01-13 07:59:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.960922</td>\n",
       "      <td>40.772369</td>\n",
       "      <td>-73.960503</td>\n",
       "      <td>40.772617</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.046125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400007</td>\n",
       "      <td>id0125792</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-09 00:15:00</td>\n",
       "      <td>2016-04-09 00:24:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.006317</td>\n",
       "      <td>40.733429</td>\n",
       "      <td>-73.989990</td>\n",
       "      <td>40.746780</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.013351</td>\n",
       "      <td>0.016327</td>\n",
       "      <td>2.050575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400008</td>\n",
       "      <td>id1571632</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-29 13:25:00</td>\n",
       "      <td>2016-03-29 13:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.960457</td>\n",
       "      <td>40.769959</td>\n",
       "      <td>-73.960236</td>\n",
       "      <td>40.776211</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.447278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>400009</td>\n",
       "      <td>id0059452</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-07 11:42:00</td>\n",
       "      <td>2016-06-07 11:46:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.006783</td>\n",
       "      <td>40.730610</td>\n",
       "      <td>-74.006409</td>\n",
       "      <td>40.739063</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.609901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>400010</td>\n",
       "      <td>id3039400</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-16 11:42:00</td>\n",
       "      <td>2016-04-16 11:46:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.969604</td>\n",
       "      <td>40.800266</td>\n",
       "      <td>-73.961494</td>\n",
       "      <td>40.806274</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.975472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id  vendor_id     pickup_datetime    dropoff_datetime  \\\n",
       "0      400001  id0596752          2 2016-03-14 06:36:00 2016-03-14 07:50:00   \n",
       "1      400002  id0329966          2 2016-04-30 09:07:00 2016-04-30 09:10:00   \n",
       "2      400003  id3281166          1 2016-06-11 01:46:00 2016-06-11 02:35:00   \n",
       "3      400004  id3798985          2 2016-02-11 20:42:00 2016-02-11 21:00:00   \n",
       "4      400005  id0107658          1 2016-01-01 07:52:00 2016-01-01 08:00:00   \n",
       "5      400006  id0668653          1 2016-01-13 07:49:00 2016-01-13 07:59:00   \n",
       "6      400007  id0125792          2 2016-04-09 00:15:00 2016-04-09 00:24:00   \n",
       "7      400008  id1571632          1 2016-03-29 13:25:00 2016-03-29 13:30:00   \n",
       "8      400009  id0059452          2 2016-06-07 11:42:00 2016-06-07 11:46:00   \n",
       "9      400010  id3039400          1 2016-04-16 11:42:00 2016-04-16 11:46:00   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.776741        40.645241         -73.991867   \n",
       "1                1        -74.001312        40.746628         -73.995064   \n",
       "2                3        -73.994797        40.725075         -73.802750   \n",
       "3                1        -74.008949        40.706249         -73.948730   \n",
       "4                1        -73.981209        40.781635         -73.977676   \n",
       "5                2        -73.960922        40.772369         -73.960503   \n",
       "6                1        -74.006317        40.733429         -73.989990   \n",
       "7                1        -73.960457        40.769959         -73.960236   \n",
       "8                1        -74.006783        40.730610         -74.006409   \n",
       "9                1        -73.969604        40.800266         -73.961494   \n",
       "\n",
       "   dropoff_latitude  ...  Unnamed: 11  Unnamed: 12  pickup_month pickup_day  \\\n",
       "0         40.742512  ...          NaN          NaN             3         14   \n",
       "1         40.739925  ...          NaN          NaN             4         30   \n",
       "2         40.588665  ...          NaN          NaN             6         11   \n",
       "3         40.784988  ...          NaN          NaN             2         11   \n",
       "4         40.753685  ...          NaN          NaN             1          1   \n",
       "5         40.772617  ...          NaN          NaN             1         13   \n",
       "6         40.746780  ...          NaN          NaN             4          9   \n",
       "7         40.776211  ...          NaN          NaN             3         29   \n",
       "8         40.739063  ...          NaN          NaN             6          7   \n",
       "9         40.806274  ...          NaN          NaN             4         16   \n",
       "\n",
       "   pickup_weekday  pickup_hour  pickup_minute  latitude_difference  \\\n",
       "0               0            6             36             0.097271   \n",
       "1               5            9              7            -0.006702   \n",
       "2               5            1             46            -0.136410   \n",
       "3               3           20             42             0.078739   \n",
       "4               4            7             52            -0.027950   \n",
       "5               2            7             49             0.000248   \n",
       "6               5            0             15             0.013351   \n",
       "7               1           13             25             0.006252   \n",
       "8               1           11             42             0.008453   \n",
       "9               5           11             42             0.006008   \n",
       "\n",
       "   longitude_difference  trip_distance  \n",
       "0             -0.215126      21.584541  \n",
       "1              0.006248       0.894821  \n",
       "2              0.192047      22.694171  \n",
       "3              0.060219       9.601065  \n",
       "4              0.003532       2.175243  \n",
       "5              0.000420       0.046125  \n",
       "6              0.016327       2.050575  \n",
       "7              0.000221       0.447278  \n",
       "8              0.000374       0.609901  \n",
       "9              0.008110       0.975472  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre-processing\n",
    "\n",
    "sample_df[\"store_and_fwd_flag\"].value_counts()\n",
    "#Convert character variables to numeric\n",
    "f = lambda x: 0 if x == 'N' else 1\n",
    "\n",
    "sample_df[\"store_and_fwd_flag\"] = sample_df[\"store_and_fwd_flag\"].apply(lambda x: f(x))\n",
    "#Check result\n",
    "sample_df[\"store_and_fwd_flag\"].value_counts()\n",
    "\n",
    "\n",
    "#First, convert datetime strings into datetime\n",
    "sample_df[\"dropoff_datetime\"] = pd.to_datetime(sample_df[\"dropoff_datetime\"], format='%d-%m-%Y %H:%M')\n",
    "sample_df[\"pickup_datetime\"] = pd.to_datetime(sample_df[\"pickup_datetime\"], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "#Now construct other variables, like month, date, etc.\n",
    "sample_df[\"pickup_month\"] = sample_df[\"pickup_datetime\"].dt.month\n",
    "sample_df[\"pickup_day\"] = sample_df[\"pickup_datetime\"].dt.day\n",
    "sample_df[\"pickup_weekday\"] = sample_df[\"pickup_datetime\"].dt.weekday #sample_df[\"pickup_weekday\"] = sample_df[\"pickup_datetime\"].dt.weekday_name\n",
    "sample_df[\"pickup_hour\"] = sample_df[\"pickup_datetime\"].dt.hour\n",
    "sample_df[\"pickup_minute\"] = sample_df[\"pickup_datetime\"].dt.minute\n",
    "\n",
    "#Get latitude and longitude differences\n",
    "sample_df[\"latitude_difference\"] = sample_df[\"dropoff_latitude\"] - sample_df[\"pickup_latitude\"]\n",
    "sample_df[\"longitude_difference\"] = sample_df[\"dropoff_longitude\"] - sample_df[\"pickup_longitude\"]\n",
    "\n",
    "#Convert duration to minutes for easier interpretation\n",
    "sample_df[\"trip_duration\"] = sample_df[\"trip_duration\"].apply(lambda x: round(x/60))\n",
    "\n",
    "#Convert trip distance from longitude and latitude differences to Manhattan distance.\n",
    "sample_df[\"trip_distance\"] = 0.621371 * 6371 * (abs(2 * np.arctan2(np.sqrt(np.square(np.sin((abs(sample_df[\"latitude_difference\"]) * np.pi / 180) / 2))),\n",
    "                                  np.sqrt(1-(np.square(np.sin((abs(sample_df[\"latitude_difference\"]) * np.pi / 180) / 2)))))) + \\\n",
    "                                     abs(2 * np.arctan2(np.sqrt(np.square(np.sin((abs(sample_df[\"longitude_difference\"]) * np.pi / 180) / 2))),\n",
    "                                  np.sqrt(1-(np.square(np.sin((abs(sample_df[\"longitude_difference\"]) * np.pi / 180) / 2)))))))\n",
    "\n",
    "sample_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ca4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = sample_df.drop([\"trip_duration\", \"id\", \"vendor_id\", \"pickup_datetime\", \"dropoff_datetime\", \"Unnamed: 11\",\"Unnamed: 12\"], axis=1)\n",
    "y = sample_df[\"trip_duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc1809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2018)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571ecdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d977d072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.804449424557986\n",
      "Mean Squared Error (MSE): 2675.705087724081\n",
      "Root Mean Squared Error (RMSE): 51.72721805514077\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5919015240139642\n",
      "R-squared (R2 score): 0.026415466167302837\n",
      "Adjusted R-squared: 0.026267626319482984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    mask = (y_true > 0) & (y_pred > 0)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0:  # If all values are non-positive, handle this case\n",
    "        return 0  # Return a default value or handle it as needed\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c3251d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Creating and fitting the Gradient Boosting Regression model\n",
    "gb_model = GradientBoostingRegressor()\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = gb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b404d09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 6.72362308181391\n",
      "Mean Squared Error (MSE): 2674.7812310205672\n",
      "Root Mean Squared Error (RMSE): 51.71828720114934\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.47910281762871276\n",
      "R-squared (R2 score): 0.026751621523939506\n",
      "Adjusted R-squared: 0.02660383272166833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    mask = (y_true > 0) & (y_pred > 0)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0:  # If all values are non-positive, handle this case\n",
    "        return 0  # Return a default value or handle it as needed\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d536431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elastic Net Regression \n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Creating and fitting the Elastic Net Regression model\n",
    "elastic_net_model = ElasticNet()\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = elastic_net_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88032826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.861670468747381\n",
      "Mean Squared Error (MSE): 2676.6090282965893\n",
      "Root Mean Squared Error (RMSE): 51.73595488919277\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.6223758138904837\n",
      "R-squared (R2 score): 0.02608655751255773\n",
      "Adjusted R-squared: 0.02593866771960851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bed7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Creating and fitting the Stochastic Gradient Descent Regression model\n",
    "sgd_model = SGDRegressor()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = sgd_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4fae2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 2.001936318143819e+19\n",
      "Mean Squared Error (MSE): 4.121408988048574e+38\n",
      "Root Mean Squared Error (RMSE): 2.030125362643542e+19\n",
      "Root Mean Squared Logarithmic Error (RMSLE): nan\n",
      "R-squared (R2 score): -1.4996196952991454e+35\n",
      "Adjusted R-squared: -1.4998474141461857e+35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    mask = (y_true > 0) & (y_pred > 0)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0:  # If all values are non-positive, handle this case\n",
    "        return 0  # Return a default value or handle it as needed\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49826b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Creating and fitting the Bayesian Ridge Regression model\n",
    "bayesian_model = BayesianRidge()\n",
    "bayesian_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = bayesian_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a7188b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.799963369291777\n",
      "Mean Squared Error (MSE): 2675.4805343880066\n",
      "Root Mean Squared Error (RMSE): 51.725047456604685\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.610699553834968\n",
      "R-squared (R2 score): 0.026497172352347498\n",
      "Adjusted R-squared: 0.026349344911698824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    mask = (y_true > 0) & (y_pred > 0)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0:  # If all values are non-positive, handle this case\n",
    "        return 0  # Return a default value or handle it as needed\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "476b097f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.092416\n",
      "0:\tlearn: 54.3011481\ttotal: 156ms\tremaining: 2m 35s\n",
      "1:\tlearn: 54.2060612\ttotal: 174ms\tremaining: 1m 26s\n",
      "2:\tlearn: 54.1224405\ttotal: 189ms\tremaining: 1m 2s\n",
      "3:\tlearn: 54.0488763\ttotal: 207ms\tremaining: 51.5s\n",
      "4:\tlearn: 53.9864717\ttotal: 222ms\tremaining: 44.1s\n",
      "5:\tlearn: 53.9360367\ttotal: 234ms\tremaining: 38.8s\n",
      "6:\tlearn: 53.8922208\ttotal: 246ms\tremaining: 34.9s\n",
      "7:\tlearn: 53.8541686\ttotal: 258ms\tremaining: 32s\n",
      "8:\tlearn: 53.8263486\ttotal: 270ms\tremaining: 29.7s\n",
      "9:\tlearn: 53.7996223\ttotal: 282ms\tremaining: 27.9s\n",
      "10:\tlearn: 53.7791203\ttotal: 293ms\tremaining: 26.4s\n",
      "11:\tlearn: 53.7601199\ttotal: 305ms\tremaining: 25.1s\n",
      "12:\tlearn: 53.7422936\ttotal: 317ms\tremaining: 24.1s\n",
      "13:\tlearn: 53.7227939\ttotal: 329ms\tremaining: 23.2s\n",
      "14:\tlearn: 53.7098011\ttotal: 342ms\tremaining: 22.4s\n",
      "15:\tlearn: 53.6980197\ttotal: 355ms\tremaining: 21.8s\n",
      "16:\tlearn: 53.6811966\ttotal: 366ms\tremaining: 21.2s\n",
      "17:\tlearn: 53.6686716\ttotal: 378ms\tremaining: 20.6s\n",
      "18:\tlearn: 53.6574506\ttotal: 389ms\tremaining: 20.1s\n",
      "19:\tlearn: 53.6470917\ttotal: 400ms\tremaining: 19.6s\n",
      "20:\tlearn: 53.6338071\ttotal: 412ms\tremaining: 19.2s\n",
      "21:\tlearn: 53.6221916\ttotal: 425ms\tremaining: 18.9s\n",
      "22:\tlearn: 53.6047760\ttotal: 438ms\tremaining: 18.6s\n",
      "23:\tlearn: 53.5928572\ttotal: 449ms\tremaining: 18.2s\n",
      "24:\tlearn: 53.5812044\ttotal: 459ms\tremaining: 17.9s\n",
      "25:\tlearn: 53.5719955\ttotal: 470ms\tremaining: 17.6s\n",
      "26:\tlearn: 53.5620009\ttotal: 481ms\tremaining: 17.3s\n",
      "27:\tlearn: 53.5494042\ttotal: 492ms\tremaining: 17.1s\n",
      "28:\tlearn: 53.5414246\ttotal: 506ms\tremaining: 16.9s\n",
      "29:\tlearn: 53.5323454\ttotal: 519ms\tremaining: 16.8s\n",
      "30:\tlearn: 53.5236672\ttotal: 529ms\tremaining: 16.5s\n",
      "31:\tlearn: 53.5114831\ttotal: 540ms\tremaining: 16.3s\n",
      "32:\tlearn: 53.4927439\ttotal: 553ms\tremaining: 16.2s\n",
      "33:\tlearn: 53.4839439\ttotal: 564ms\tremaining: 16s\n",
      "34:\tlearn: 53.4689699\ttotal: 575ms\tremaining: 15.8s\n",
      "35:\tlearn: 53.4565166\ttotal: 584ms\tremaining: 15.6s\n",
      "36:\tlearn: 53.4482153\ttotal: 595ms\tremaining: 15.5s\n",
      "37:\tlearn: 53.4423731\ttotal: 606ms\tremaining: 15.3s\n",
      "38:\tlearn: 53.4278757\ttotal: 619ms\tremaining: 15.2s\n",
      "39:\tlearn: 53.4170429\ttotal: 631ms\tremaining: 15.1s\n",
      "40:\tlearn: 53.4077916\ttotal: 641ms\tremaining: 15s\n",
      "41:\tlearn: 53.4021462\ttotal: 650ms\tremaining: 14.8s\n",
      "42:\tlearn: 53.3960057\ttotal: 661ms\tremaining: 14.7s\n",
      "43:\tlearn: 53.3761412\ttotal: 671ms\tremaining: 14.6s\n",
      "44:\tlearn: 53.3682606\ttotal: 680ms\tremaining: 14.4s\n",
      "45:\tlearn: 53.3592843\ttotal: 690ms\tremaining: 14.3s\n",
      "46:\tlearn: 53.3532525\ttotal: 700ms\tremaining: 14.2s\n",
      "47:\tlearn: 53.3475498\ttotal: 710ms\tremaining: 14.1s\n",
      "48:\tlearn: 53.3434957\ttotal: 720ms\tremaining: 14s\n",
      "49:\tlearn: 53.3295988\ttotal: 729ms\tremaining: 13.8s\n",
      "50:\tlearn: 53.3234530\ttotal: 740ms\tremaining: 13.8s\n",
      "51:\tlearn: 53.3192748\ttotal: 750ms\tremaining: 13.7s\n",
      "52:\tlearn: 53.3141534\ttotal: 760ms\tremaining: 13.6s\n",
      "53:\tlearn: 53.3072119\ttotal: 772ms\tremaining: 13.5s\n",
      "54:\tlearn: 53.2965588\ttotal: 782ms\tremaining: 13.4s\n",
      "55:\tlearn: 53.2873191\ttotal: 793ms\tremaining: 13.4s\n",
      "56:\tlearn: 53.2815963\ttotal: 806ms\tremaining: 13.3s\n",
      "57:\tlearn: 53.2776415\ttotal: 820ms\tremaining: 13.3s\n",
      "58:\tlearn: 53.2697157\ttotal: 835ms\tremaining: 13.3s\n",
      "59:\tlearn: 53.2636653\ttotal: 850ms\tremaining: 13.3s\n",
      "60:\tlearn: 53.2577797\ttotal: 864ms\tremaining: 13.3s\n",
      "61:\tlearn: 53.2500724\ttotal: 877ms\tremaining: 13.3s\n",
      "62:\tlearn: 53.2443021\ttotal: 891ms\tremaining: 13.2s\n",
      "63:\tlearn: 53.2354133\ttotal: 906ms\tremaining: 13.2s\n",
      "64:\tlearn: 53.2266908\ttotal: 919ms\tremaining: 13.2s\n",
      "65:\tlearn: 53.2196073\ttotal: 935ms\tremaining: 13.2s\n",
      "66:\tlearn: 53.2136890\ttotal: 952ms\tremaining: 13.3s\n",
      "67:\tlearn: 53.2032257\ttotal: 966ms\tremaining: 13.2s\n",
      "68:\tlearn: 53.1971697\ttotal: 976ms\tremaining: 13.2s\n",
      "69:\tlearn: 53.1907088\ttotal: 988ms\tremaining: 13.1s\n",
      "70:\tlearn: 53.1786086\ttotal: 1s\tremaining: 13.1s\n",
      "71:\tlearn: 53.1716497\ttotal: 1.01s\tremaining: 13s\n",
      "72:\tlearn: 53.1661042\ttotal: 1.02s\tremaining: 13s\n",
      "73:\tlearn: 53.1600622\ttotal: 1.04s\tremaining: 13s\n",
      "74:\tlearn: 53.1503399\ttotal: 1.05s\tremaining: 13s\n",
      "75:\tlearn: 53.1432903\ttotal: 1.06s\tremaining: 12.9s\n",
      "76:\tlearn: 53.1351351\ttotal: 1.07s\tremaining: 12.8s\n",
      "77:\tlearn: 53.1269005\ttotal: 1.08s\tremaining: 12.8s\n",
      "78:\tlearn: 53.1153180\ttotal: 1.09s\tremaining: 12.7s\n",
      "79:\tlearn: 53.1095447\ttotal: 1.1s\tremaining: 12.7s\n",
      "80:\tlearn: 53.1041573\ttotal: 1.11s\tremaining: 12.6s\n",
      "81:\tlearn: 53.0972479\ttotal: 1.12s\tremaining: 12.6s\n",
      "82:\tlearn: 53.0910271\ttotal: 1.13s\tremaining: 12.5s\n",
      "83:\tlearn: 53.0859170\ttotal: 1.15s\tremaining: 12.5s\n",
      "84:\tlearn: 53.0794127\ttotal: 1.16s\tremaining: 12.5s\n",
      "85:\tlearn: 53.0664678\ttotal: 1.17s\tremaining: 12.5s\n",
      "86:\tlearn: 53.0594454\ttotal: 1.18s\tremaining: 12.4s\n",
      "87:\tlearn: 53.0560843\ttotal: 1.2s\tremaining: 12.4s\n",
      "88:\tlearn: 53.0482885\ttotal: 1.21s\tremaining: 12.4s\n",
      "89:\tlearn: 53.0433588\ttotal: 1.22s\tremaining: 12.3s\n",
      "90:\tlearn: 53.0348805\ttotal: 1.23s\tremaining: 12.3s\n",
      "91:\tlearn: 53.0330752\ttotal: 1.24s\tremaining: 12.3s\n",
      "92:\tlearn: 53.0142209\ttotal: 1.25s\tremaining: 12.2s\n",
      "93:\tlearn: 53.0092590\ttotal: 1.26s\tremaining: 12.2s\n",
      "94:\tlearn: 53.0010958\ttotal: 1.27s\tremaining: 12.1s\n",
      "95:\tlearn: 52.9919218\ttotal: 1.28s\tremaining: 12.1s\n",
      "96:\tlearn: 52.9893037\ttotal: 1.29s\tremaining: 12s\n",
      "97:\tlearn: 52.9856234\ttotal: 1.3s\tremaining: 12s\n",
      "98:\tlearn: 52.9752621\ttotal: 1.31s\tremaining: 11.9s\n",
      "99:\tlearn: 52.9671264\ttotal: 1.32s\tremaining: 11.9s\n",
      "100:\tlearn: 52.9571070\ttotal: 1.33s\tremaining: 11.8s\n",
      "101:\tlearn: 52.9498032\ttotal: 1.34s\tremaining: 11.8s\n",
      "102:\tlearn: 52.9437488\ttotal: 1.34s\tremaining: 11.7s\n",
      "103:\tlearn: 52.9335792\ttotal: 1.35s\tremaining: 11.7s\n",
      "104:\tlearn: 52.9272762\ttotal: 1.36s\tremaining: 11.6s\n",
      "105:\tlearn: 52.9189788\ttotal: 1.38s\tremaining: 11.6s\n",
      "106:\tlearn: 52.9087910\ttotal: 1.39s\tremaining: 11.6s\n",
      "107:\tlearn: 52.9008652\ttotal: 1.4s\tremaining: 11.5s\n",
      "108:\tlearn: 52.8940978\ttotal: 1.41s\tremaining: 11.5s\n",
      "109:\tlearn: 52.8846465\ttotal: 1.42s\tremaining: 11.5s\n",
      "110:\tlearn: 52.8753477\ttotal: 1.43s\tremaining: 11.4s\n",
      "111:\tlearn: 52.8605132\ttotal: 1.44s\tremaining: 11.4s\n",
      "112:\tlearn: 52.8555245\ttotal: 1.45s\tremaining: 11.4s\n",
      "113:\tlearn: 52.8504410\ttotal: 1.46s\tremaining: 11.3s\n",
      "114:\tlearn: 52.8477906\ttotal: 1.47s\tremaining: 11.3s\n",
      "115:\tlearn: 52.8407187\ttotal: 1.48s\tremaining: 11.3s\n",
      "116:\tlearn: 52.8350487\ttotal: 1.49s\tremaining: 11.3s\n",
      "117:\tlearn: 52.8300568\ttotal: 1.5s\tremaining: 11.2s\n",
      "118:\tlearn: 52.8221436\ttotal: 1.51s\tremaining: 11.2s\n",
      "119:\tlearn: 52.8194890\ttotal: 1.52s\tremaining: 11.1s\n",
      "120:\tlearn: 52.8148701\ttotal: 1.53s\tremaining: 11.1s\n",
      "121:\tlearn: 52.8105778\ttotal: 1.54s\tremaining: 11.1s\n",
      "122:\tlearn: 52.8050962\ttotal: 1.55s\tremaining: 11s\n",
      "123:\tlearn: 52.8024867\ttotal: 1.56s\tremaining: 11s\n",
      "124:\tlearn: 52.7981873\ttotal: 1.57s\tremaining: 11s\n",
      "125:\tlearn: 52.7931245\ttotal: 1.58s\tremaining: 11s\n",
      "126:\tlearn: 52.7877915\ttotal: 1.59s\tremaining: 10.9s\n",
      "127:\tlearn: 52.7808648\ttotal: 1.6s\tremaining: 10.9s\n",
      "128:\tlearn: 52.7619046\ttotal: 1.61s\tremaining: 10.9s\n",
      "129:\tlearn: 52.7436243\ttotal: 1.62s\tremaining: 10.8s\n",
      "130:\tlearn: 52.7378470\ttotal: 1.63s\tremaining: 10.8s\n",
      "131:\tlearn: 52.7270478\ttotal: 1.64s\tremaining: 10.8s\n",
      "132:\tlearn: 52.7170124\ttotal: 1.64s\tremaining: 10.7s\n",
      "133:\tlearn: 52.7111083\ttotal: 1.65s\tremaining: 10.7s\n",
      "134:\tlearn: 52.7060046\ttotal: 1.66s\tremaining: 10.7s\n",
      "135:\tlearn: 52.6981442\ttotal: 1.67s\tremaining: 10.6s\n",
      "136:\tlearn: 52.6932490\ttotal: 1.68s\tremaining: 10.6s\n",
      "137:\tlearn: 52.6823113\ttotal: 1.69s\tremaining: 10.6s\n",
      "138:\tlearn: 52.6647451\ttotal: 1.7s\tremaining: 10.5s\n",
      "139:\tlearn: 52.6563605\ttotal: 1.71s\tremaining: 10.5s\n",
      "140:\tlearn: 52.6488712\ttotal: 1.72s\tremaining: 10.5s\n",
      "141:\tlearn: 52.6443239\ttotal: 1.73s\tremaining: 10.5s\n",
      "142:\tlearn: 52.6399758\ttotal: 1.74s\tremaining: 10.4s\n",
      "143:\tlearn: 52.6351618\ttotal: 1.75s\tremaining: 10.4s\n",
      "144:\tlearn: 52.6287579\ttotal: 1.76s\tremaining: 10.4s\n",
      "145:\tlearn: 52.6232779\ttotal: 1.77s\tremaining: 10.4s\n",
      "146:\tlearn: 52.6209181\ttotal: 1.78s\tremaining: 10.3s\n",
      "147:\tlearn: 52.6169928\ttotal: 1.79s\tremaining: 10.3s\n",
      "148:\tlearn: 52.6134620\ttotal: 1.8s\tremaining: 10.3s\n",
      "149:\tlearn: 52.6082589\ttotal: 1.81s\tremaining: 10.3s\n",
      "150:\tlearn: 52.5951632\ttotal: 1.82s\tremaining: 10.2s\n",
      "151:\tlearn: 52.5859233\ttotal: 1.83s\tremaining: 10.2s\n",
      "152:\tlearn: 52.5814879\ttotal: 1.84s\tremaining: 10.2s\n",
      "153:\tlearn: 52.5698062\ttotal: 1.85s\tremaining: 10.2s\n",
      "154:\tlearn: 52.5645803\ttotal: 1.86s\tremaining: 10.1s\n",
      "155:\tlearn: 52.5624309\ttotal: 1.87s\tremaining: 10.1s\n",
      "156:\tlearn: 52.5563635\ttotal: 1.88s\tremaining: 10.1s\n",
      "157:\tlearn: 52.5515609\ttotal: 1.89s\tremaining: 10.1s\n",
      "158:\tlearn: 52.5345544\ttotal: 1.9s\tremaining: 10s\n",
      "159:\tlearn: 52.5304779\ttotal: 1.91s\tremaining: 10s\n",
      "160:\tlearn: 52.5231285\ttotal: 1.92s\tremaining: 9.99s\n",
      "161:\tlearn: 52.5182362\ttotal: 1.93s\tremaining: 9.96s\n",
      "162:\tlearn: 52.5127152\ttotal: 1.93s\tremaining: 9.94s\n",
      "163:\tlearn: 52.5076817\ttotal: 1.94s\tremaining: 9.91s\n",
      "164:\tlearn: 52.5055527\ttotal: 1.95s\tremaining: 9.89s\n",
      "165:\tlearn: 52.4951162\ttotal: 1.96s\tremaining: 9.86s\n",
      "166:\tlearn: 52.4890190\ttotal: 1.97s\tremaining: 9.84s\n",
      "167:\tlearn: 52.4851715\ttotal: 1.98s\tremaining: 9.81s\n",
      "168:\tlearn: 52.4809649\ttotal: 1.99s\tremaining: 9.79s\n",
      "169:\tlearn: 52.4707770\ttotal: 2s\tremaining: 9.76s\n",
      "170:\tlearn: 52.4687053\ttotal: 2.01s\tremaining: 9.74s\n",
      "171:\tlearn: 52.4635990\ttotal: 2.02s\tremaining: 9.71s\n",
      "172:\tlearn: 52.4567708\ttotal: 2.02s\tremaining: 9.68s\n",
      "173:\tlearn: 52.4475735\ttotal: 2.03s\tremaining: 9.65s\n",
      "174:\tlearn: 52.4340364\ttotal: 2.04s\tremaining: 9.63s\n",
      "175:\tlearn: 52.4304912\ttotal: 2.05s\tremaining: 9.6s\n",
      "176:\tlearn: 52.4212620\ttotal: 2.06s\tremaining: 9.57s\n",
      "177:\tlearn: 52.4193700\ttotal: 2.07s\tremaining: 9.54s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178:\tlearn: 52.4150180\ttotal: 2.08s\tremaining: 9.52s\n",
      "179:\tlearn: 52.4098934\ttotal: 2.08s\tremaining: 9.5s\n",
      "180:\tlearn: 52.4048694\ttotal: 2.1s\tremaining: 9.49s\n",
      "181:\tlearn: 52.3988101\ttotal: 2.11s\tremaining: 9.46s\n",
      "182:\tlearn: 52.3935405\ttotal: 2.12s\tremaining: 9.45s\n",
      "183:\tlearn: 52.3813234\ttotal: 2.13s\tremaining: 9.42s\n",
      "184:\tlearn: 52.3742097\ttotal: 2.13s\tremaining: 9.4s\n",
      "185:\tlearn: 52.3670952\ttotal: 2.14s\tremaining: 9.38s\n",
      "186:\tlearn: 52.3620338\ttotal: 2.15s\tremaining: 9.36s\n",
      "187:\tlearn: 52.3572566\ttotal: 2.16s\tremaining: 9.33s\n",
      "188:\tlearn: 52.3522199\ttotal: 2.17s\tremaining: 9.31s\n",
      "189:\tlearn: 52.3481658\ttotal: 2.18s\tremaining: 9.28s\n",
      "190:\tlearn: 52.3463370\ttotal: 2.19s\tremaining: 9.26s\n",
      "191:\tlearn: 52.3407202\ttotal: 2.19s\tremaining: 9.24s\n",
      "192:\tlearn: 52.3322025\ttotal: 2.21s\tremaining: 9.22s\n",
      "193:\tlearn: 52.3265429\ttotal: 2.21s\tremaining: 9.2s\n",
      "194:\tlearn: 52.3146669\ttotal: 2.22s\tremaining: 9.18s\n",
      "195:\tlearn: 52.3081323\ttotal: 2.23s\tremaining: 9.15s\n",
      "196:\tlearn: 52.2934007\ttotal: 2.24s\tremaining: 9.13s\n",
      "197:\tlearn: 52.2782063\ttotal: 2.25s\tremaining: 9.11s\n",
      "198:\tlearn: 52.2747036\ttotal: 2.26s\tremaining: 9.09s\n",
      "199:\tlearn: 52.2646873\ttotal: 2.27s\tremaining: 9.07s\n",
      "200:\tlearn: 52.2629677\ttotal: 2.28s\tremaining: 9.05s\n",
      "201:\tlearn: 52.2577369\ttotal: 2.29s\tremaining: 9.03s\n",
      "202:\tlearn: 52.2493866\ttotal: 2.29s\tremaining: 9.01s\n",
      "203:\tlearn: 52.2353116\ttotal: 2.3s\tremaining: 8.99s\n",
      "204:\tlearn: 52.2300271\ttotal: 2.31s\tremaining: 8.98s\n",
      "205:\tlearn: 52.2250450\ttotal: 2.33s\tremaining: 8.97s\n",
      "206:\tlearn: 52.2155247\ttotal: 2.34s\tremaining: 8.96s\n",
      "207:\tlearn: 52.2050881\ttotal: 2.35s\tremaining: 8.93s\n",
      "208:\tlearn: 52.2001287\ttotal: 2.35s\tremaining: 8.91s\n",
      "209:\tlearn: 52.1973908\ttotal: 2.37s\tremaining: 8.9s\n",
      "210:\tlearn: 52.1934298\ttotal: 2.38s\tremaining: 8.88s\n",
      "211:\tlearn: 52.1887000\ttotal: 2.39s\tremaining: 8.87s\n",
      "212:\tlearn: 52.1871268\ttotal: 2.4s\tremaining: 8.85s\n",
      "213:\tlearn: 52.1773993\ttotal: 2.41s\tremaining: 8.84s\n",
      "214:\tlearn: 52.1736072\ttotal: 2.42s\tremaining: 8.83s\n",
      "215:\tlearn: 52.1671602\ttotal: 2.43s\tremaining: 8.81s\n",
      "216:\tlearn: 52.1635065\ttotal: 2.44s\tremaining: 8.79s\n",
      "217:\tlearn: 52.1544533\ttotal: 2.45s\tremaining: 8.78s\n",
      "218:\tlearn: 52.1498501\ttotal: 2.46s\tremaining: 8.76s\n",
      "219:\tlearn: 52.1463517\ttotal: 2.47s\tremaining: 8.74s\n",
      "220:\tlearn: 52.1333033\ttotal: 2.48s\tremaining: 8.73s\n",
      "221:\tlearn: 52.1128779\ttotal: 2.49s\tremaining: 8.71s\n",
      "222:\tlearn: 52.1044327\ttotal: 2.5s\tremaining: 8.7s\n",
      "223:\tlearn: 52.0898647\ttotal: 2.51s\tremaining: 8.69s\n",
      "224:\tlearn: 52.0830334\ttotal: 2.52s\tremaining: 8.67s\n",
      "225:\tlearn: 52.0709387\ttotal: 2.53s\tremaining: 8.65s\n",
      "226:\tlearn: 52.0611126\ttotal: 2.54s\tremaining: 8.64s\n",
      "227:\tlearn: 52.0543939\ttotal: 2.55s\tremaining: 8.63s\n",
      "228:\tlearn: 52.0505218\ttotal: 2.56s\tremaining: 8.61s\n",
      "229:\tlearn: 52.0426915\ttotal: 2.56s\tremaining: 8.59s\n",
      "230:\tlearn: 52.0346320\ttotal: 2.57s\tremaining: 8.57s\n",
      "231:\tlearn: 52.0267024\ttotal: 2.58s\tremaining: 8.55s\n",
      "232:\tlearn: 52.0133984\ttotal: 2.59s\tremaining: 8.54s\n",
      "233:\tlearn: 52.0011184\ttotal: 2.6s\tremaining: 8.52s\n",
      "234:\tlearn: 51.9960827\ttotal: 2.61s\tremaining: 8.51s\n",
      "235:\tlearn: 51.9772152\ttotal: 2.62s\tremaining: 8.49s\n",
      "236:\tlearn: 51.9757846\ttotal: 2.63s\tremaining: 8.48s\n",
      "237:\tlearn: 51.9715083\ttotal: 2.64s\tremaining: 8.46s\n",
      "238:\tlearn: 51.9601825\ttotal: 2.65s\tremaining: 8.44s\n",
      "239:\tlearn: 51.9557876\ttotal: 2.66s\tremaining: 8.43s\n",
      "240:\tlearn: 51.9516968\ttotal: 2.67s\tremaining: 8.41s\n",
      "241:\tlearn: 51.9483004\ttotal: 2.68s\tremaining: 8.39s\n",
      "242:\tlearn: 51.9384458\ttotal: 2.69s\tremaining: 8.37s\n",
      "243:\tlearn: 51.9327167\ttotal: 2.7s\tremaining: 8.37s\n",
      "244:\tlearn: 51.9279225\ttotal: 2.71s\tremaining: 8.35s\n",
      "245:\tlearn: 51.9214900\ttotal: 2.72s\tremaining: 8.34s\n",
      "246:\tlearn: 51.9061365\ttotal: 2.73s\tremaining: 8.33s\n",
      "247:\tlearn: 51.9026140\ttotal: 2.74s\tremaining: 8.31s\n",
      "248:\tlearn: 51.8929094\ttotal: 2.75s\tremaining: 8.3s\n",
      "249:\tlearn: 51.8838022\ttotal: 2.76s\tremaining: 8.29s\n",
      "250:\tlearn: 51.8759230\ttotal: 2.77s\tremaining: 8.27s\n",
      "251:\tlearn: 51.8717509\ttotal: 2.78s\tremaining: 8.26s\n",
      "252:\tlearn: 51.8583865\ttotal: 2.79s\tremaining: 8.25s\n",
      "253:\tlearn: 51.8536326\ttotal: 2.8s\tremaining: 8.23s\n",
      "254:\tlearn: 51.8457648\ttotal: 2.81s\tremaining: 8.22s\n",
      "255:\tlearn: 51.8362947\ttotal: 2.83s\tremaining: 8.21s\n",
      "256:\tlearn: 51.8314163\ttotal: 2.84s\tremaining: 8.2s\n",
      "257:\tlearn: 51.8221789\ttotal: 2.85s\tremaining: 8.19s\n",
      "258:\tlearn: 51.8117119\ttotal: 2.86s\tremaining: 8.17s\n",
      "259:\tlearn: 51.8063819\ttotal: 2.87s\tremaining: 8.16s\n",
      "260:\tlearn: 51.8021494\ttotal: 2.88s\tremaining: 8.14s\n",
      "261:\tlearn: 51.7857544\ttotal: 2.89s\tremaining: 8.13s\n",
      "262:\tlearn: 51.7785250\ttotal: 2.9s\tremaining: 8.11s\n",
      "263:\tlearn: 51.7760215\ttotal: 2.91s\tremaining: 8.1s\n",
      "264:\tlearn: 51.7658672\ttotal: 2.92s\tremaining: 8.09s\n",
      "265:\tlearn: 51.7495234\ttotal: 2.93s\tremaining: 8.08s\n",
      "266:\tlearn: 51.7427244\ttotal: 2.94s\tremaining: 8.06s\n",
      "267:\tlearn: 51.7342515\ttotal: 2.95s\tremaining: 8.05s\n",
      "268:\tlearn: 51.7330297\ttotal: 2.96s\tremaining: 8.04s\n",
      "269:\tlearn: 51.7171876\ttotal: 2.97s\tremaining: 8.02s\n",
      "270:\tlearn: 51.7104417\ttotal: 2.98s\tremaining: 8s\n",
      "271:\tlearn: 51.7014972\ttotal: 2.99s\tremaining: 7.99s\n",
      "272:\tlearn: 51.6969266\ttotal: 3s\tremaining: 7.98s\n",
      "273:\tlearn: 51.6910970\ttotal: 3s\tremaining: 7.96s\n",
      "274:\tlearn: 51.6862871\ttotal: 3.02s\tremaining: 7.95s\n",
      "275:\tlearn: 51.6842761\ttotal: 3.02s\tremaining: 7.93s\n",
      "276:\tlearn: 51.6754282\ttotal: 3.03s\tremaining: 7.92s\n",
      "277:\tlearn: 51.6673560\ttotal: 3.04s\tremaining: 7.91s\n",
      "278:\tlearn: 51.6636655\ttotal: 3.05s\tremaining: 7.89s\n",
      "279:\tlearn: 51.6574328\ttotal: 3.06s\tremaining: 7.88s\n",
      "280:\tlearn: 51.6517273\ttotal: 3.07s\tremaining: 7.87s\n",
      "281:\tlearn: 51.6506393\ttotal: 3.08s\tremaining: 7.86s\n",
      "282:\tlearn: 51.6384936\ttotal: 3.1s\tremaining: 7.85s\n",
      "283:\tlearn: 51.6343357\ttotal: 3.11s\tremaining: 7.83s\n",
      "284:\tlearn: 51.6286561\ttotal: 3.12s\tremaining: 7.82s\n",
      "285:\tlearn: 51.6136339\ttotal: 3.13s\tremaining: 7.81s\n",
      "286:\tlearn: 51.6047589\ttotal: 3.14s\tremaining: 7.79s\n",
      "287:\tlearn: 51.5917999\ttotal: 3.15s\tremaining: 7.78s\n",
      "288:\tlearn: 51.5833137\ttotal: 3.16s\tremaining: 7.76s\n",
      "289:\tlearn: 51.5797074\ttotal: 3.17s\tremaining: 7.75s\n",
      "290:\tlearn: 51.5700441\ttotal: 3.17s\tremaining: 7.74s\n",
      "291:\tlearn: 51.5627914\ttotal: 3.19s\tremaining: 7.72s\n",
      "292:\tlearn: 51.5581263\ttotal: 3.19s\tremaining: 7.71s\n",
      "293:\tlearn: 51.5562085\ttotal: 3.2s\tremaining: 7.69s\n",
      "294:\tlearn: 51.5478400\ttotal: 3.21s\tremaining: 7.68s\n",
      "295:\tlearn: 51.5443328\ttotal: 3.22s\tremaining: 7.66s\n",
      "296:\tlearn: 51.5378568\ttotal: 3.23s\tremaining: 7.66s\n",
      "297:\tlearn: 51.5308066\ttotal: 3.25s\tremaining: 7.65s\n",
      "298:\tlearn: 51.5223560\ttotal: 3.25s\tremaining: 7.63s\n",
      "299:\tlearn: 51.5136006\ttotal: 3.27s\tremaining: 7.62s\n",
      "300:\tlearn: 51.5048269\ttotal: 3.28s\tremaining: 7.61s\n",
      "301:\tlearn: 51.4981480\ttotal: 3.29s\tremaining: 7.6s\n",
      "302:\tlearn: 51.4959154\ttotal: 3.3s\tremaining: 7.59s\n",
      "303:\tlearn: 51.4879190\ttotal: 3.31s\tremaining: 7.58s\n",
      "304:\tlearn: 51.4818906\ttotal: 3.32s\tremaining: 7.57s\n",
      "305:\tlearn: 51.4784048\ttotal: 3.33s\tremaining: 7.56s\n",
      "306:\tlearn: 51.4731287\ttotal: 3.34s\tremaining: 7.55s\n",
      "307:\tlearn: 51.4713958\ttotal: 3.35s\tremaining: 7.54s\n",
      "308:\tlearn: 51.4647742\ttotal: 3.37s\tremaining: 7.53s\n",
      "309:\tlearn: 51.4595466\ttotal: 3.38s\tremaining: 7.52s\n",
      "310:\tlearn: 51.4575891\ttotal: 3.39s\tremaining: 7.51s\n",
      "311:\tlearn: 51.4498693\ttotal: 3.4s\tremaining: 7.5s\n",
      "312:\tlearn: 51.4459636\ttotal: 3.41s\tremaining: 7.49s\n",
      "313:\tlearn: 51.4412789\ttotal: 3.42s\tremaining: 7.48s\n",
      "314:\tlearn: 51.4355860\ttotal: 3.43s\tremaining: 7.47s\n",
      "315:\tlearn: 51.4294841\ttotal: 3.45s\tremaining: 7.46s\n",
      "316:\tlearn: 51.4251472\ttotal: 3.46s\tremaining: 7.45s\n",
      "317:\tlearn: 51.4202969\ttotal: 3.47s\tremaining: 7.43s\n",
      "318:\tlearn: 51.4194052\ttotal: 3.48s\tremaining: 7.42s\n",
      "319:\tlearn: 51.4104050\ttotal: 3.49s\tremaining: 7.41s\n",
      "320:\tlearn: 51.4034631\ttotal: 3.5s\tremaining: 7.4s\n",
      "321:\tlearn: 51.3983316\ttotal: 3.51s\tremaining: 7.38s\n",
      "322:\tlearn: 51.3927918\ttotal: 3.52s\tremaining: 7.37s\n",
      "323:\tlearn: 51.3866071\ttotal: 3.53s\tremaining: 7.36s\n",
      "324:\tlearn: 51.3787745\ttotal: 3.54s\tremaining: 7.35s\n",
      "325:\tlearn: 51.3723603\ttotal: 3.55s\tremaining: 7.34s\n",
      "326:\tlearn: 51.3674280\ttotal: 3.56s\tremaining: 7.32s\n",
      "327:\tlearn: 51.3540353\ttotal: 3.57s\tremaining: 7.31s\n",
      "328:\tlearn: 51.3413818\ttotal: 3.58s\tremaining: 7.29s\n",
      "329:\tlearn: 51.3358735\ttotal: 3.59s\tremaining: 7.28s\n",
      "330:\tlearn: 51.3276132\ttotal: 3.6s\tremaining: 7.27s\n",
      "331:\tlearn: 51.3188677\ttotal: 3.61s\tremaining: 7.26s\n",
      "332:\tlearn: 51.3145559\ttotal: 3.62s\tremaining: 7.24s\n",
      "333:\tlearn: 51.3027669\ttotal: 3.63s\tremaining: 7.23s\n",
      "334:\tlearn: 51.2947561\ttotal: 3.63s\tremaining: 7.21s\n",
      "335:\tlearn: 51.2915527\ttotal: 3.64s\tremaining: 7.2s\n",
      "336:\tlearn: 51.2839627\ttotal: 3.65s\tremaining: 7.19s\n",
      "337:\tlearn: 51.2754308\ttotal: 3.66s\tremaining: 7.17s\n",
      "338:\tlearn: 51.2672985\ttotal: 3.67s\tremaining: 7.16s\n",
      "339:\tlearn: 51.2634062\ttotal: 3.68s\tremaining: 7.15s\n",
      "340:\tlearn: 51.2561113\ttotal: 3.69s\tremaining: 7.14s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341:\tlearn: 51.2531741\ttotal: 3.71s\tremaining: 7.13s\n",
      "342:\tlearn: 51.2491050\ttotal: 3.72s\tremaining: 7.12s\n",
      "343:\tlearn: 51.2415239\ttotal: 3.73s\tremaining: 7.11s\n",
      "344:\tlearn: 51.2362068\ttotal: 3.74s\tremaining: 7.09s\n",
      "345:\tlearn: 51.2321444\ttotal: 3.75s\tremaining: 7.08s\n",
      "346:\tlearn: 51.2263139\ttotal: 3.76s\tremaining: 7.07s\n",
      "347:\tlearn: 51.2185265\ttotal: 3.77s\tremaining: 7.06s\n",
      "348:\tlearn: 51.2145419\ttotal: 3.78s\tremaining: 7.04s\n",
      "349:\tlearn: 51.2069269\ttotal: 3.79s\tremaining: 7.03s\n",
      "350:\tlearn: 51.1976394\ttotal: 3.8s\tremaining: 7.02s\n",
      "351:\tlearn: 51.1929853\ttotal: 3.81s\tremaining: 7.01s\n",
      "352:\tlearn: 51.1864175\ttotal: 3.82s\tremaining: 7s\n",
      "353:\tlearn: 51.1834378\ttotal: 3.83s\tremaining: 6.98s\n",
      "354:\tlearn: 51.1783156\ttotal: 3.84s\tremaining: 6.97s\n",
      "355:\tlearn: 51.1734757\ttotal: 3.85s\tremaining: 6.96s\n",
      "356:\tlearn: 51.1652495\ttotal: 3.86s\tremaining: 6.95s\n",
      "357:\tlearn: 51.1579813\ttotal: 3.87s\tremaining: 6.93s\n",
      "358:\tlearn: 51.1501780\ttotal: 3.88s\tremaining: 6.92s\n",
      "359:\tlearn: 51.1460069\ttotal: 3.88s\tremaining: 6.91s\n",
      "360:\tlearn: 51.1382065\ttotal: 3.9s\tremaining: 6.89s\n",
      "361:\tlearn: 51.1367289\ttotal: 3.9s\tremaining: 6.88s\n",
      "362:\tlearn: 51.1329986\ttotal: 3.92s\tremaining: 6.87s\n",
      "363:\tlearn: 51.1251996\ttotal: 3.93s\tremaining: 6.86s\n",
      "364:\tlearn: 51.1207697\ttotal: 3.94s\tremaining: 6.85s\n",
      "365:\tlearn: 51.1122471\ttotal: 3.95s\tremaining: 6.84s\n",
      "366:\tlearn: 51.1080705\ttotal: 3.96s\tremaining: 6.83s\n",
      "367:\tlearn: 51.1017566\ttotal: 3.97s\tremaining: 6.81s\n",
      "368:\tlearn: 51.0959669\ttotal: 3.98s\tremaining: 6.8s\n",
      "369:\tlearn: 51.0914856\ttotal: 3.99s\tremaining: 6.8s\n",
      "370:\tlearn: 51.0876023\ttotal: 4s\tremaining: 6.79s\n",
      "371:\tlearn: 51.0848011\ttotal: 4.01s\tremaining: 6.77s\n",
      "372:\tlearn: 51.0808318\ttotal: 4.02s\tremaining: 6.76s\n",
      "373:\tlearn: 51.0691689\ttotal: 4.03s\tremaining: 6.75s\n",
      "374:\tlearn: 51.0654677\ttotal: 4.04s\tremaining: 6.74s\n",
      "375:\tlearn: 51.0615131\ttotal: 4.05s\tremaining: 6.72s\n",
      "376:\tlearn: 51.0569067\ttotal: 4.06s\tremaining: 6.71s\n",
      "377:\tlearn: 51.0538204\ttotal: 4.07s\tremaining: 6.7s\n",
      "378:\tlearn: 51.0500807\ttotal: 4.08s\tremaining: 6.69s\n",
      "379:\tlearn: 51.0456943\ttotal: 4.09s\tremaining: 6.68s\n",
      "380:\tlearn: 51.0428012\ttotal: 4.11s\tremaining: 6.67s\n",
      "381:\tlearn: 51.0393728\ttotal: 4.12s\tremaining: 6.66s\n",
      "382:\tlearn: 51.0347618\ttotal: 4.13s\tremaining: 6.65s\n",
      "383:\tlearn: 51.0285473\ttotal: 4.14s\tremaining: 6.64s\n",
      "384:\tlearn: 51.0188794\ttotal: 4.15s\tremaining: 6.63s\n",
      "385:\tlearn: 51.0134139\ttotal: 4.16s\tremaining: 6.62s\n",
      "386:\tlearn: 51.0052093\ttotal: 4.17s\tremaining: 6.61s\n",
      "387:\tlearn: 50.9998223\ttotal: 4.18s\tremaining: 6.6s\n",
      "388:\tlearn: 50.9887779\ttotal: 4.19s\tremaining: 6.58s\n",
      "389:\tlearn: 50.9854640\ttotal: 4.2s\tremaining: 6.57s\n",
      "390:\tlearn: 50.9838924\ttotal: 4.21s\tremaining: 6.56s\n",
      "391:\tlearn: 50.9766994\ttotal: 4.22s\tremaining: 6.55s\n",
      "392:\tlearn: 50.9738873\ttotal: 4.23s\tremaining: 6.54s\n",
      "393:\tlearn: 50.9686538\ttotal: 4.24s\tremaining: 6.53s\n",
      "394:\tlearn: 50.9582957\ttotal: 4.25s\tremaining: 6.51s\n",
      "395:\tlearn: 50.9511930\ttotal: 4.26s\tremaining: 6.5s\n",
      "396:\tlearn: 50.9474869\ttotal: 4.27s\tremaining: 6.49s\n",
      "397:\tlearn: 50.9430705\ttotal: 4.28s\tremaining: 6.48s\n",
      "398:\tlearn: 50.9353475\ttotal: 4.29s\tremaining: 6.46s\n",
      "399:\tlearn: 50.9290427\ttotal: 4.3s\tremaining: 6.45s\n",
      "400:\tlearn: 50.9254647\ttotal: 4.31s\tremaining: 6.44s\n",
      "401:\tlearn: 50.9202429\ttotal: 4.32s\tremaining: 6.43s\n",
      "402:\tlearn: 50.9152722\ttotal: 4.33s\tremaining: 6.41s\n",
      "403:\tlearn: 50.9107060\ttotal: 4.34s\tremaining: 6.41s\n",
      "404:\tlearn: 50.9037012\ttotal: 4.35s\tremaining: 6.39s\n",
      "405:\tlearn: 50.8964377\ttotal: 4.36s\tremaining: 6.38s\n",
      "406:\tlearn: 50.8814655\ttotal: 4.37s\tremaining: 6.37s\n",
      "407:\tlearn: 50.8729840\ttotal: 4.38s\tremaining: 6.36s\n",
      "408:\tlearn: 50.8572256\ttotal: 4.39s\tremaining: 6.35s\n",
      "409:\tlearn: 50.8463246\ttotal: 4.41s\tremaining: 6.34s\n",
      "410:\tlearn: 50.8444631\ttotal: 4.42s\tremaining: 6.33s\n",
      "411:\tlearn: 50.8385118\ttotal: 4.43s\tremaining: 6.32s\n",
      "412:\tlearn: 50.8325277\ttotal: 4.44s\tremaining: 6.3s\n",
      "413:\tlearn: 50.8267037\ttotal: 4.45s\tremaining: 6.29s\n",
      "414:\tlearn: 50.8218670\ttotal: 4.46s\tremaining: 6.29s\n",
      "415:\tlearn: 50.8147597\ttotal: 4.47s\tremaining: 6.28s\n",
      "416:\tlearn: 50.8109406\ttotal: 4.48s\tremaining: 6.27s\n",
      "417:\tlearn: 50.7961669\ttotal: 4.49s\tremaining: 6.26s\n",
      "418:\tlearn: 50.7926007\ttotal: 4.5s\tremaining: 6.25s\n",
      "419:\tlearn: 50.7892011\ttotal: 4.51s\tremaining: 6.23s\n",
      "420:\tlearn: 50.7847957\ttotal: 4.52s\tremaining: 6.22s\n",
      "421:\tlearn: 50.7834503\ttotal: 4.53s\tremaining: 6.21s\n",
      "422:\tlearn: 50.7787284\ttotal: 4.54s\tremaining: 6.2s\n",
      "423:\tlearn: 50.7673971\ttotal: 4.56s\tremaining: 6.19s\n",
      "424:\tlearn: 50.7625290\ttotal: 4.57s\tremaining: 6.18s\n",
      "425:\tlearn: 50.7583404\ttotal: 4.58s\tremaining: 6.17s\n",
      "426:\tlearn: 50.7570603\ttotal: 4.59s\tremaining: 6.15s\n",
      "427:\tlearn: 50.7492239\ttotal: 4.6s\tremaining: 6.14s\n",
      "428:\tlearn: 50.7456056\ttotal: 4.61s\tremaining: 6.13s\n",
      "429:\tlearn: 50.7413858\ttotal: 4.62s\tremaining: 6.12s\n",
      "430:\tlearn: 50.7342827\ttotal: 4.63s\tremaining: 6.11s\n",
      "431:\tlearn: 50.7143770\ttotal: 4.64s\tremaining: 6.1s\n",
      "432:\tlearn: 50.7108059\ttotal: 4.65s\tremaining: 6.09s\n",
      "433:\tlearn: 50.7065830\ttotal: 4.66s\tremaining: 6.08s\n",
      "434:\tlearn: 50.7017715\ttotal: 4.67s\tremaining: 6.06s\n",
      "435:\tlearn: 50.6964046\ttotal: 4.68s\tremaining: 6.05s\n",
      "436:\tlearn: 50.6938535\ttotal: 4.69s\tremaining: 6.04s\n",
      "437:\tlearn: 50.6905632\ttotal: 4.7s\tremaining: 6.03s\n",
      "438:\tlearn: 50.6858442\ttotal: 4.71s\tremaining: 6.02s\n",
      "439:\tlearn: 50.6738120\ttotal: 4.72s\tremaining: 6s\n",
      "440:\tlearn: 50.6703579\ttotal: 4.73s\tremaining: 5.99s\n",
      "441:\tlearn: 50.6614466\ttotal: 4.74s\tremaining: 5.98s\n",
      "442:\tlearn: 50.6547741\ttotal: 4.75s\tremaining: 5.97s\n",
      "443:\tlearn: 50.6487582\ttotal: 4.76s\tremaining: 5.96s\n",
      "444:\tlearn: 50.6461161\ttotal: 4.77s\tremaining: 5.95s\n",
      "445:\tlearn: 50.6425946\ttotal: 4.78s\tremaining: 5.94s\n",
      "446:\tlearn: 50.6339712\ttotal: 4.79s\tremaining: 5.93s\n",
      "447:\tlearn: 50.6258649\ttotal: 4.8s\tremaining: 5.91s\n",
      "448:\tlearn: 50.6189766\ttotal: 4.81s\tremaining: 5.9s\n",
      "449:\tlearn: 50.6155808\ttotal: 4.82s\tremaining: 5.89s\n",
      "450:\tlearn: 50.6025520\ttotal: 4.83s\tremaining: 5.88s\n",
      "451:\tlearn: 50.5940797\ttotal: 4.84s\tremaining: 5.87s\n",
      "452:\tlearn: 50.5913359\ttotal: 4.85s\tremaining: 5.86s\n",
      "453:\tlearn: 50.5820560\ttotal: 4.86s\tremaining: 5.84s\n",
      "454:\tlearn: 50.5769551\ttotal: 4.87s\tremaining: 5.83s\n",
      "455:\tlearn: 50.5686643\ttotal: 4.88s\tremaining: 5.82s\n",
      "456:\tlearn: 50.5626668\ttotal: 4.89s\tremaining: 5.81s\n",
      "457:\tlearn: 50.5560566\ttotal: 4.9s\tremaining: 5.8s\n",
      "458:\tlearn: 50.5480831\ttotal: 4.91s\tremaining: 5.79s\n",
      "459:\tlearn: 50.5388867\ttotal: 4.92s\tremaining: 5.77s\n",
      "460:\tlearn: 50.5342407\ttotal: 4.93s\tremaining: 5.76s\n",
      "461:\tlearn: 50.5300159\ttotal: 4.94s\tremaining: 5.75s\n",
      "462:\tlearn: 50.5258154\ttotal: 4.95s\tremaining: 5.75s\n",
      "463:\tlearn: 50.5217605\ttotal: 4.96s\tremaining: 5.74s\n",
      "464:\tlearn: 50.5185089\ttotal: 4.97s\tremaining: 5.72s\n",
      "465:\tlearn: 50.5112382\ttotal: 4.99s\tremaining: 5.71s\n",
      "466:\tlearn: 50.5079840\ttotal: 5s\tremaining: 5.7s\n",
      "467:\tlearn: 50.4996770\ttotal: 5.01s\tremaining: 5.69s\n",
      "468:\tlearn: 50.4954552\ttotal: 5.02s\tremaining: 5.68s\n",
      "469:\tlearn: 50.4923645\ttotal: 5.03s\tremaining: 5.67s\n",
      "470:\tlearn: 50.4872724\ttotal: 5.04s\tremaining: 5.66s\n",
      "471:\tlearn: 50.4826474\ttotal: 5.05s\tremaining: 5.65s\n",
      "472:\tlearn: 50.4716793\ttotal: 5.07s\tremaining: 5.64s\n",
      "473:\tlearn: 50.4616601\ttotal: 5.08s\tremaining: 5.63s\n",
      "474:\tlearn: 50.4559017\ttotal: 5.09s\tremaining: 5.62s\n",
      "475:\tlearn: 50.4477276\ttotal: 5.1s\tremaining: 5.61s\n",
      "476:\tlearn: 50.4406193\ttotal: 5.11s\tremaining: 5.6s\n",
      "477:\tlearn: 50.4350718\ttotal: 5.12s\tremaining: 5.59s\n",
      "478:\tlearn: 50.4278941\ttotal: 5.13s\tremaining: 5.58s\n",
      "479:\tlearn: 50.4198329\ttotal: 5.14s\tremaining: 5.57s\n",
      "480:\tlearn: 50.4032883\ttotal: 5.15s\tremaining: 5.56s\n",
      "481:\tlearn: 50.4000417\ttotal: 5.16s\tremaining: 5.54s\n",
      "482:\tlearn: 50.3925548\ttotal: 5.17s\tremaining: 5.54s\n",
      "483:\tlearn: 50.3860152\ttotal: 5.18s\tremaining: 5.53s\n",
      "484:\tlearn: 50.3819897\ttotal: 5.2s\tremaining: 5.52s\n",
      "485:\tlearn: 50.3758104\ttotal: 5.21s\tremaining: 5.51s\n",
      "486:\tlearn: 50.3575089\ttotal: 5.22s\tremaining: 5.5s\n",
      "487:\tlearn: 50.3500314\ttotal: 5.23s\tremaining: 5.49s\n",
      "488:\tlearn: 50.3441500\ttotal: 5.24s\tremaining: 5.48s\n",
      "489:\tlearn: 50.3342645\ttotal: 5.25s\tremaining: 5.47s\n",
      "490:\tlearn: 50.3306359\ttotal: 5.26s\tremaining: 5.46s\n",
      "491:\tlearn: 50.3243809\ttotal: 5.27s\tremaining: 5.45s\n",
      "492:\tlearn: 50.3189877\ttotal: 5.29s\tremaining: 5.43s\n",
      "493:\tlearn: 50.3140676\ttotal: 5.3s\tremaining: 5.42s\n",
      "494:\tlearn: 50.3101899\ttotal: 5.31s\tremaining: 5.42s\n",
      "495:\tlearn: 50.3047661\ttotal: 5.32s\tremaining: 5.4s\n",
      "496:\tlearn: 50.3004102\ttotal: 5.33s\tremaining: 5.39s\n",
      "497:\tlearn: 50.2845307\ttotal: 5.34s\tremaining: 5.38s\n",
      "498:\tlearn: 50.2803982\ttotal: 5.35s\tremaining: 5.38s\n",
      "499:\tlearn: 50.2757997\ttotal: 5.37s\tremaining: 5.37s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500:\tlearn: 50.2686857\ttotal: 5.38s\tremaining: 5.36s\n",
      "501:\tlearn: 50.2636599\ttotal: 5.39s\tremaining: 5.34s\n",
      "502:\tlearn: 50.2621829\ttotal: 5.4s\tremaining: 5.33s\n",
      "503:\tlearn: 50.2556680\ttotal: 5.41s\tremaining: 5.33s\n",
      "504:\tlearn: 50.2452953\ttotal: 5.42s\tremaining: 5.32s\n",
      "505:\tlearn: 50.2413693\ttotal: 5.44s\tremaining: 5.31s\n",
      "506:\tlearn: 50.2382607\ttotal: 5.45s\tremaining: 5.29s\n",
      "507:\tlearn: 50.2316543\ttotal: 5.46s\tremaining: 5.28s\n",
      "508:\tlearn: 50.2295010\ttotal: 5.47s\tremaining: 5.28s\n",
      "509:\tlearn: 50.2241803\ttotal: 5.48s\tremaining: 5.26s\n",
      "510:\tlearn: 50.2196462\ttotal: 5.49s\tremaining: 5.25s\n",
      "511:\tlearn: 50.2181479\ttotal: 5.5s\tremaining: 5.24s\n",
      "512:\tlearn: 50.2002145\ttotal: 5.51s\tremaining: 5.24s\n",
      "513:\tlearn: 50.1966288\ttotal: 5.53s\tremaining: 5.22s\n",
      "514:\tlearn: 50.1940261\ttotal: 5.54s\tremaining: 5.21s\n",
      "515:\tlearn: 50.1900457\ttotal: 5.55s\tremaining: 5.2s\n",
      "516:\tlearn: 50.1855970\ttotal: 5.56s\tremaining: 5.19s\n",
      "517:\tlearn: 50.1835115\ttotal: 5.57s\tremaining: 5.18s\n",
      "518:\tlearn: 50.1809025\ttotal: 5.58s\tremaining: 5.17s\n",
      "519:\tlearn: 50.1770281\ttotal: 5.59s\tremaining: 5.16s\n",
      "520:\tlearn: 50.1609841\ttotal: 5.6s\tremaining: 5.15s\n",
      "521:\tlearn: 50.1592802\ttotal: 5.61s\tremaining: 5.14s\n",
      "522:\tlearn: 50.1563264\ttotal: 5.62s\tremaining: 5.13s\n",
      "523:\tlearn: 50.1490682\ttotal: 5.63s\tremaining: 5.12s\n",
      "524:\tlearn: 50.1412256\ttotal: 5.64s\tremaining: 5.11s\n",
      "525:\tlearn: 50.1211683\ttotal: 5.65s\tremaining: 5.09s\n",
      "526:\tlearn: 50.1136412\ttotal: 5.67s\tremaining: 5.08s\n",
      "527:\tlearn: 50.1069550\ttotal: 5.67s\tremaining: 5.07s\n",
      "528:\tlearn: 50.0997643\ttotal: 5.68s\tremaining: 5.06s\n",
      "529:\tlearn: 50.0910067\ttotal: 5.69s\tremaining: 5.05s\n",
      "530:\tlearn: 50.0864447\ttotal: 5.7s\tremaining: 5.04s\n",
      "531:\tlearn: 50.0804365\ttotal: 5.71s\tremaining: 5.03s\n",
      "532:\tlearn: 50.0770141\ttotal: 5.73s\tremaining: 5.02s\n",
      "533:\tlearn: 50.0705964\ttotal: 5.74s\tremaining: 5s\n",
      "534:\tlearn: 50.0610178\ttotal: 5.74s\tremaining: 4.99s\n",
      "535:\tlearn: 50.0582039\ttotal: 5.75s\tremaining: 4.98s\n",
      "536:\tlearn: 50.0537497\ttotal: 5.76s\tremaining: 4.97s\n",
      "537:\tlearn: 50.0485614\ttotal: 5.77s\tremaining: 4.96s\n",
      "538:\tlearn: 50.0422567\ttotal: 5.79s\tremaining: 4.95s\n",
      "539:\tlearn: 50.0283923\ttotal: 5.8s\tremaining: 4.94s\n",
      "540:\tlearn: 50.0210418\ttotal: 5.81s\tremaining: 4.93s\n",
      "541:\tlearn: 50.0170297\ttotal: 5.82s\tremaining: 4.92s\n",
      "542:\tlearn: 49.9907580\ttotal: 5.83s\tremaining: 4.91s\n",
      "543:\tlearn: 49.9869247\ttotal: 5.84s\tremaining: 4.9s\n",
      "544:\tlearn: 49.9842446\ttotal: 5.85s\tremaining: 4.88s\n",
      "545:\tlearn: 49.9797900\ttotal: 5.86s\tremaining: 4.87s\n",
      "546:\tlearn: 49.9753590\ttotal: 5.87s\tremaining: 4.86s\n",
      "547:\tlearn: 49.9705482\ttotal: 5.88s\tremaining: 4.85s\n",
      "548:\tlearn: 49.9645436\ttotal: 5.89s\tremaining: 4.84s\n",
      "549:\tlearn: 49.9584446\ttotal: 5.91s\tremaining: 4.83s\n",
      "550:\tlearn: 49.9570041\ttotal: 5.92s\tremaining: 4.82s\n",
      "551:\tlearn: 49.9536402\ttotal: 5.93s\tremaining: 4.81s\n",
      "552:\tlearn: 49.9480538\ttotal: 5.94s\tremaining: 4.8s\n",
      "553:\tlearn: 49.9452135\ttotal: 5.95s\tremaining: 4.79s\n",
      "554:\tlearn: 49.9373994\ttotal: 5.96s\tremaining: 4.78s\n",
      "555:\tlearn: 49.9309203\ttotal: 5.97s\tremaining: 4.77s\n",
      "556:\tlearn: 49.9213171\ttotal: 5.98s\tremaining: 4.76s\n",
      "557:\tlearn: 49.9118514\ttotal: 6s\tremaining: 4.75s\n",
      "558:\tlearn: 49.9043008\ttotal: 6.01s\tremaining: 4.74s\n",
      "559:\tlearn: 49.8976546\ttotal: 6.02s\tremaining: 4.73s\n",
      "560:\tlearn: 49.8925495\ttotal: 6.04s\tremaining: 4.72s\n",
      "561:\tlearn: 49.8771931\ttotal: 6.05s\tremaining: 4.72s\n",
      "562:\tlearn: 49.8684563\ttotal: 6.07s\tremaining: 4.71s\n",
      "563:\tlearn: 49.8642318\ttotal: 6.08s\tremaining: 4.7s\n",
      "564:\tlearn: 49.8562161\ttotal: 6.09s\tremaining: 4.69s\n",
      "565:\tlearn: 49.8521132\ttotal: 6.1s\tremaining: 4.68s\n",
      "566:\tlearn: 49.8390628\ttotal: 6.11s\tremaining: 4.67s\n",
      "567:\tlearn: 49.8228556\ttotal: 6.12s\tremaining: 4.66s\n",
      "568:\tlearn: 49.8150008\ttotal: 6.14s\tremaining: 4.65s\n",
      "569:\tlearn: 49.8082384\ttotal: 6.15s\tremaining: 4.64s\n",
      "570:\tlearn: 49.8021239\ttotal: 6.16s\tremaining: 4.63s\n",
      "571:\tlearn: 49.7926073\ttotal: 6.17s\tremaining: 4.62s\n",
      "572:\tlearn: 49.7851369\ttotal: 6.18s\tremaining: 4.61s\n",
      "573:\tlearn: 49.7803109\ttotal: 6.2s\tremaining: 4.6s\n",
      "574:\tlearn: 49.7761194\ttotal: 6.21s\tremaining: 4.59s\n",
      "575:\tlearn: 49.7718307\ttotal: 6.22s\tremaining: 4.58s\n",
      "576:\tlearn: 49.7678993\ttotal: 6.24s\tremaining: 4.57s\n",
      "577:\tlearn: 49.7615357\ttotal: 6.25s\tremaining: 4.56s\n",
      "578:\tlearn: 49.7464739\ttotal: 6.26s\tremaining: 4.55s\n",
      "579:\tlearn: 49.7409129\ttotal: 6.27s\tremaining: 4.54s\n",
      "580:\tlearn: 49.7338185\ttotal: 6.29s\tremaining: 4.53s\n",
      "581:\tlearn: 49.7199699\ttotal: 6.3s\tremaining: 4.53s\n",
      "582:\tlearn: 49.7116352\ttotal: 6.32s\tremaining: 4.52s\n",
      "583:\tlearn: 49.6978035\ttotal: 6.33s\tremaining: 4.51s\n",
      "584:\tlearn: 49.6870671\ttotal: 6.34s\tremaining: 4.5s\n",
      "585:\tlearn: 49.6810016\ttotal: 6.35s\tremaining: 4.49s\n",
      "586:\tlearn: 49.6690026\ttotal: 6.37s\tremaining: 4.48s\n",
      "587:\tlearn: 49.6635860\ttotal: 6.38s\tremaining: 4.47s\n",
      "588:\tlearn: 49.6571600\ttotal: 6.39s\tremaining: 4.46s\n",
      "589:\tlearn: 49.6515154\ttotal: 6.4s\tremaining: 4.45s\n",
      "590:\tlearn: 49.6483413\ttotal: 6.42s\tremaining: 4.44s\n",
      "591:\tlearn: 49.6420094\ttotal: 6.43s\tremaining: 4.43s\n",
      "592:\tlearn: 49.6340390\ttotal: 6.44s\tremaining: 4.42s\n",
      "593:\tlearn: 49.6110213\ttotal: 6.45s\tremaining: 4.41s\n",
      "594:\tlearn: 49.6080719\ttotal: 6.46s\tremaining: 4.4s\n",
      "595:\tlearn: 49.6039845\ttotal: 6.47s\tremaining: 4.39s\n",
      "596:\tlearn: 49.5989288\ttotal: 6.49s\tremaining: 4.38s\n",
      "597:\tlearn: 49.5944947\ttotal: 6.5s\tremaining: 4.37s\n",
      "598:\tlearn: 49.5904892\ttotal: 6.51s\tremaining: 4.36s\n",
      "599:\tlearn: 49.5861036\ttotal: 6.52s\tremaining: 4.35s\n",
      "600:\tlearn: 49.5808263\ttotal: 6.53s\tremaining: 4.34s\n",
      "601:\tlearn: 49.5771884\ttotal: 6.54s\tremaining: 4.33s\n",
      "602:\tlearn: 49.5681701\ttotal: 6.55s\tremaining: 4.32s\n",
      "603:\tlearn: 49.5549346\ttotal: 6.57s\tremaining: 4.3s\n",
      "604:\tlearn: 49.5501708\ttotal: 6.58s\tremaining: 4.29s\n",
      "605:\tlearn: 49.5357945\ttotal: 6.59s\tremaining: 4.29s\n",
      "606:\tlearn: 49.5335398\ttotal: 6.6s\tremaining: 4.27s\n",
      "607:\tlearn: 49.5288602\ttotal: 6.61s\tremaining: 4.26s\n",
      "608:\tlearn: 49.5249169\ttotal: 6.63s\tremaining: 4.25s\n",
      "609:\tlearn: 49.5116312\ttotal: 6.64s\tremaining: 4.24s\n",
      "610:\tlearn: 49.5039204\ttotal: 6.65s\tremaining: 4.23s\n",
      "611:\tlearn: 49.5004546\ttotal: 6.66s\tremaining: 4.22s\n",
      "612:\tlearn: 49.4880639\ttotal: 6.67s\tremaining: 4.21s\n",
      "613:\tlearn: 49.4807554\ttotal: 6.68s\tremaining: 4.2s\n",
      "614:\tlearn: 49.4765113\ttotal: 6.7s\tremaining: 4.19s\n",
      "615:\tlearn: 49.4737168\ttotal: 6.71s\tremaining: 4.18s\n",
      "616:\tlearn: 49.4682463\ttotal: 6.72s\tremaining: 4.17s\n",
      "617:\tlearn: 49.4630934\ttotal: 6.73s\tremaining: 4.16s\n",
      "618:\tlearn: 49.4560498\ttotal: 6.74s\tremaining: 4.15s\n",
      "619:\tlearn: 49.4513241\ttotal: 6.75s\tremaining: 4.14s\n",
      "620:\tlearn: 49.4427928\ttotal: 6.76s\tremaining: 4.13s\n",
      "621:\tlearn: 49.4390047\ttotal: 6.78s\tremaining: 4.12s\n",
      "622:\tlearn: 49.4180523\ttotal: 6.79s\tremaining: 4.11s\n",
      "623:\tlearn: 49.4147482\ttotal: 6.8s\tremaining: 4.1s\n",
      "624:\tlearn: 49.4080688\ttotal: 6.81s\tremaining: 4.09s\n",
      "625:\tlearn: 49.4049559\ttotal: 6.82s\tremaining: 4.08s\n",
      "626:\tlearn: 49.4028018\ttotal: 6.83s\tremaining: 4.07s\n",
      "627:\tlearn: 49.3966006\ttotal: 6.84s\tremaining: 4.05s\n",
      "628:\tlearn: 49.3940326\ttotal: 6.86s\tremaining: 4.04s\n",
      "629:\tlearn: 49.3825320\ttotal: 6.87s\tremaining: 4.03s\n",
      "630:\tlearn: 49.3745166\ttotal: 6.88s\tremaining: 4.02s\n",
      "631:\tlearn: 49.3715731\ttotal: 6.89s\tremaining: 4.01s\n",
      "632:\tlearn: 49.3667552\ttotal: 6.9s\tremaining: 4s\n",
      "633:\tlearn: 49.3608060\ttotal: 6.91s\tremaining: 3.99s\n",
      "634:\tlearn: 49.3583617\ttotal: 6.92s\tremaining: 3.98s\n",
      "635:\tlearn: 49.3537202\ttotal: 6.93s\tremaining: 3.96s\n",
      "636:\tlearn: 49.3486234\ttotal: 6.94s\tremaining: 3.95s\n",
      "637:\tlearn: 49.3350495\ttotal: 6.95s\tremaining: 3.94s\n",
      "638:\tlearn: 49.3294470\ttotal: 6.96s\tremaining: 3.93s\n",
      "639:\tlearn: 49.3245592\ttotal: 6.97s\tremaining: 3.92s\n",
      "640:\tlearn: 49.3158661\ttotal: 6.98s\tremaining: 3.91s\n",
      "641:\tlearn: 49.3118650\ttotal: 7s\tremaining: 3.9s\n",
      "642:\tlearn: 49.3060867\ttotal: 7.01s\tremaining: 3.89s\n",
      "643:\tlearn: 49.2898134\ttotal: 7.02s\tremaining: 3.88s\n",
      "644:\tlearn: 49.2869632\ttotal: 7.04s\tremaining: 3.87s\n",
      "645:\tlearn: 49.2832719\ttotal: 7.05s\tremaining: 3.86s\n",
      "646:\tlearn: 49.2740022\ttotal: 7.06s\tremaining: 3.85s\n",
      "647:\tlearn: 49.2690459\ttotal: 7.07s\tremaining: 3.84s\n",
      "648:\tlearn: 49.2559485\ttotal: 7.08s\tremaining: 3.83s\n",
      "649:\tlearn: 49.2480824\ttotal: 7.09s\tremaining: 3.82s\n",
      "650:\tlearn: 49.2427728\ttotal: 7.1s\tremaining: 3.81s\n",
      "651:\tlearn: 49.2397562\ttotal: 7.11s\tremaining: 3.79s\n",
      "652:\tlearn: 49.2348452\ttotal: 7.12s\tremaining: 3.78s\n",
      "653:\tlearn: 49.2323552\ttotal: 7.13s\tremaining: 3.77s\n",
      "654:\tlearn: 49.2246534\ttotal: 7.14s\tremaining: 3.76s\n",
      "655:\tlearn: 49.2212238\ttotal: 7.15s\tremaining: 3.75s\n",
      "656:\tlearn: 49.2156470\ttotal: 7.16s\tremaining: 3.74s\n",
      "657:\tlearn: 49.2070771\ttotal: 7.17s\tremaining: 3.73s\n",
      "658:\tlearn: 49.1991211\ttotal: 7.18s\tremaining: 3.72s\n",
      "659:\tlearn: 49.1927860\ttotal: 7.2s\tremaining: 3.71s\n",
      "660:\tlearn: 49.1891930\ttotal: 7.21s\tremaining: 3.7s\n",
      "661:\tlearn: 49.1845603\ttotal: 7.22s\tremaining: 3.68s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662:\tlearn: 49.1766393\ttotal: 7.23s\tremaining: 3.67s\n",
      "663:\tlearn: 49.1731062\ttotal: 7.24s\tremaining: 3.66s\n",
      "664:\tlearn: 49.1639632\ttotal: 7.25s\tremaining: 3.65s\n",
      "665:\tlearn: 49.1530174\ttotal: 7.26s\tremaining: 3.64s\n",
      "666:\tlearn: 49.1487334\ttotal: 7.28s\tremaining: 3.63s\n",
      "667:\tlearn: 49.1458436\ttotal: 7.29s\tremaining: 3.62s\n",
      "668:\tlearn: 49.1318813\ttotal: 7.3s\tremaining: 3.61s\n",
      "669:\tlearn: 49.1298384\ttotal: 7.31s\tremaining: 3.6s\n",
      "670:\tlearn: 49.1231183\ttotal: 7.32s\tremaining: 3.59s\n",
      "671:\tlearn: 49.1176524\ttotal: 7.33s\tremaining: 3.58s\n",
      "672:\tlearn: 49.1128226\ttotal: 7.34s\tremaining: 3.57s\n",
      "673:\tlearn: 49.1062293\ttotal: 7.35s\tremaining: 3.56s\n",
      "674:\tlearn: 49.1011950\ttotal: 7.36s\tremaining: 3.54s\n",
      "675:\tlearn: 49.0962819\ttotal: 7.37s\tremaining: 3.53s\n",
      "676:\tlearn: 49.0879298\ttotal: 7.38s\tremaining: 3.52s\n",
      "677:\tlearn: 49.0832623\ttotal: 7.39s\tremaining: 3.51s\n",
      "678:\tlearn: 49.0784525\ttotal: 7.41s\tremaining: 3.5s\n",
      "679:\tlearn: 49.0752218\ttotal: 7.42s\tremaining: 3.49s\n",
      "680:\tlearn: 49.0695683\ttotal: 7.43s\tremaining: 3.48s\n",
      "681:\tlearn: 49.0666879\ttotal: 7.44s\tremaining: 3.47s\n",
      "682:\tlearn: 49.0575365\ttotal: 7.45s\tremaining: 3.46s\n",
      "683:\tlearn: 49.0512235\ttotal: 7.46s\tremaining: 3.45s\n",
      "684:\tlearn: 49.0446718\ttotal: 7.48s\tremaining: 3.44s\n",
      "685:\tlearn: 49.0392650\ttotal: 7.49s\tremaining: 3.43s\n",
      "686:\tlearn: 49.0254161\ttotal: 7.5s\tremaining: 3.42s\n",
      "687:\tlearn: 49.0203359\ttotal: 7.51s\tremaining: 3.41s\n",
      "688:\tlearn: 49.0134925\ttotal: 7.53s\tremaining: 3.4s\n",
      "689:\tlearn: 49.0101802\ttotal: 7.54s\tremaining: 3.38s\n",
      "690:\tlearn: 48.9973189\ttotal: 7.55s\tremaining: 3.38s\n",
      "691:\tlearn: 48.9885851\ttotal: 7.56s\tremaining: 3.37s\n",
      "692:\tlearn: 48.9809721\ttotal: 7.57s\tremaining: 3.35s\n",
      "693:\tlearn: 48.9767704\ttotal: 7.58s\tremaining: 3.34s\n",
      "694:\tlearn: 48.9738833\ttotal: 7.59s\tremaining: 3.33s\n",
      "695:\tlearn: 48.9593706\ttotal: 7.6s\tremaining: 3.32s\n",
      "696:\tlearn: 48.9535801\ttotal: 7.61s\tremaining: 3.31s\n",
      "697:\tlearn: 48.9519965\ttotal: 7.62s\tremaining: 3.3s\n",
      "698:\tlearn: 48.9492527\ttotal: 7.63s\tremaining: 3.29s\n",
      "699:\tlearn: 48.9458778\ttotal: 7.64s\tremaining: 3.27s\n",
      "700:\tlearn: 48.9427078\ttotal: 7.66s\tremaining: 3.27s\n",
      "701:\tlearn: 48.9406376\ttotal: 7.67s\tremaining: 3.25s\n",
      "702:\tlearn: 48.9345236\ttotal: 7.67s\tremaining: 3.24s\n",
      "703:\tlearn: 48.9194009\ttotal: 7.68s\tremaining: 3.23s\n",
      "704:\tlearn: 48.9163748\ttotal: 7.7s\tremaining: 3.22s\n",
      "705:\tlearn: 48.9088626\ttotal: 7.71s\tremaining: 3.21s\n",
      "706:\tlearn: 48.9039267\ttotal: 7.72s\tremaining: 3.2s\n",
      "707:\tlearn: 48.8972604\ttotal: 7.73s\tremaining: 3.19s\n",
      "708:\tlearn: 48.8940071\ttotal: 7.74s\tremaining: 3.18s\n",
      "709:\tlearn: 48.8905283\ttotal: 7.75s\tremaining: 3.17s\n",
      "710:\tlearn: 48.8846598\ttotal: 7.76s\tremaining: 3.15s\n",
      "711:\tlearn: 48.8812132\ttotal: 7.78s\tremaining: 3.15s\n",
      "712:\tlearn: 48.8759358\ttotal: 7.79s\tremaining: 3.13s\n",
      "713:\tlearn: 48.8714534\ttotal: 7.79s\tremaining: 3.12s\n",
      "714:\tlearn: 48.8680091\ttotal: 7.8s\tremaining: 3.11s\n",
      "715:\tlearn: 48.8622676\ttotal: 7.82s\tremaining: 3.1s\n",
      "716:\tlearn: 48.8596531\ttotal: 7.83s\tremaining: 3.09s\n",
      "717:\tlearn: 48.8563892\ttotal: 7.84s\tremaining: 3.08s\n",
      "718:\tlearn: 48.8536307\ttotal: 7.84s\tremaining: 3.07s\n",
      "719:\tlearn: 48.8513469\ttotal: 7.86s\tremaining: 3.06s\n",
      "720:\tlearn: 48.8456345\ttotal: 7.87s\tremaining: 3.04s\n",
      "721:\tlearn: 48.8331768\ttotal: 7.88s\tremaining: 3.03s\n",
      "722:\tlearn: 48.8275588\ttotal: 7.89s\tremaining: 3.02s\n",
      "723:\tlearn: 48.8170047\ttotal: 7.9s\tremaining: 3.01s\n",
      "724:\tlearn: 48.8127417\ttotal: 7.91s\tremaining: 3s\n",
      "725:\tlearn: 48.8098598\ttotal: 7.92s\tremaining: 2.99s\n",
      "726:\tlearn: 48.8067580\ttotal: 7.93s\tremaining: 2.98s\n",
      "727:\tlearn: 48.8017907\ttotal: 7.94s\tremaining: 2.97s\n",
      "728:\tlearn: 48.7965837\ttotal: 7.95s\tremaining: 2.96s\n",
      "729:\tlearn: 48.7880993\ttotal: 7.96s\tremaining: 2.94s\n",
      "730:\tlearn: 48.7847656\ttotal: 7.97s\tremaining: 2.93s\n",
      "731:\tlearn: 48.7779499\ttotal: 7.98s\tremaining: 2.92s\n",
      "732:\tlearn: 48.7738899\ttotal: 7.99s\tremaining: 2.91s\n",
      "733:\tlearn: 48.7693479\ttotal: 8s\tremaining: 2.9s\n",
      "734:\tlearn: 48.7627897\ttotal: 8.01s\tremaining: 2.89s\n",
      "735:\tlearn: 48.7576663\ttotal: 8.03s\tremaining: 2.88s\n",
      "736:\tlearn: 48.7544944\ttotal: 8.04s\tremaining: 2.87s\n",
      "737:\tlearn: 48.7481402\ttotal: 8.05s\tremaining: 2.86s\n",
      "738:\tlearn: 48.7366800\ttotal: 8.06s\tremaining: 2.85s\n",
      "739:\tlearn: 48.7338115\ttotal: 8.07s\tremaining: 2.84s\n",
      "740:\tlearn: 48.7298646\ttotal: 8.08s\tremaining: 2.83s\n",
      "741:\tlearn: 48.7259758\ttotal: 8.1s\tremaining: 2.81s\n",
      "742:\tlearn: 48.7130519\ttotal: 8.11s\tremaining: 2.8s\n",
      "743:\tlearn: 48.7088105\ttotal: 8.12s\tremaining: 2.79s\n",
      "744:\tlearn: 48.7054716\ttotal: 8.13s\tremaining: 2.78s\n",
      "745:\tlearn: 48.7021858\ttotal: 8.14s\tremaining: 2.77s\n",
      "746:\tlearn: 48.6976884\ttotal: 8.15s\tremaining: 2.76s\n",
      "747:\tlearn: 48.6957040\ttotal: 8.16s\tremaining: 2.75s\n",
      "748:\tlearn: 48.6877839\ttotal: 8.17s\tremaining: 2.74s\n",
      "749:\tlearn: 48.6837564\ttotal: 8.18s\tremaining: 2.73s\n",
      "750:\tlearn: 48.6752545\ttotal: 8.19s\tremaining: 2.71s\n",
      "751:\tlearn: 48.6721940\ttotal: 8.2s\tremaining: 2.7s\n",
      "752:\tlearn: 48.6631192\ttotal: 8.21s\tremaining: 2.69s\n",
      "753:\tlearn: 48.6579145\ttotal: 8.22s\tremaining: 2.68s\n",
      "754:\tlearn: 48.6532656\ttotal: 8.23s\tremaining: 2.67s\n",
      "755:\tlearn: 48.6451232\ttotal: 8.24s\tremaining: 2.66s\n",
      "756:\tlearn: 48.6428396\ttotal: 8.25s\tremaining: 2.65s\n",
      "757:\tlearn: 48.6400007\ttotal: 8.26s\tremaining: 2.64s\n",
      "758:\tlearn: 48.6286831\ttotal: 8.27s\tremaining: 2.63s\n",
      "759:\tlearn: 48.6239640\ttotal: 8.28s\tremaining: 2.61s\n",
      "760:\tlearn: 48.6202762\ttotal: 8.29s\tremaining: 2.6s\n",
      "761:\tlearn: 48.6032157\ttotal: 8.3s\tremaining: 2.59s\n",
      "762:\tlearn: 48.6003035\ttotal: 8.31s\tremaining: 2.58s\n",
      "763:\tlearn: 48.5959352\ttotal: 8.32s\tremaining: 2.57s\n",
      "764:\tlearn: 48.5919775\ttotal: 8.33s\tremaining: 2.56s\n",
      "765:\tlearn: 48.5855629\ttotal: 8.34s\tremaining: 2.55s\n",
      "766:\tlearn: 48.5825470\ttotal: 8.35s\tremaining: 2.54s\n",
      "767:\tlearn: 48.5764006\ttotal: 8.36s\tremaining: 2.53s\n",
      "768:\tlearn: 48.5733674\ttotal: 8.37s\tremaining: 2.52s\n",
      "769:\tlearn: 48.5558324\ttotal: 8.38s\tremaining: 2.5s\n",
      "770:\tlearn: 48.5427749\ttotal: 8.4s\tremaining: 2.49s\n",
      "771:\tlearn: 48.5345488\ttotal: 8.41s\tremaining: 2.48s\n",
      "772:\tlearn: 48.5312532\ttotal: 8.42s\tremaining: 2.47s\n",
      "773:\tlearn: 48.5200963\ttotal: 8.43s\tremaining: 2.46s\n",
      "774:\tlearn: 48.5028173\ttotal: 8.44s\tremaining: 2.45s\n",
      "775:\tlearn: 48.4901405\ttotal: 8.45s\tremaining: 2.44s\n",
      "776:\tlearn: 48.4869650\ttotal: 8.46s\tremaining: 2.43s\n",
      "777:\tlearn: 48.4798458\ttotal: 8.47s\tremaining: 2.42s\n",
      "778:\tlearn: 48.4718579\ttotal: 8.48s\tremaining: 2.41s\n",
      "779:\tlearn: 48.4624222\ttotal: 8.49s\tremaining: 2.4s\n",
      "780:\tlearn: 48.4572254\ttotal: 8.51s\tremaining: 2.38s\n",
      "781:\tlearn: 48.4533155\ttotal: 8.52s\tremaining: 2.37s\n",
      "782:\tlearn: 48.4503256\ttotal: 8.53s\tremaining: 2.36s\n",
      "783:\tlearn: 48.4463503\ttotal: 8.54s\tremaining: 2.35s\n",
      "784:\tlearn: 48.4414657\ttotal: 8.55s\tremaining: 2.34s\n",
      "785:\tlearn: 48.4389988\ttotal: 8.56s\tremaining: 2.33s\n",
      "786:\tlearn: 48.4233532\ttotal: 8.57s\tremaining: 2.32s\n",
      "787:\tlearn: 48.4127690\ttotal: 8.58s\tremaining: 2.31s\n",
      "788:\tlearn: 48.4099096\ttotal: 8.59s\tremaining: 2.3s\n",
      "789:\tlearn: 48.4044648\ttotal: 8.6s\tremaining: 2.29s\n",
      "790:\tlearn: 48.3975506\ttotal: 8.61s\tremaining: 2.27s\n",
      "791:\tlearn: 48.3885948\ttotal: 8.62s\tremaining: 2.26s\n",
      "792:\tlearn: 48.3834068\ttotal: 8.63s\tremaining: 2.25s\n",
      "793:\tlearn: 48.3777438\ttotal: 8.64s\tremaining: 2.24s\n",
      "794:\tlearn: 48.3746219\ttotal: 8.65s\tremaining: 2.23s\n",
      "795:\tlearn: 48.3689232\ttotal: 8.66s\tremaining: 2.22s\n",
      "796:\tlearn: 48.3618605\ttotal: 8.67s\tremaining: 2.21s\n",
      "797:\tlearn: 48.3587465\ttotal: 8.68s\tremaining: 2.2s\n",
      "798:\tlearn: 48.3532305\ttotal: 8.69s\tremaining: 2.19s\n",
      "799:\tlearn: 48.3503267\ttotal: 8.7s\tremaining: 2.17s\n",
      "800:\tlearn: 48.3446725\ttotal: 8.71s\tremaining: 2.16s\n",
      "801:\tlearn: 48.3374149\ttotal: 8.72s\tremaining: 2.15s\n",
      "802:\tlearn: 48.3301484\ttotal: 8.73s\tremaining: 2.14s\n",
      "803:\tlearn: 48.3104302\ttotal: 8.74s\tremaining: 2.13s\n",
      "804:\tlearn: 48.2948115\ttotal: 8.75s\tremaining: 2.12s\n",
      "805:\tlearn: 48.2933125\ttotal: 8.77s\tremaining: 2.11s\n",
      "806:\tlearn: 48.2847327\ttotal: 8.78s\tremaining: 2.1s\n",
      "807:\tlearn: 48.2782226\ttotal: 8.79s\tremaining: 2.09s\n",
      "808:\tlearn: 48.2738981\ttotal: 8.8s\tremaining: 2.08s\n",
      "809:\tlearn: 48.2494980\ttotal: 8.81s\tremaining: 2.07s\n",
      "810:\tlearn: 48.2391036\ttotal: 8.82s\tremaining: 2.06s\n",
      "811:\tlearn: 48.2344315\ttotal: 8.84s\tremaining: 2.04s\n",
      "812:\tlearn: 48.2315757\ttotal: 8.85s\tremaining: 2.03s\n",
      "813:\tlearn: 48.2281553\ttotal: 8.86s\tremaining: 2.02s\n",
      "814:\tlearn: 48.2253319\ttotal: 8.86s\tremaining: 2.01s\n",
      "815:\tlearn: 48.2205891\ttotal: 8.87s\tremaining: 2s\n",
      "816:\tlearn: 48.2133684\ttotal: 8.88s\tremaining: 1.99s\n",
      "817:\tlearn: 48.2088603\ttotal: 8.9s\tremaining: 1.98s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "818:\tlearn: 48.1978753\ttotal: 8.91s\tremaining: 1.97s\n",
      "819:\tlearn: 48.1917152\ttotal: 8.92s\tremaining: 1.96s\n",
      "820:\tlearn: 48.1893198\ttotal: 8.94s\tremaining: 1.95s\n",
      "821:\tlearn: 48.1834461\ttotal: 8.95s\tremaining: 1.94s\n",
      "822:\tlearn: 48.1810201\ttotal: 8.96s\tremaining: 1.93s\n",
      "823:\tlearn: 48.1803629\ttotal: 8.97s\tremaining: 1.92s\n",
      "824:\tlearn: 48.1678495\ttotal: 8.98s\tremaining: 1.9s\n",
      "825:\tlearn: 48.1648109\ttotal: 8.99s\tremaining: 1.89s\n",
      "826:\tlearn: 48.1616691\ttotal: 9s\tremaining: 1.88s\n",
      "827:\tlearn: 48.1568568\ttotal: 9.02s\tremaining: 1.87s\n",
      "828:\tlearn: 48.1512388\ttotal: 9.03s\tremaining: 1.86s\n",
      "829:\tlearn: 48.1487437\ttotal: 9.04s\tremaining: 1.85s\n",
      "830:\tlearn: 48.1438537\ttotal: 9.05s\tremaining: 1.84s\n",
      "831:\tlearn: 48.1361071\ttotal: 9.06s\tremaining: 1.83s\n",
      "832:\tlearn: 48.1231385\ttotal: 9.07s\tremaining: 1.82s\n",
      "833:\tlearn: 48.1075641\ttotal: 9.08s\tremaining: 1.81s\n",
      "834:\tlearn: 48.1031789\ttotal: 9.1s\tremaining: 1.8s\n",
      "835:\tlearn: 48.0979748\ttotal: 9.11s\tremaining: 1.79s\n",
      "836:\tlearn: 48.0964158\ttotal: 9.12s\tremaining: 1.77s\n",
      "837:\tlearn: 48.0941318\ttotal: 9.13s\tremaining: 1.76s\n",
      "838:\tlearn: 48.0887688\ttotal: 9.14s\tremaining: 1.75s\n",
      "839:\tlearn: 48.0839267\ttotal: 9.15s\tremaining: 1.74s\n",
      "840:\tlearn: 48.0808609\ttotal: 9.16s\tremaining: 1.73s\n",
      "841:\tlearn: 48.0711820\ttotal: 9.17s\tremaining: 1.72s\n",
      "842:\tlearn: 48.0660664\ttotal: 9.18s\tremaining: 1.71s\n",
      "843:\tlearn: 48.0556420\ttotal: 9.19s\tremaining: 1.7s\n",
      "844:\tlearn: 48.0498930\ttotal: 9.2s\tremaining: 1.69s\n",
      "845:\tlearn: 48.0464001\ttotal: 9.21s\tremaining: 1.68s\n",
      "846:\tlearn: 48.0436145\ttotal: 9.22s\tremaining: 1.67s\n",
      "847:\tlearn: 48.0392785\ttotal: 9.23s\tremaining: 1.66s\n",
      "848:\tlearn: 48.0328933\ttotal: 9.24s\tremaining: 1.64s\n",
      "849:\tlearn: 48.0289905\ttotal: 9.25s\tremaining: 1.63s\n",
      "850:\tlearn: 48.0241132\ttotal: 9.26s\tremaining: 1.62s\n",
      "851:\tlearn: 48.0073305\ttotal: 9.28s\tremaining: 1.61s\n",
      "852:\tlearn: 48.0026849\ttotal: 9.29s\tremaining: 1.6s\n",
      "853:\tlearn: 47.9890967\ttotal: 9.3s\tremaining: 1.59s\n",
      "854:\tlearn: 47.9852827\ttotal: 9.31s\tremaining: 1.58s\n",
      "855:\tlearn: 47.9826314\ttotal: 9.32s\tremaining: 1.57s\n",
      "856:\tlearn: 47.9792357\ttotal: 9.33s\tremaining: 1.56s\n",
      "857:\tlearn: 47.9691045\ttotal: 9.35s\tremaining: 1.55s\n",
      "858:\tlearn: 47.9659161\ttotal: 9.36s\tremaining: 1.53s\n",
      "859:\tlearn: 47.9579076\ttotal: 9.37s\tremaining: 1.52s\n",
      "860:\tlearn: 47.9453959\ttotal: 9.38s\tremaining: 1.51s\n",
      "861:\tlearn: 47.9377056\ttotal: 9.39s\tremaining: 1.5s\n",
      "862:\tlearn: 47.9298874\ttotal: 9.4s\tremaining: 1.49s\n",
      "863:\tlearn: 47.9239079\ttotal: 9.41s\tremaining: 1.48s\n",
      "864:\tlearn: 47.9194697\ttotal: 9.42s\tremaining: 1.47s\n",
      "865:\tlearn: 47.9165573\ttotal: 9.43s\tremaining: 1.46s\n",
      "866:\tlearn: 47.9006665\ttotal: 9.44s\tremaining: 1.45s\n",
      "867:\tlearn: 47.8991844\ttotal: 9.45s\tremaining: 1.44s\n",
      "868:\tlearn: 47.8982316\ttotal: 9.46s\tremaining: 1.43s\n",
      "869:\tlearn: 47.8917284\ttotal: 9.47s\tremaining: 1.42s\n",
      "870:\tlearn: 47.8806029\ttotal: 9.48s\tremaining: 1.4s\n",
      "871:\tlearn: 47.8683980\ttotal: 9.5s\tremaining: 1.39s\n",
      "872:\tlearn: 47.8653352\ttotal: 9.51s\tremaining: 1.38s\n",
      "873:\tlearn: 47.8555166\ttotal: 9.52s\tremaining: 1.37s\n",
      "874:\tlearn: 47.8511055\ttotal: 9.53s\tremaining: 1.36s\n",
      "875:\tlearn: 47.8273748\ttotal: 9.55s\tremaining: 1.35s\n",
      "876:\tlearn: 47.8212745\ttotal: 9.56s\tremaining: 1.34s\n",
      "877:\tlearn: 47.8188830\ttotal: 9.57s\tremaining: 1.33s\n",
      "878:\tlearn: 47.8146242\ttotal: 9.58s\tremaining: 1.32s\n",
      "879:\tlearn: 47.8127024\ttotal: 9.59s\tremaining: 1.31s\n",
      "880:\tlearn: 47.8105910\ttotal: 9.6s\tremaining: 1.3s\n",
      "881:\tlearn: 47.8066475\ttotal: 9.62s\tremaining: 1.29s\n",
      "882:\tlearn: 47.8048151\ttotal: 9.63s\tremaining: 1.27s\n",
      "883:\tlearn: 47.8022899\ttotal: 9.64s\tremaining: 1.26s\n",
      "884:\tlearn: 47.7877507\ttotal: 9.65s\tremaining: 1.25s\n",
      "885:\tlearn: 47.7851323\ttotal: 9.66s\tremaining: 1.24s\n",
      "886:\tlearn: 47.7709151\ttotal: 9.68s\tremaining: 1.23s\n",
      "887:\tlearn: 47.7692267\ttotal: 9.69s\tremaining: 1.22s\n",
      "888:\tlearn: 47.7509814\ttotal: 9.7s\tremaining: 1.21s\n",
      "889:\tlearn: 47.7488029\ttotal: 9.71s\tremaining: 1.2s\n",
      "890:\tlearn: 47.7429205\ttotal: 9.72s\tremaining: 1.19s\n",
      "891:\tlearn: 47.7383710\ttotal: 9.73s\tremaining: 1.18s\n",
      "892:\tlearn: 47.7358737\ttotal: 9.74s\tremaining: 1.17s\n",
      "893:\tlearn: 47.7270887\ttotal: 9.76s\tremaining: 1.16s\n",
      "894:\tlearn: 47.7190756\ttotal: 9.77s\tremaining: 1.15s\n",
      "895:\tlearn: 47.7155411\ttotal: 9.78s\tremaining: 1.13s\n",
      "896:\tlearn: 47.7021271\ttotal: 9.79s\tremaining: 1.12s\n",
      "897:\tlearn: 47.6980286\ttotal: 9.8s\tremaining: 1.11s\n",
      "898:\tlearn: 47.6878712\ttotal: 9.81s\tremaining: 1.1s\n",
      "899:\tlearn: 47.6812687\ttotal: 9.82s\tremaining: 1.09s\n",
      "900:\tlearn: 47.6765175\ttotal: 9.83s\tremaining: 1.08s\n",
      "901:\tlearn: 47.6747632\ttotal: 9.84s\tremaining: 1.07s\n",
      "902:\tlearn: 47.6645456\ttotal: 9.85s\tremaining: 1.06s\n",
      "903:\tlearn: 47.6624756\ttotal: 9.86s\tremaining: 1.05s\n",
      "904:\tlearn: 47.6563523\ttotal: 9.87s\tremaining: 1.04s\n",
      "905:\tlearn: 47.6400396\ttotal: 9.88s\tremaining: 1.02s\n",
      "906:\tlearn: 47.6373959\ttotal: 9.89s\tremaining: 1.01s\n",
      "907:\tlearn: 47.6304602\ttotal: 9.9s\tremaining: 1s\n",
      "908:\tlearn: 47.6267233\ttotal: 9.91s\tremaining: 993ms\n",
      "909:\tlearn: 47.6213896\ttotal: 9.93s\tremaining: 982ms\n",
      "910:\tlearn: 47.6191905\ttotal: 9.94s\tremaining: 971ms\n",
      "911:\tlearn: 47.6043548\ttotal: 9.95s\tremaining: 960ms\n",
      "912:\tlearn: 47.5982963\ttotal: 9.96s\tremaining: 949ms\n",
      "913:\tlearn: 47.5881668\ttotal: 9.97s\tremaining: 938ms\n",
      "914:\tlearn: 47.5824723\ttotal: 9.98s\tremaining: 928ms\n",
      "915:\tlearn: 47.5730811\ttotal: 10s\tremaining: 917ms\n",
      "916:\tlearn: 47.5692149\ttotal: 10s\tremaining: 906ms\n",
      "917:\tlearn: 47.5638103\ttotal: 10s\tremaining: 895ms\n",
      "918:\tlearn: 47.5543544\ttotal: 10s\tremaining: 885ms\n",
      "919:\tlearn: 47.5497098\ttotal: 10s\tremaining: 874ms\n",
      "920:\tlearn: 47.5345138\ttotal: 10.1s\tremaining: 863ms\n",
      "921:\tlearn: 47.5321229\ttotal: 10.1s\tremaining: 852ms\n",
      "922:\tlearn: 47.5300869\ttotal: 10.1s\tremaining: 841ms\n",
      "923:\tlearn: 47.5203552\ttotal: 10.1s\tremaining: 831ms\n",
      "924:\tlearn: 47.5070086\ttotal: 10.1s\tremaining: 820ms\n",
      "925:\tlearn: 47.5049095\ttotal: 10.1s\tremaining: 809ms\n",
      "926:\tlearn: 47.5000973\ttotal: 10.1s\tremaining: 798ms\n",
      "927:\tlearn: 47.4978144\ttotal: 10.1s\tremaining: 787ms\n",
      "928:\tlearn: 47.4953500\ttotal: 10.2s\tremaining: 777ms\n",
      "929:\tlearn: 47.4852508\ttotal: 10.2s\tremaining: 766ms\n",
      "930:\tlearn: 47.4781240\ttotal: 10.2s\tremaining: 755ms\n",
      "931:\tlearn: 47.4674582\ttotal: 10.2s\tremaining: 744ms\n",
      "932:\tlearn: 47.4613231\ttotal: 10.2s\tremaining: 733ms\n",
      "933:\tlearn: 47.4550025\ttotal: 10.2s\tremaining: 722ms\n",
      "934:\tlearn: 47.4503757\ttotal: 10.2s\tremaining: 711ms\n",
      "935:\tlearn: 47.4455061\ttotal: 10.2s\tremaining: 700ms\n",
      "936:\tlearn: 47.4400855\ttotal: 10.3s\tremaining: 690ms\n",
      "937:\tlearn: 47.4321472\ttotal: 10.3s\tremaining: 679ms\n",
      "938:\tlearn: 47.4293685\ttotal: 10.3s\tremaining: 668ms\n",
      "939:\tlearn: 47.4250043\ttotal: 10.3s\tremaining: 657ms\n",
      "940:\tlearn: 47.4105186\ttotal: 10.3s\tremaining: 646ms\n",
      "941:\tlearn: 47.4032296\ttotal: 10.3s\tremaining: 635ms\n",
      "942:\tlearn: 47.3981647\ttotal: 10.3s\tremaining: 624ms\n",
      "943:\tlearn: 47.3938803\ttotal: 10.3s\tremaining: 613ms\n",
      "944:\tlearn: 47.3892407\ttotal: 10.3s\tremaining: 602ms\n",
      "945:\tlearn: 47.3821479\ttotal: 10.4s\tremaining: 591ms\n",
      "946:\tlearn: 47.3780601\ttotal: 10.4s\tremaining: 580ms\n",
      "947:\tlearn: 47.3752140\ttotal: 10.4s\tremaining: 569ms\n",
      "948:\tlearn: 47.3621107\ttotal: 10.4s\tremaining: 558ms\n",
      "949:\tlearn: 47.3442122\ttotal: 10.4s\tremaining: 547ms\n",
      "950:\tlearn: 47.3422336\ttotal: 10.4s\tremaining: 536ms\n",
      "951:\tlearn: 47.3378409\ttotal: 10.4s\tremaining: 526ms\n",
      "952:\tlearn: 47.3316489\ttotal: 10.4s\tremaining: 515ms\n",
      "953:\tlearn: 47.3261460\ttotal: 10.4s\tremaining: 504ms\n",
      "954:\tlearn: 47.3214769\ttotal: 10.5s\tremaining: 493ms\n",
      "955:\tlearn: 47.3171495\ttotal: 10.5s\tremaining: 482ms\n",
      "956:\tlearn: 47.3138152\ttotal: 10.5s\tremaining: 471ms\n",
      "957:\tlearn: 47.3097603\ttotal: 10.5s\tremaining: 460ms\n",
      "958:\tlearn: 47.3036526\ttotal: 10.5s\tremaining: 449ms\n",
      "959:\tlearn: 47.2988817\ttotal: 10.5s\tremaining: 438ms\n",
      "960:\tlearn: 47.2961554\ttotal: 10.5s\tremaining: 427ms\n",
      "961:\tlearn: 47.2947953\ttotal: 10.5s\tremaining: 416ms\n",
      "962:\tlearn: 47.2895424\ttotal: 10.5s\tremaining: 405ms\n",
      "963:\tlearn: 47.2858902\ttotal: 10.6s\tremaining: 394ms\n",
      "964:\tlearn: 47.2808163\ttotal: 10.6s\tremaining: 383ms\n",
      "965:\tlearn: 47.2769142\ttotal: 10.6s\tremaining: 372ms\n",
      "966:\tlearn: 47.2715645\ttotal: 10.6s\tremaining: 361ms\n",
      "967:\tlearn: 47.2693361\ttotal: 10.6s\tremaining: 350ms\n",
      "968:\tlearn: 47.2616367\ttotal: 10.6s\tremaining: 339ms\n",
      "969:\tlearn: 47.2579927\ttotal: 10.6s\tremaining: 329ms\n",
      "970:\tlearn: 47.2538179\ttotal: 10.6s\tremaining: 318ms\n",
      "971:\tlearn: 47.2451630\ttotal: 10.6s\tremaining: 307ms\n",
      "972:\tlearn: 47.2382039\ttotal: 10.7s\tremaining: 296ms\n",
      "973:\tlearn: 47.2342937\ttotal: 10.7s\tremaining: 285ms\n",
      "974:\tlearn: 47.2268825\ttotal: 10.7s\tremaining: 274ms\n",
      "975:\tlearn: 47.2228320\ttotal: 10.7s\tremaining: 263ms\n",
      "976:\tlearn: 47.2176408\ttotal: 10.7s\tremaining: 252ms\n",
      "977:\tlearn: 47.2131550\ttotal: 10.7s\tremaining: 241ms\n",
      "978:\tlearn: 47.2094419\ttotal: 10.7s\tremaining: 230ms\n",
      "979:\tlearn: 47.2072609\ttotal: 10.7s\tremaining: 219ms\n",
      "980:\tlearn: 47.2016410\ttotal: 10.7s\tremaining: 208ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981:\tlearn: 47.1984726\ttotal: 10.7s\tremaining: 197ms\n",
      "982:\tlearn: 47.1960587\ttotal: 10.8s\tremaining: 186ms\n",
      "983:\tlearn: 47.1920144\ttotal: 10.8s\tremaining: 175ms\n",
      "984:\tlearn: 47.1864208\ttotal: 10.8s\tremaining: 164ms\n",
      "985:\tlearn: 47.1837903\ttotal: 10.8s\tremaining: 153ms\n",
      "986:\tlearn: 47.1794686\ttotal: 10.8s\tremaining: 142ms\n",
      "987:\tlearn: 47.1723148\ttotal: 10.8s\tremaining: 131ms\n",
      "988:\tlearn: 47.1672902\ttotal: 10.8s\tremaining: 120ms\n",
      "989:\tlearn: 47.1610324\ttotal: 10.8s\tremaining: 109ms\n",
      "990:\tlearn: 47.1559932\ttotal: 10.8s\tremaining: 98.4ms\n",
      "991:\tlearn: 47.1437113\ttotal: 10.8s\tremaining: 87.5ms\n",
      "992:\tlearn: 47.1356095\ttotal: 10.9s\tremaining: 76.5ms\n",
      "993:\tlearn: 47.1308115\ttotal: 10.9s\tremaining: 65.6ms\n",
      "994:\tlearn: 47.1252259\ttotal: 10.9s\tremaining: 54.7ms\n",
      "995:\tlearn: 47.1243893\ttotal: 10.9s\tremaining: 43.7ms\n",
      "996:\tlearn: 47.1164225\ttotal: 10.9s\tremaining: 32.8ms\n",
      "997:\tlearn: 47.1052138\ttotal: 10.9s\tremaining: 21.9ms\n",
      "998:\tlearn: 47.1002928\ttotal: 10.9s\tremaining: 10.9ms\n",
      "999:\tlearn: 47.0957117\ttotal: 10.9s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Creating and fitting the CatBoostRegressor model\n",
    "catboost_model = CatBoostRegressor()\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = catboost_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f29dc1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 6.859614521529677\n",
      "Mean Squared Error (MSE): 2710.4201313594963\n",
      "Root Mean Squared Error (RMSE): 52.061695433010016\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.610699553834968\n",
      "R-squared (R2 score): 0.013784018206228765\n",
      "Adjusted R-squared: 0.013634260259590136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    mask = (y_true > 0) & (y_pred > 0)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0:  # If all values are non-positive, handle this case\n",
    "        return 0  # Return a default value or handle it as needed\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ae1b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Creating and fitting the XGBoost Regressor model\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6e2bed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 8.087697415762593\n",
      "Mean Squared Error (MSE): 2909.3371650689746\n",
      "Root Mean Squared Error (RMSE): 53.93827180276519\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.610699553834968\n",
      "R-squared (R2 score): -0.058594118092847536\n",
      "Adjusted R-squared: -0.05875486673652808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    mask = (y_true > 0) & (y_pred > 0)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0:  # If all values are non-positive, handle this case\n",
    "        return 0  # Return a default value or handle it as needed\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58b73da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to sanitize feature names\n",
    "def sanitize_feature_names(feature_names):\n",
    "    sanitized_names = []\n",
    "    for name in feature_names:\n",
    "        # Replace non-alphanumeric characters with underscores\n",
    "        sanitized = re.sub(r'\\W+', '_', name)\n",
    "        # Ensure the name doesn't start with a number\n",
    "        if re.match(r'^\\d', sanitized):\n",
    "            sanitized = '_' + sanitized\n",
    "        sanitized_names.append(sanitized)\n",
    "    return sanitized_names\n",
    "\n",
    "# Sanitize feature names\n",
    "X_train.columns = sanitize_feature_names(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc895409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2179\n",
      "[LightGBM] [Info] Number of data points in the train set: 172893, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 15.981220\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Creating and fitting the LGBM Regressor model\n",
    "lgbm_model = LGBMRegressor()\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = lgbm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85446335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 6.92640985276173\n",
      "Mean Squared Error (MSE): 2673.4719732239137\n",
      "Root Mean Squared Error (RMSE): 51.70562806140076\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.610699553834968\n",
      "R-squared (R2 score): 0.027228009279626653\n",
      "Adjusted R-squared: 0.027080292817343365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    mask = (y_true > 0) & (y_pred > 0)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0:  # If all values are non-positive, handle this case\n",
    "        return 0  # Return a default value or handle it as needed\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d13f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Set of Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "faa3a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial Regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Creating polynomial features\n",
    "poly_degree = 3  # Define the degree of the polynomial\n",
    "poly = PolynomialFeatures(degree=poly_degree)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Creating and fitting the Polynomial Regression model\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "y_pred = poly_model.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca7ae1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.094998650531448\n",
      "Mean Squared Error (MSE): 2670.1998697124054\n",
      "Root Mean Squared Error (RMSE): 51.67397671664535\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5366923449365429\n",
      "R-squared (R2 score): 0.02841859989685125\n",
      "Adjusted R-squared: 0.028271064227020526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05068b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_model = Ridge(alpha=1.0)  # You can adjust the alpha (regularization strength) as needed\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred = ridge_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50716411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.804344482574467\n",
      "Mean Squared Error (MSE): 2675.700152475208\n",
      "Root Mean Squared Error (RMSE): 51.72717035055376\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.61027007221064\n",
      "R-squared (R2 score): 0.02641726191153293\n",
      "Adjusted R-squared: 0.02626942233639873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32aab803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principal Components Regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming X_train and X_test are your feature matrices, and y_train is the target variable\n",
    "\n",
    "# Step 1: Scale the data (recommended before applying PCA)\n",
    "# (You can use other scaling methods like StandardScaler or MinMaxScaler as needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 2: Perform PCA and then fit the model\n",
    "n_components = 10  # Number of components (you can change this number)\n",
    "pca = PCA(n_components=n_components)\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "# Create a pipeline to chain PCA and Linear Regression\n",
    "pipeline = make_pipeline(pca, linear_regression)\n",
    "\n",
    "# Fit the model using the pipeline\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict using the test data\n",
    "y_pred = pipeline.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f41e3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 9.111365764299718\n",
      "Mean Squared Error (MSE): 2708.675429757844\n",
      "Root Mean Squared Error (RMSE): 52.04493663900307\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.7065615577567538\n",
      "R-squared (R2 score): 0.014418846948497377\n",
      "Adjusted R-squared: 0.014269185401278972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b9d3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Alpha (regularization strength) needs to be set. This is a hyperparameter that can be tuned.\n",
    "alpha = 0.1  # You can change the value of alpha as needed\n",
    "\n",
    "lasso_model = Lasso(alpha=alpha)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_pred = lasso_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ba0cd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.815911319705638\n",
      "Mean Squared Error (MSE): 2675.183428688301\n",
      "Root Mean Squared Error (RMSE): 51.72217540560626\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.6169997802734023\n",
      "R-squared (R2 score): 0.026605277507685376\n",
      "Adjusted R-squared: 0.026457466482919578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6718baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordinal Regression\n",
    "from mord import LogisticIT\n",
    "import pandas as pd\n",
    "\n",
    "num_classes = 10  # You can change this based on your data or required number of classes\n",
    "y_train_ordinal = pd.qcut(y_train, q=num_classes, labels=False)\n",
    "\n",
    "ordinal_model = LogisticIT()\n",
    "ordinal_model.fit(X_train, y_train_ordinal)\n",
    "y_pred = ordinal_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfa7ae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 11.562952316365882\n",
      "Mean Squared Error (MSE): 2847.0605079101592\n",
      "Root Mean Squared Error (RMSE): 53.3578532918085\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 1.4556237948972461\n",
      "R-squared (R2 score): -0.03593407588311481\n",
      "Adjusted R-squared: -0.036091383575264535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9399af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poisson Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming X_train and y_train are your training data\n",
    "poisson_model = sm.GLM(y_train, X_train, family=sm.families.Poisson())\n",
    "poisson_results = poisson_model.fit()\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = poisson_results.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "604a2d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 9.227725117109808\n",
      "Mean Squared Error (MSE): 2458.9904739015637\n",
      "Root Mean Squared Error (RMSE): 49.588209020911044\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.726636353790708\n",
      "R-squared (R2 score): -0.0012126083564607537\n",
      "Adjusted R-squared: -0.0014406784733242972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7ba124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative Binomial Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming X_train and y_train are your training features and target respectively\n",
    "\n",
    "# Fit the Negative Binomial Regression model\n",
    "nb_model = sm.GLM(y_train, X_train, family=sm.families.NegativeBinomial())\n",
    "nb_result = nb_model.fit()\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred = nb_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fc3447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 27.194619285835834\n",
      "Mean Squared Error (MSE): 24865282.805341423\n",
      "Root Mean Squared Error (RMSE): 4986.510082747394\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.6075733376970922\n",
      "R-squared (R2 score): -9046.504853850653\n",
      "Adjusted R-squared: -9047.87872709356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "217c5d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  trip_distance                  with p-value 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  longitude_difference           with p-value 1.84136e-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  passenger_count                with p-value 1.43309e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  dropoff_latitude               with p-value 3.01244e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  pickup_month                   with p-value 2.98504e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  pickup_hour                    with p-value 0.00025549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  pickup_longitude               with p-value 0.000401285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  dropoff_longitude              with p-value 1.52899e-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    }
   ],
   "source": [
    "#Stepwise regression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "# Assuming X_train and y_train are your training data\n",
    "selected_features = stepwise_selection(X_train, y_train)\n",
    "\n",
    "# After obtaining selected features, fit the model using sklearn LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train[selected_features], y_train)\n",
    "y_pred = lr_model.predict(X_test[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4de985eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.797187434539566\n",
      "Mean Squared Error (MSE): 2675.6469071901774\n",
      "Root Mean Squared Error (RMSE): 51.726655673745014\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.6100487754034959\n",
      "R-squared (R2 score): 0.026436635790307417\n",
      "Adjusted R-squared: 0.02628879915711735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d231ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regression \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create a DecisionTreeRegressor model\n",
    "dt_model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the model with training data\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69618117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 9.422775995222526\n",
      "Mean Squared Error (MSE): 6516.048118870006\n",
      "Root Mean Squared Error (RMSE): 80.72204233584533\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5388496103270305\n",
      "R-squared (R2 score): -1.3709353094804388\n",
      "Adjusted R-squared: -1.3712953385309872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1b38889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48780ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.586221443970971\n",
      "Mean Squared Error (MSE): 2851.6000535400867\n",
      "Root Mean Squared Error (RMSE): 53.400375031829945\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5336992640538137\n",
      "R-squared (R2 score): -0.03758583916457736\n",
      "Adjusted R-squared: -0.0377433976787398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2580f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Nearest Neighbors Regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Create a K-Nearest Neighbors Regression model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)  # You can set the number of neighbors (K) as needed\n",
    "\n",
    "# Fit the KNN model with the training data\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the KNN model\n",
    "y_pred = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de3b166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 12.022431855218276\n",
      "Mean Squared Error (MSE): 3379.014274927377\n",
      "Root Mean Squared Error (RMSE): 58.12928930347744\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.7979456993218852\n",
      "R-squared (R2 score): -0.2294912667178215\n",
      "Adjusted R-squared: -0.22967796627543646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75233cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Robust Regression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a RANSACRegressor model\n",
    "ransac_model = RANSACRegressor(base_estimator=LinearRegression(), random_state=0)\n",
    "\n",
    "# Fit the RANSAC model to the training data\n",
    "ransac_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = ransac_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f6af38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.159265763473354\n",
      "Mean Squared Error (MSE): 2433.542668257963\n",
      "Root Mean Squared Error (RMSE): 49.330950409027835\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5311687787931472\n",
      "R-squared (R2 score): 0.009148824164646685\n",
      "Adjusted R-squared: 0.008923114318824643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17252\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f00e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199425ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
