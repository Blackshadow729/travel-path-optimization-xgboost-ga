{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2526d73b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_21712\\3203916033.py:4: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sample_df = pd.read_csv(url)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id1080784</td>\n",
       "      <td>2</td>\n",
       "      <td>29-02-2016 16:40</td>\n",
       "      <td>29-02-2016 16:47</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.953918</td>\n",
       "      <td>40.778873</td>\n",
       "      <td>-73.963875</td>\n",
       "      <td>40.771164</td>\n",
       "      <td>N</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id0889885</td>\n",
       "      <td>1</td>\n",
       "      <td>11-03-2016 23:35</td>\n",
       "      <td>11-03-2016 23:53</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.988312</td>\n",
       "      <td>40.731743</td>\n",
       "      <td>-73.994751</td>\n",
       "      <td>40.694931</td>\n",
       "      <td>N</td>\n",
       "      <td>1100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id0857912</td>\n",
       "      <td>2</td>\n",
       "      <td>21-02-2016 17:59</td>\n",
       "      <td>21-02-2016 18:26</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.997314</td>\n",
       "      <td>40.721458</td>\n",
       "      <td>-73.948029</td>\n",
       "      <td>40.774918</td>\n",
       "      <td>N</td>\n",
       "      <td>1635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3744273</td>\n",
       "      <td>2</td>\n",
       "      <td>05-01-2016 9:44</td>\n",
       "      <td>05-01-2016 10:03</td>\n",
       "      <td>6</td>\n",
       "      <td>-73.961670</td>\n",
       "      <td>40.759720</td>\n",
       "      <td>-73.956779</td>\n",
       "      <td>40.780628</td>\n",
       "      <td>N</td>\n",
       "      <td>1141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id0232939</td>\n",
       "      <td>1</td>\n",
       "      <td>17-02-2016 6:42</td>\n",
       "      <td>17-02-2016 6:56</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.017120</td>\n",
       "      <td>40.708469</td>\n",
       "      <td>-73.988182</td>\n",
       "      <td>40.740631</td>\n",
       "      <td>N</td>\n",
       "      <td>848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729317</th>\n",
       "      <td>id3905982</td>\n",
       "      <td>2</td>\n",
       "      <td>21-05-2016 13:29</td>\n",
       "      <td>21-05-2016 13:34</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.965919</td>\n",
       "      <td>40.789780</td>\n",
       "      <td>-73.952637</td>\n",
       "      <td>40.789181</td>\n",
       "      <td>N</td>\n",
       "      <td>296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729318</th>\n",
       "      <td>id0102861</td>\n",
       "      <td>1</td>\n",
       "      <td>22-02-2016 0:43</td>\n",
       "      <td>22-02-2016 0:48</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.996666</td>\n",
       "      <td>40.737434</td>\n",
       "      <td>-74.001320</td>\n",
       "      <td>40.731911</td>\n",
       "      <td>N</td>\n",
       "      <td>315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729319</th>\n",
       "      <td>id0439699</td>\n",
       "      <td>1</td>\n",
       "      <td>15-04-2016 18:56</td>\n",
       "      <td>15-04-2016 19:08</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.997849</td>\n",
       "      <td>40.761696</td>\n",
       "      <td>-74.001488</td>\n",
       "      <td>40.741207</td>\n",
       "      <td>N</td>\n",
       "      <td>673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729320</th>\n",
       "      <td>id2078912</td>\n",
       "      <td>1</td>\n",
       "      <td>19-06-2016 9:50</td>\n",
       "      <td>19-06-2016 9:58</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.006706</td>\n",
       "      <td>40.708244</td>\n",
       "      <td>-74.013550</td>\n",
       "      <td>40.713814</td>\n",
       "      <td>N</td>\n",
       "      <td>447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729321</th>\n",
       "      <td>id1053441</td>\n",
       "      <td>2</td>\n",
       "      <td>01-01-2016 17:24</td>\n",
       "      <td>01-01-2016 17:44</td>\n",
       "      <td>4</td>\n",
       "      <td>-74.003342</td>\n",
       "      <td>40.743839</td>\n",
       "      <td>-73.945847</td>\n",
       "      <td>40.712841</td>\n",
       "      <td>N</td>\n",
       "      <td>1224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729322 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  vendor_id   pickup_datetime  dropoff_datetime  \\\n",
       "0       id1080784          2  29-02-2016 16:40  29-02-2016 16:47   \n",
       "1       id0889885          1  11-03-2016 23:35  11-03-2016 23:53   \n",
       "2       id0857912          2  21-02-2016 17:59  21-02-2016 18:26   \n",
       "3       id3744273          2   05-01-2016 9:44  05-01-2016 10:03   \n",
       "4       id0232939          1   17-02-2016 6:42   17-02-2016 6:56   \n",
       "...           ...        ...               ...               ...   \n",
       "729317  id3905982          2  21-05-2016 13:29  21-05-2016 13:34   \n",
       "729318  id0102861          1   22-02-2016 0:43   22-02-2016 0:48   \n",
       "729319  id0439699          1  15-04-2016 18:56  15-04-2016 19:08   \n",
       "729320  id2078912          1   19-06-2016 9:50   19-06-2016 9:58   \n",
       "729321  id1053441          2  01-01-2016 17:24  01-01-2016 17:44   \n",
       "\n",
       "        passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                     1        -73.953918        40.778873         -73.963875   \n",
       "1                     2        -73.988312        40.731743         -73.994751   \n",
       "2                     2        -73.997314        40.721458         -73.948029   \n",
       "3                     6        -73.961670        40.759720         -73.956779   \n",
       "4                     1        -74.017120        40.708469         -73.988182   \n",
       "...                 ...               ...              ...                ...   \n",
       "729317                2        -73.965919        40.789780         -73.952637   \n",
       "729318                1        -73.996666        40.737434         -74.001320   \n",
       "729319                1        -73.997849        40.761696         -74.001488   \n",
       "729320                1        -74.006706        40.708244         -74.013550   \n",
       "729321                4        -74.003342        40.743839         -73.945847   \n",
       "\n",
       "        dropoff_latitude store_and_fwd_flag  trip_duration  Unnamed: 11  \\\n",
       "0              40.771164                  N            400          NaN   \n",
       "1              40.694931                  N           1100          NaN   \n",
       "2              40.774918                  N           1635          NaN   \n",
       "3              40.780628                  N           1141          NaN   \n",
       "4              40.740631                  N            848          NaN   \n",
       "...                  ...                ...            ...          ...   \n",
       "729317         40.789181                  N            296          NaN   \n",
       "729318         40.731911                  N            315          NaN   \n",
       "729319         40.741207                  N            673          NaN   \n",
       "729320         40.713814                  N            447          NaN   \n",
       "729321         40.712841                  N           1224          NaN   \n",
       "\n",
       "       Unnamed: 12  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "...            ...  \n",
       "729317         NaN  \n",
       "729318         NaN  \n",
       "729319         NaN  \n",
       "729320         NaN  \n",
       "729321         NaN  \n",
       "\n",
       "[729322 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "url = 'nyc_taxi_trip_duration.csv'\n",
    "sample_df = pd.read_csv(url)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbfa8fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>pickup_month</th>\n",
       "      <th>pickup_day</th>\n",
       "      <th>pickup_weekday</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>latitude_difference</th>\n",
       "      <th>longitude_difference</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id1080784</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-29 16:40:00</td>\n",
       "      <td>2016-02-29 16:47:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.953918</td>\n",
       "      <td>40.778873</td>\n",
       "      <td>-73.963875</td>\n",
       "      <td>40.771164</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.007709</td>\n",
       "      <td>-0.009956</td>\n",
       "      <td>1.220593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id0889885</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-11 23:35:00</td>\n",
       "      <td>2016-03-11 23:53:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.988312</td>\n",
       "      <td>40.731743</td>\n",
       "      <td>-73.994751</td>\n",
       "      <td>40.694931</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.036812</td>\n",
       "      <td>-0.006439</td>\n",
       "      <td>2.988357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id0857912</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-21 17:59:00</td>\n",
       "      <td>2016-02-21 18:26:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.997314</td>\n",
       "      <td>40.721458</td>\n",
       "      <td>-73.948029</td>\n",
       "      <td>40.774918</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>0.049286</td>\n",
       "      <td>7.098995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3744273</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-05 09:44:00</td>\n",
       "      <td>2016-01-05 10:03:00</td>\n",
       "      <td>6</td>\n",
       "      <td>-73.961670</td>\n",
       "      <td>40.759720</td>\n",
       "      <td>-73.956779</td>\n",
       "      <td>40.780628</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>0.020908</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>1.782524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id0232939</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-17 06:42:00</td>\n",
       "      <td>2016-02-17 06:56:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.017120</td>\n",
       "      <td>40.708469</td>\n",
       "      <td>-73.988182</td>\n",
       "      <td>40.740631</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.028938</td>\n",
       "      <td>4.221601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id1918069</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-14 18:31:00</td>\n",
       "      <td>2016-02-14 18:55:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.993614</td>\n",
       "      <td>40.751884</td>\n",
       "      <td>-73.995422</td>\n",
       "      <td>40.723862</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.028023</td>\n",
       "      <td>-0.001808</td>\n",
       "      <td>2.061117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id2429028</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-20 20:30:00</td>\n",
       "      <td>2016-04-20 20:36:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.965080</td>\n",
       "      <td>40.758915</td>\n",
       "      <td>-73.976807</td>\n",
       "      <td>40.764107</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>-0.011726</td>\n",
       "      <td>1.168933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id1663798</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-19 16:48:00</td>\n",
       "      <td>2016-06-19 17:06:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.963890</td>\n",
       "      <td>40.765434</td>\n",
       "      <td>-73.872429</td>\n",
       "      <td>40.774200</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>0.008766</td>\n",
       "      <td>0.091461</td>\n",
       "      <td>6.925039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id2436943</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-28 19:17:00</td>\n",
       "      <td>2016-03-28 19:48:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.872887</td>\n",
       "      <td>40.774281</td>\n",
       "      <td>-73.979019</td>\n",
       "      <td>40.761879</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.012402</td>\n",
       "      <td>-0.106133</td>\n",
       "      <td>8.189912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id2933909</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-10 22:01:00</td>\n",
       "      <td>2016-04-10 22:25:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.987823</td>\n",
       "      <td>40.740982</td>\n",
       "      <td>-73.999153</td>\n",
       "      <td>40.686451</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054531</td>\n",
       "      <td>-0.011330</td>\n",
       "      <td>4.550537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id     pickup_datetime    dropoff_datetime  \\\n",
       "0  id1080784          2 2016-02-29 16:40:00 2016-02-29 16:47:00   \n",
       "1  id0889885          1 2016-03-11 23:35:00 2016-03-11 23:53:00   \n",
       "2  id0857912          2 2016-02-21 17:59:00 2016-02-21 18:26:00   \n",
       "3  id3744273          2 2016-01-05 09:44:00 2016-01-05 10:03:00   \n",
       "4  id0232939          1 2016-02-17 06:42:00 2016-02-17 06:56:00   \n",
       "5  id1918069          2 2016-02-14 18:31:00 2016-02-14 18:55:00   \n",
       "6  id2429028          1 2016-04-20 20:30:00 2016-04-20 20:36:00   \n",
       "7  id1663798          2 2016-06-19 16:48:00 2016-06-19 17:06:00   \n",
       "8  id2436943          2 2016-03-28 19:17:00 2016-03-28 19:48:00   \n",
       "9  id2933909          1 2016-04-10 22:01:00 2016-04-10 22:25:00   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.953918        40.778873         -73.963875   \n",
       "1                2        -73.988312        40.731743         -73.994751   \n",
       "2                2        -73.997314        40.721458         -73.948029   \n",
       "3                6        -73.961670        40.759720         -73.956779   \n",
       "4                1        -74.017120        40.708469         -73.988182   \n",
       "5                2        -73.993614        40.751884         -73.995422   \n",
       "6                1        -73.965080        40.758915         -73.976807   \n",
       "7                1        -73.963890        40.765434         -73.872429   \n",
       "8                2        -73.872887        40.774281         -73.979019   \n",
       "9                1        -73.987823        40.740982         -73.999153   \n",
       "\n",
       "   dropoff_latitude  store_and_fwd_flag  ...  Unnamed: 11  Unnamed: 12  \\\n",
       "0         40.771164                   0  ...          NaN          NaN   \n",
       "1         40.694931                   0  ...          NaN          NaN   \n",
       "2         40.774918                   0  ...          NaN          NaN   \n",
       "3         40.780628                   0  ...          NaN          NaN   \n",
       "4         40.740631                   0  ...          NaN          NaN   \n",
       "5         40.723862                   0  ...          NaN          NaN   \n",
       "6         40.764107                   0  ...          NaN          NaN   \n",
       "7         40.774200                   0  ...          NaN          NaN   \n",
       "8         40.761879                   0  ...          NaN          NaN   \n",
       "9         40.686451                   0  ...          NaN          NaN   \n",
       "\n",
       "  pickup_month  pickup_day  pickup_weekday  pickup_hour  pickup_minute  \\\n",
       "0            2          29               0           16             40   \n",
       "1            3          11               4           23             35   \n",
       "2            2          21               6           17             59   \n",
       "3            1           5               1            9             44   \n",
       "4            2          17               2            6             42   \n",
       "5            2          14               6           18             31   \n",
       "6            4          20               2           20             30   \n",
       "7            6          19               6           16             48   \n",
       "8            3          28               0           19             17   \n",
       "9            4          10               6           22              1   \n",
       "\n",
       "   latitude_difference  longitude_difference  trip_distance  \n",
       "0            -0.007709             -0.009956       1.220593  \n",
       "1            -0.036812             -0.006439       2.988357  \n",
       "2             0.053459              0.049286       7.098995  \n",
       "3             0.020908              0.004890       1.782524  \n",
       "4             0.032162              0.028938       4.221601  \n",
       "5            -0.028023             -0.001808       2.061117  \n",
       "6             0.005192             -0.011726       1.168933  \n",
       "7             0.008766              0.091461       6.925039  \n",
       "8            -0.012402             -0.106133       8.189912  \n",
       "9            -0.054531             -0.011330       4.550537  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre-processing\n",
    "\n",
    "sample_df[\"store_and_fwd_flag\"].value_counts()\n",
    "#Convert character variables to numeric\n",
    "f = lambda x: 0 if x == 'N' else 1\n",
    "\n",
    "sample_df[\"store_and_fwd_flag\"] = sample_df[\"store_and_fwd_flag\"].apply(lambda x: f(x))\n",
    "#Check result\n",
    "sample_df[\"store_and_fwd_flag\"].value_counts()\n",
    "\n",
    "\n",
    "#First, convert datetime strings into datetime\n",
    "sample_df[\"dropoff_datetime\"] = pd.to_datetime(sample_df[\"dropoff_datetime\"], format='%d-%m-%Y %H:%M')\n",
    "sample_df[\"pickup_datetime\"] = pd.to_datetime(sample_df[\"pickup_datetime\"], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "#Now construct other variables, like month, date, etc.\n",
    "sample_df[\"pickup_month\"] = sample_df[\"pickup_datetime\"].dt.month\n",
    "sample_df[\"pickup_day\"] = sample_df[\"pickup_datetime\"].dt.day\n",
    "sample_df[\"pickup_weekday\"] = sample_df[\"pickup_datetime\"].dt.weekday #sample_df[\"pickup_weekday\"] = sample_df[\"pickup_datetime\"].dt.weekday_name\n",
    "sample_df[\"pickup_hour\"] = sample_df[\"pickup_datetime\"].dt.hour\n",
    "sample_df[\"pickup_minute\"] = sample_df[\"pickup_datetime\"].dt.minute\n",
    "\n",
    "#Get latitude and longitude differences\n",
    "sample_df[\"latitude_difference\"] = sample_df[\"dropoff_latitude\"] - sample_df[\"pickup_latitude\"]\n",
    "sample_df[\"longitude_difference\"] = sample_df[\"dropoff_longitude\"] - sample_df[\"pickup_longitude\"]\n",
    "\n",
    "#Convert duration to minutes for easier interpretation\n",
    "sample_df[\"trip_duration\"] = sample_df[\"trip_duration\"].apply(lambda x: round(x/60))\n",
    "\n",
    "#Convert trip distance from longitude and latitude differences to Manhattan distance.\n",
    "sample_df[\"trip_distance\"] = 0.621371 * 6371 * (abs(2 * np.arctan2(np.sqrt(np.square(np.sin((abs(sample_df[\"latitude_difference\"]) * np.pi / 180) / 2))),\n",
    "                                  np.sqrt(1-(np.square(np.sin((abs(sample_df[\"latitude_difference\"]) * np.pi / 180) / 2)))))) + \\\n",
    "                                     abs(2 * np.arctan2(np.sqrt(np.square(np.sin((abs(sample_df[\"longitude_difference\"]) * np.pi / 180) / 2))),\n",
    "                                  np.sqrt(1-(np.square(np.sin((abs(sample_df[\"longitude_difference\"]) * np.pi / 180) / 2)))))))\n",
    "\n",
    "sample_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab53ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = sample_df.drop([\"trip_duration\", \"id\", \"vendor_id\", \"pickup_datetime\", \"dropoff_datetime\", \"Unnamed: 11\",\"Unnamed: 12\"], axis=1)\n",
    "y = sample_df[\"trip_duration\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a438e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2018)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=2019)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e5ef784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Creating and fitting the Bayesian Ridge Regression model\n",
    "bayesian_model = BayesianRidge()\n",
    "bayesian_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = bayesian_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0385b3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.301112761922452\n",
      "Mean Squared Error (MSE): 2236.6647289943853\n",
      "Root Mean Squared Error (RMSE): 47.293389908045135\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5897843121120744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8412\\2365895544.py:19: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)  # Pass squared=False to get RMSE directly\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72071bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.301112761922452\n",
      "Mean Squared Error (MSE): 2236.6647289943853\n",
      "Root Mean Squared Error (RMSE): 47.293389908045135\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5897843121120744\n",
      "R-squared (R2 score): 0.031074832938120966\n",
      "Adjusted R-squared: 0.031012830797456536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8412\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d0b44f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.2-cp39-cp39-win_amd64.whl (101.0 MB)\n",
      "     -------------------------------------- 101.0/101.0 MB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (1.9.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (1.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.0/47.0 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from catboost) (3.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2022.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.2.2 graphviz-0.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a28f118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.104787\n",
      "0:\tlearn: 74.8013744\ttotal: 199ms\tremaining: 3m 19s\n",
      "1:\tlearn: 74.7124947\ttotal: 233ms\tremaining: 1m 56s\n",
      "2:\tlearn: 74.0295580\ttotal: 264ms\tremaining: 1m 27s\n",
      "3:\tlearn: 73.3804912\ttotal: 292ms\tremaining: 1m 12s\n",
      "4:\tlearn: 73.2245468\ttotal: 321ms\tremaining: 1m 3s\n",
      "5:\tlearn: 72.9752033\ttotal: 351ms\tremaining: 58.2s\n",
      "6:\tlearn: 72.9405388\ttotal: 383ms\tremaining: 54.4s\n",
      "7:\tlearn: 72.8437058\ttotal: 413ms\tremaining: 51.2s\n",
      "8:\tlearn: 72.5538814\ttotal: 447ms\tremaining: 49.2s\n",
      "9:\tlearn: 72.5313292\ttotal: 482ms\tremaining: 47.7s\n",
      "10:\tlearn: 72.4171235\ttotal: 514ms\tremaining: 46.2s\n",
      "11:\tlearn: 71.5334559\ttotal: 544ms\tremaining: 44.8s\n",
      "12:\tlearn: 71.4962573\ttotal: 575ms\tremaining: 43.7s\n",
      "13:\tlearn: 71.4681044\ttotal: 604ms\tremaining: 42.5s\n",
      "14:\tlearn: 70.6222316\ttotal: 635ms\tremaining: 41.7s\n",
      "15:\tlearn: 70.6153271\ttotal: 666ms\tremaining: 41s\n",
      "16:\tlearn: 69.8122243\ttotal: 694ms\tremaining: 40.1s\n",
      "17:\tlearn: 69.6645299\ttotal: 718ms\tremaining: 39.2s\n",
      "18:\tlearn: 69.5784517\ttotal: 739ms\tremaining: 38.2s\n",
      "19:\tlearn: 69.1598855\ttotal: 761ms\tremaining: 37.3s\n",
      "20:\tlearn: 68.4115232\ttotal: 781ms\tremaining: 36.4s\n",
      "21:\tlearn: 68.3647383\ttotal: 803ms\tremaining: 35.7s\n",
      "22:\tlearn: 68.3601471\ttotal: 824ms\tremaining: 35s\n",
      "23:\tlearn: 67.8071623\ttotal: 841ms\tremaining: 34.2s\n",
      "24:\tlearn: 67.7938065\ttotal: 860ms\tremaining: 33.5s\n",
      "25:\tlearn: 67.1056144\ttotal: 879ms\tremaining: 32.9s\n",
      "26:\tlearn: 66.4444075\ttotal: 896ms\tremaining: 32.3s\n",
      "27:\tlearn: 65.8125015\ttotal: 916ms\tremaining: 31.8s\n",
      "28:\tlearn: 65.2064776\ttotal: 934ms\tremaining: 31.3s\n",
      "29:\tlearn: 65.0691348\ttotal: 948ms\tremaining: 30.7s\n",
      "30:\tlearn: 64.6132756\ttotal: 967ms\tremaining: 30.2s\n",
      "31:\tlearn: 64.2519848\ttotal: 984ms\tremaining: 29.8s\n",
      "32:\tlearn: 63.7168693\ttotal: 1s\tremaining: 29.4s\n",
      "33:\tlearn: 63.2060527\ttotal: 1.02s\tremaining: 28.9s\n",
      "34:\tlearn: 62.8621838\ttotal: 1.03s\tremaining: 28.5s\n",
      "35:\tlearn: 62.3879515\ttotal: 1.05s\tremaining: 28.2s\n",
      "36:\tlearn: 61.9325926\ttotal: 1.07s\tremaining: 27.9s\n",
      "37:\tlearn: 61.5920360\ttotal: 1.09s\tremaining: 27.7s\n",
      "38:\tlearn: 61.1760408\ttotal: 1.11s\tremaining: 27.4s\n",
      "39:\tlearn: 60.7781116\ttotal: 1.13s\tremaining: 27.2s\n",
      "40:\tlearn: 60.3984116\ttotal: 1.15s\tremaining: 26.9s\n",
      "41:\tlearn: 60.3750011\ttotal: 1.17s\tremaining: 26.6s\n",
      "42:\tlearn: 60.1757337\ttotal: 1.18s\tremaining: 26.4s\n",
      "43:\tlearn: 60.1707414\ttotal: 1.2s\tremaining: 26.1s\n",
      "44:\tlearn: 59.8167572\ttotal: 1.22s\tremaining: 25.9s\n",
      "45:\tlearn: 59.4835423\ttotal: 1.23s\tremaining: 25.6s\n",
      "46:\tlearn: 59.1630024\ttotal: 1.25s\tremaining: 25.4s\n",
      "47:\tlearn: 58.9236420\ttotal: 1.27s\tremaining: 25.2s\n",
      "48:\tlearn: 58.8849257\ttotal: 1.28s\tremaining: 24.9s\n",
      "49:\tlearn: 58.5941226\ttotal: 1.3s\tremaining: 24.8s\n",
      "50:\tlearn: 58.5892899\ttotal: 1.32s\tremaining: 24.6s\n",
      "51:\tlearn: 58.3145764\ttotal: 1.34s\tremaining: 24.4s\n",
      "52:\tlearn: 58.1095161\ttotal: 1.36s\tremaining: 24.2s\n",
      "53:\tlearn: 57.8531651\ttotal: 1.38s\tremaining: 24.1s\n",
      "54:\tlearn: 57.7038918\ttotal: 1.4s\tremaining: 24s\n",
      "55:\tlearn: 57.5169346\ttotal: 1.42s\tremaining: 23.9s\n",
      "56:\tlearn: 57.5141331\ttotal: 1.44s\tremaining: 23.8s\n",
      "57:\tlearn: 57.5093671\ttotal: 1.45s\tremaining: 23.6s\n",
      "58:\tlearn: 57.5057319\ttotal: 1.47s\tremaining: 23.5s\n",
      "59:\tlearn: 57.4960621\ttotal: 1.49s\tremaining: 23.3s\n",
      "60:\tlearn: 57.2691150\ttotal: 1.51s\tremaining: 23.2s\n",
      "61:\tlearn: 57.2447459\ttotal: 1.52s\tremaining: 23.1s\n",
      "62:\tlearn: 57.2416138\ttotal: 1.54s\tremaining: 22.9s\n",
      "63:\tlearn: 57.1965081\ttotal: 1.56s\tremaining: 22.8s\n",
      "64:\tlearn: 56.9816599\ttotal: 1.57s\tremaining: 22.6s\n",
      "65:\tlearn: 56.9768082\ttotal: 1.59s\tremaining: 22.5s\n",
      "66:\tlearn: 56.9564669\ttotal: 1.6s\tremaining: 22.4s\n",
      "67:\tlearn: 56.9544352\ttotal: 1.62s\tremaining: 22.3s\n",
      "68:\tlearn: 56.7914767\ttotal: 1.65s\tremaining: 22.2s\n",
      "69:\tlearn: 56.6354564\ttotal: 1.66s\tremaining: 22.1s\n",
      "70:\tlearn: 56.6324942\ttotal: 1.68s\tremaining: 22s\n",
      "71:\tlearn: 56.5935242\ttotal: 1.7s\tremaining: 21.9s\n",
      "72:\tlearn: 56.5560675\ttotal: 1.72s\tremaining: 21.8s\n",
      "73:\tlearn: 56.5386724\ttotal: 1.73s\tremaining: 21.6s\n",
      "74:\tlearn: 56.5330451\ttotal: 1.75s\tremaining: 21.6s\n",
      "75:\tlearn: 56.5298488\ttotal: 1.77s\tremaining: 21.5s\n",
      "76:\tlearn: 56.5272035\ttotal: 1.78s\tremaining: 21.4s\n",
      "77:\tlearn: 56.5227811\ttotal: 1.8s\tremaining: 21.3s\n",
      "78:\tlearn: 56.5193111\ttotal: 1.82s\tremaining: 21.2s\n",
      "79:\tlearn: 56.5158252\ttotal: 1.84s\tremaining: 21.1s\n",
      "80:\tlearn: 56.3357722\ttotal: 1.86s\tremaining: 21.1s\n",
      "81:\tlearn: 56.3318944\ttotal: 1.88s\tremaining: 21s\n",
      "82:\tlearn: 56.2730621\ttotal: 1.89s\tremaining: 20.9s\n",
      "83:\tlearn: 56.1951194\ttotal: 1.91s\tremaining: 20.8s\n",
      "84:\tlearn: 56.0311459\ttotal: 1.93s\tremaining: 20.8s\n",
      "85:\tlearn: 55.8745963\ttotal: 1.95s\tremaining: 20.7s\n",
      "86:\tlearn: 55.8582666\ttotal: 1.96s\tremaining: 20.6s\n",
      "87:\tlearn: 55.8550444\ttotal: 1.98s\tremaining: 20.6s\n",
      "88:\tlearn: 55.8513504\ttotal: 2s\tremaining: 20.5s\n",
      "89:\tlearn: 55.8495900\ttotal: 2.02s\tremaining: 20.4s\n",
      "90:\tlearn: 55.7319011\ttotal: 2.03s\tremaining: 20.3s\n",
      "91:\tlearn: 55.7288119\ttotal: 2.05s\tremaining: 20.3s\n",
      "92:\tlearn: 55.7259762\ttotal: 2.07s\tremaining: 20.2s\n",
      "93:\tlearn: 55.5811049\ttotal: 2.09s\tremaining: 20.2s\n",
      "94:\tlearn: 55.4951264\ttotal: 2.11s\tremaining: 20.1s\n",
      "95:\tlearn: 55.4930138\ttotal: 2.13s\tremaining: 20s\n",
      "96:\tlearn: 55.3595399\ttotal: 2.15s\tremaining: 20s\n",
      "97:\tlearn: 55.2338107\ttotal: 2.17s\tremaining: 19.9s\n",
      "98:\tlearn: 55.2324634\ttotal: 2.19s\tremaining: 19.9s\n",
      "99:\tlearn: 55.2254618\ttotal: 2.2s\tremaining: 19.8s\n",
      "100:\tlearn: 55.2201765\ttotal: 2.22s\tremaining: 19.8s\n",
      "101:\tlearn: 55.1026504\ttotal: 2.24s\tremaining: 19.8s\n",
      "102:\tlearn: 55.1004281\ttotal: 2.26s\tremaining: 19.7s\n",
      "103:\tlearn: 55.0970717\ttotal: 2.28s\tremaining: 19.7s\n",
      "104:\tlearn: 55.0949264\ttotal: 2.3s\tremaining: 19.6s\n",
      "105:\tlearn: 55.0915833\ttotal: 2.32s\tremaining: 19.6s\n",
      "106:\tlearn: 54.9810259\ttotal: 2.34s\tremaining: 19.5s\n",
      "107:\tlearn: 54.9766929\ttotal: 2.36s\tremaining: 19.5s\n",
      "108:\tlearn: 54.9707762\ttotal: 2.38s\tremaining: 19.4s\n",
      "109:\tlearn: 54.9644362\ttotal: 2.4s\tremaining: 19.4s\n",
      "110:\tlearn: 54.9595977\ttotal: 2.42s\tremaining: 19.4s\n",
      "111:\tlearn: 54.9504533\ttotal: 2.44s\tremaining: 19.3s\n",
      "112:\tlearn: 54.9485756\ttotal: 2.46s\tremaining: 19.3s\n",
      "113:\tlearn: 54.9455062\ttotal: 2.48s\tremaining: 19.2s\n",
      "114:\tlearn: 54.9410799\ttotal: 2.5s\tremaining: 19.2s\n",
      "115:\tlearn: 54.9371943\ttotal: 2.52s\tremaining: 19.2s\n",
      "116:\tlearn: 54.9335166\ttotal: 2.54s\tremaining: 19.2s\n",
      "117:\tlearn: 54.9306557\ttotal: 2.56s\tremaining: 19.1s\n",
      "118:\tlearn: 54.8223201\ttotal: 2.58s\tremaining: 19.1s\n",
      "119:\tlearn: 54.8196965\ttotal: 2.6s\tremaining: 19.1s\n",
      "120:\tlearn: 54.8170116\ttotal: 2.62s\tremaining: 19s\n",
      "121:\tlearn: 54.8136695\ttotal: 2.64s\tremaining: 19s\n",
      "122:\tlearn: 54.8112546\ttotal: 2.66s\tremaining: 19s\n",
      "123:\tlearn: 54.7121115\ttotal: 2.69s\tremaining: 19s\n",
      "124:\tlearn: 54.6138102\ttotal: 2.71s\tremaining: 19s\n",
      "125:\tlearn: 54.6105873\ttotal: 2.73s\tremaining: 19s\n",
      "126:\tlearn: 54.6083159\ttotal: 2.76s\tremaining: 19s\n",
      "127:\tlearn: 54.6040420\ttotal: 2.79s\tremaining: 19s\n",
      "128:\tlearn: 54.5962813\ttotal: 2.81s\tremaining: 19s\n",
      "129:\tlearn: 54.5940386\ttotal: 2.83s\tremaining: 19s\n",
      "130:\tlearn: 54.5048368\ttotal: 2.86s\tremaining: 18.9s\n",
      "131:\tlearn: 54.4201684\ttotal: 2.88s\tremaining: 18.9s\n",
      "132:\tlearn: 54.4136021\ttotal: 2.9s\tremaining: 18.9s\n",
      "133:\tlearn: 54.4084454\ttotal: 2.92s\tremaining: 18.9s\n",
      "134:\tlearn: 54.4043496\ttotal: 2.94s\tremaining: 18.8s\n",
      "135:\tlearn: 54.3994520\ttotal: 2.96s\tremaining: 18.8s\n",
      "136:\tlearn: 54.3162861\ttotal: 2.98s\tremaining: 18.8s\n",
      "137:\tlearn: 54.3141797\ttotal: 3s\tremaining: 18.8s\n",
      "138:\tlearn: 54.3094424\ttotal: 3.03s\tremaining: 18.8s\n",
      "139:\tlearn: 54.2312845\ttotal: 3.05s\tremaining: 18.7s\n",
      "140:\tlearn: 54.2292856\ttotal: 3.06s\tremaining: 18.7s\n",
      "141:\tlearn: 54.2261679\ttotal: 3.09s\tremaining: 18.7s\n",
      "142:\tlearn: 54.1536904\ttotal: 3.11s\tremaining: 18.6s\n",
      "143:\tlearn: 54.0843812\ttotal: 3.13s\tremaining: 18.6s\n",
      "144:\tlearn: 54.0802714\ttotal: 3.15s\tremaining: 18.6s\n",
      "145:\tlearn: 54.0122525\ttotal: 3.17s\tremaining: 18.6s\n",
      "146:\tlearn: 53.9476662\ttotal: 3.19s\tremaining: 18.5s\n",
      "147:\tlearn: 53.8868008\ttotal: 3.22s\tremaining: 18.5s\n",
      "148:\tlearn: 53.8832219\ttotal: 3.24s\tremaining: 18.5s\n",
      "149:\tlearn: 53.8253687\ttotal: 3.26s\tremaining: 18.5s\n",
      "150:\tlearn: 53.7706854\ttotal: 3.28s\tremaining: 18.4s\n",
      "151:\tlearn: 53.7173270\ttotal: 3.3s\tremaining: 18.4s\n",
      "152:\tlearn: 53.7091244\ttotal: 3.32s\tremaining: 18.4s\n",
      "153:\tlearn: 53.7015168\ttotal: 3.34s\tremaining: 18.3s\n",
      "154:\tlearn: 53.6981196\ttotal: 3.36s\tremaining: 18.3s\n",
      "155:\tlearn: 53.6949303\ttotal: 3.38s\tremaining: 18.3s\n",
      "156:\tlearn: 53.6906531\ttotal: 3.39s\tremaining: 18.2s\n",
      "157:\tlearn: 53.6426648\ttotal: 3.42s\tremaining: 18.2s\n",
      "158:\tlearn: 53.5944642\ttotal: 3.44s\tremaining: 18.2s\n",
      "159:\tlearn: 53.5889492\ttotal: 3.46s\tremaining: 18.2s\n",
      "160:\tlearn: 53.5862484\ttotal: 3.48s\tremaining: 18.1s\n",
      "161:\tlearn: 53.5531476\ttotal: 3.5s\tremaining: 18.1s\n",
      "162:\tlearn: 53.5506604\ttotal: 3.52s\tremaining: 18.1s\n",
      "163:\tlearn: 53.5485763\ttotal: 3.54s\tremaining: 18.1s\n",
      "164:\tlearn: 53.5455777\ttotal: 3.56s\tremaining: 18s\n",
      "165:\tlearn: 53.5380178\ttotal: 3.59s\tremaining: 18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166:\tlearn: 53.5325255\ttotal: 3.61s\tremaining: 18s\n",
      "167:\tlearn: 53.5307375\ttotal: 3.63s\tremaining: 18s\n",
      "168:\tlearn: 53.5256934\ttotal: 3.65s\tremaining: 18s\n",
      "169:\tlearn: 53.5212722\ttotal: 3.67s\tremaining: 17.9s\n",
      "170:\tlearn: 53.4800525\ttotal: 3.69s\tremaining: 17.9s\n",
      "171:\tlearn: 53.4665313\ttotal: 3.71s\tremaining: 17.9s\n",
      "172:\tlearn: 53.4245681\ttotal: 3.73s\tremaining: 17.8s\n",
      "173:\tlearn: 53.4226835\ttotal: 3.75s\tremaining: 17.8s\n",
      "174:\tlearn: 53.4195909\ttotal: 3.77s\tremaining: 17.8s\n",
      "175:\tlearn: 53.4176641\ttotal: 3.79s\tremaining: 17.8s\n",
      "176:\tlearn: 53.4134088\ttotal: 3.81s\tremaining: 17.7s\n",
      "177:\tlearn: 53.4092389\ttotal: 3.83s\tremaining: 17.7s\n",
      "178:\tlearn: 53.4075420\ttotal: 3.85s\tremaining: 17.7s\n",
      "179:\tlearn: 53.4040860\ttotal: 3.88s\tremaining: 17.7s\n",
      "180:\tlearn: 53.4034331\ttotal: 3.9s\tremaining: 17.6s\n",
      "181:\tlearn: 53.4012978\ttotal: 3.92s\tremaining: 17.6s\n",
      "182:\tlearn: 53.3997271\ttotal: 3.94s\tremaining: 17.6s\n",
      "183:\tlearn: 53.3923179\ttotal: 3.96s\tremaining: 17.6s\n",
      "184:\tlearn: 53.3863269\ttotal: 3.98s\tremaining: 17.5s\n",
      "185:\tlearn: 53.3839825\ttotal: 4s\tremaining: 17.5s\n",
      "186:\tlearn: 53.3816811\ttotal: 4.02s\tremaining: 17.5s\n",
      "187:\tlearn: 53.3767978\ttotal: 4.04s\tremaining: 17.4s\n",
      "188:\tlearn: 53.3751344\ttotal: 4.06s\tremaining: 17.4s\n",
      "189:\tlearn: 53.3379056\ttotal: 4.08s\tremaining: 17.4s\n",
      "190:\tlearn: 53.3353690\ttotal: 4.11s\tremaining: 17.4s\n",
      "191:\tlearn: 53.3311787\ttotal: 4.13s\tremaining: 17.4s\n",
      "192:\tlearn: 53.3259795\ttotal: 4.15s\tremaining: 17.4s\n",
      "193:\tlearn: 53.2903280\ttotal: 4.17s\tremaining: 17.3s\n",
      "194:\tlearn: 53.2844461\ttotal: 4.19s\tremaining: 17.3s\n",
      "195:\tlearn: 53.2816922\ttotal: 4.21s\tremaining: 17.3s\n",
      "196:\tlearn: 53.2780175\ttotal: 4.23s\tremaining: 17.3s\n",
      "197:\tlearn: 53.2730515\ttotal: 4.26s\tremaining: 17.2s\n",
      "198:\tlearn: 53.2698587\ttotal: 4.28s\tremaining: 17.2s\n",
      "199:\tlearn: 53.2677439\ttotal: 4.3s\tremaining: 17.2s\n",
      "200:\tlearn: 53.2653638\ttotal: 4.32s\tremaining: 17.2s\n",
      "201:\tlearn: 53.2315466\ttotal: 4.34s\tremaining: 17.2s\n",
      "202:\tlearn: 53.1979992\ttotal: 4.37s\tremaining: 17.2s\n",
      "203:\tlearn: 53.1677842\ttotal: 4.39s\tremaining: 17.1s\n",
      "204:\tlearn: 53.1646679\ttotal: 4.42s\tremaining: 17.1s\n",
      "205:\tlearn: 53.1641023\ttotal: 4.44s\tremaining: 17.1s\n",
      "206:\tlearn: 53.1354360\ttotal: 4.47s\tremaining: 17.1s\n",
      "207:\tlearn: 53.1216832\ttotal: 4.49s\tremaining: 17.1s\n",
      "208:\tlearn: 53.1170673\ttotal: 4.51s\tremaining: 17.1s\n",
      "209:\tlearn: 53.1132439\ttotal: 4.54s\tremaining: 17.1s\n",
      "210:\tlearn: 53.1093587\ttotal: 4.56s\tremaining: 17.1s\n",
      "211:\tlearn: 53.1077493\ttotal: 4.58s\tremaining: 17s\n",
      "212:\tlearn: 53.1013288\ttotal: 4.59s\tremaining: 17s\n",
      "213:\tlearn: 53.1008088\ttotal: 4.62s\tremaining: 17s\n",
      "214:\tlearn: 53.0977759\ttotal: 4.64s\tremaining: 16.9s\n",
      "215:\tlearn: 53.0698860\ttotal: 4.66s\tremaining: 16.9s\n",
      "216:\tlearn: 53.0665149\ttotal: 4.68s\tremaining: 16.9s\n",
      "217:\tlearn: 53.0646178\ttotal: 4.7s\tremaining: 16.9s\n",
      "218:\tlearn: 53.0614683\ttotal: 4.73s\tremaining: 16.9s\n",
      "219:\tlearn: 53.0580508\ttotal: 4.75s\tremaining: 16.8s\n",
      "220:\tlearn: 53.0502812\ttotal: 4.77s\tremaining: 16.8s\n",
      "221:\tlearn: 53.0468738\ttotal: 4.79s\tremaining: 16.8s\n",
      "222:\tlearn: 53.0434053\ttotal: 4.82s\tremaining: 16.8s\n",
      "223:\tlearn: 53.0408198\ttotal: 4.84s\tremaining: 16.8s\n",
      "224:\tlearn: 53.0357483\ttotal: 4.86s\tremaining: 16.7s\n",
      "225:\tlearn: 53.0311493\ttotal: 4.88s\tremaining: 16.7s\n",
      "226:\tlearn: 53.0292898\ttotal: 4.9s\tremaining: 16.7s\n",
      "227:\tlearn: 53.0031649\ttotal: 4.92s\tremaining: 16.7s\n",
      "228:\tlearn: 52.9784472\ttotal: 4.94s\tremaining: 16.6s\n",
      "229:\tlearn: 52.9760926\ttotal: 4.96s\tremaining: 16.6s\n",
      "230:\tlearn: 52.9712313\ttotal: 4.98s\tremaining: 16.6s\n",
      "231:\tlearn: 52.9693846\ttotal: 5s\tremaining: 16.6s\n",
      "232:\tlearn: 52.9455914\ttotal: 5.02s\tremaining: 16.5s\n",
      "233:\tlearn: 52.9434210\ttotal: 5.05s\tremaining: 16.5s\n",
      "234:\tlearn: 52.9404202\ttotal: 5.07s\tremaining: 16.5s\n",
      "235:\tlearn: 52.9348081\ttotal: 5.09s\tremaining: 16.5s\n",
      "236:\tlearn: 52.9110814\ttotal: 5.11s\tremaining: 16.5s\n",
      "237:\tlearn: 52.9077662\ttotal: 5.14s\tremaining: 16.5s\n",
      "238:\tlearn: 52.8866482\ttotal: 5.16s\tremaining: 16.4s\n",
      "239:\tlearn: 52.8831316\ttotal: 5.18s\tremaining: 16.4s\n",
      "240:\tlearn: 52.8818932\ttotal: 5.21s\tremaining: 16.4s\n",
      "241:\tlearn: 52.8796329\ttotal: 5.23s\tremaining: 16.4s\n",
      "242:\tlearn: 52.8596010\ttotal: 5.26s\tremaining: 16.4s\n",
      "243:\tlearn: 52.8406024\ttotal: 5.28s\tremaining: 16.4s\n",
      "244:\tlearn: 52.8222480\ttotal: 5.3s\tremaining: 16.3s\n",
      "245:\tlearn: 52.8179542\ttotal: 5.33s\tremaining: 16.3s\n",
      "246:\tlearn: 52.8155287\ttotal: 5.35s\tremaining: 16.3s\n",
      "247:\tlearn: 52.8126567\ttotal: 5.37s\tremaining: 16.3s\n",
      "248:\tlearn: 52.8086841\ttotal: 5.39s\tremaining: 16.3s\n",
      "249:\tlearn: 52.8071527\ttotal: 5.41s\tremaining: 16.2s\n",
      "250:\tlearn: 52.8060089\ttotal: 5.44s\tremaining: 16.2s\n",
      "251:\tlearn: 52.8028101\ttotal: 5.46s\tremaining: 16.2s\n",
      "252:\tlearn: 52.7993509\ttotal: 5.48s\tremaining: 16.2s\n",
      "253:\tlearn: 52.7965461\ttotal: 5.5s\tremaining: 16.2s\n",
      "254:\tlearn: 52.7950940\ttotal: 5.52s\tremaining: 16.1s\n",
      "255:\tlearn: 52.7915651\ttotal: 5.54s\tremaining: 16.1s\n",
      "256:\tlearn: 52.7872830\ttotal: 5.56s\tremaining: 16.1s\n",
      "257:\tlearn: 52.7838501\ttotal: 5.58s\tremaining: 16s\n",
      "258:\tlearn: 52.7804970\ttotal: 5.6s\tremaining: 16s\n",
      "259:\tlearn: 52.7789465\ttotal: 5.62s\tremaining: 16s\n",
      "260:\tlearn: 52.7755812\ttotal: 5.64s\tremaining: 16s\n",
      "261:\tlearn: 52.7584331\ttotal: 5.66s\tremaining: 15.9s\n",
      "262:\tlearn: 52.7551343\ttotal: 5.68s\tremaining: 15.9s\n",
      "263:\tlearn: 52.7522062\ttotal: 5.71s\tremaining: 15.9s\n",
      "264:\tlearn: 52.7499814\ttotal: 5.73s\tremaining: 15.9s\n",
      "265:\tlearn: 52.7468139\ttotal: 5.75s\tremaining: 15.9s\n",
      "266:\tlearn: 52.7424523\ttotal: 5.77s\tremaining: 15.8s\n",
      "267:\tlearn: 52.7364849\ttotal: 5.79s\tremaining: 15.8s\n",
      "268:\tlearn: 52.7342476\ttotal: 5.81s\tremaining: 15.8s\n",
      "269:\tlearn: 52.7311908\ttotal: 5.84s\tremaining: 15.8s\n",
      "270:\tlearn: 52.7181667\ttotal: 5.86s\tremaining: 15.8s\n",
      "271:\tlearn: 52.7158453\ttotal: 5.88s\tremaining: 15.7s\n",
      "272:\tlearn: 52.7134591\ttotal: 5.91s\tremaining: 15.7s\n",
      "273:\tlearn: 52.7103986\ttotal: 5.93s\tremaining: 15.7s\n",
      "274:\tlearn: 52.7100763\ttotal: 5.96s\tremaining: 15.7s\n",
      "275:\tlearn: 52.7078506\ttotal: 5.97s\tremaining: 15.7s\n",
      "276:\tlearn: 52.7046473\ttotal: 6s\tremaining: 15.7s\n",
      "277:\tlearn: 52.7011582\ttotal: 6.03s\tremaining: 15.7s\n",
      "278:\tlearn: 52.6979632\ttotal: 6.05s\tremaining: 15.6s\n",
      "279:\tlearn: 52.6963525\ttotal: 6.08s\tremaining: 15.6s\n",
      "280:\tlearn: 52.6959916\ttotal: 6.1s\tremaining: 15.6s\n",
      "281:\tlearn: 52.6797103\ttotal: 6.12s\tremaining: 15.6s\n",
      "282:\tlearn: 52.6764082\ttotal: 6.15s\tremaining: 15.6s\n",
      "283:\tlearn: 52.6702223\ttotal: 6.17s\tremaining: 15.5s\n",
      "284:\tlearn: 52.6698794\ttotal: 6.19s\tremaining: 15.5s\n",
      "285:\tlearn: 52.6668389\ttotal: 6.21s\tremaining: 15.5s\n",
      "286:\tlearn: 52.6613103\ttotal: 6.24s\tremaining: 15.5s\n",
      "287:\tlearn: 52.6577912\ttotal: 6.26s\tremaining: 15.5s\n",
      "288:\tlearn: 52.6529563\ttotal: 6.28s\tremaining: 15.5s\n",
      "289:\tlearn: 52.6503669\ttotal: 6.3s\tremaining: 15.4s\n",
      "290:\tlearn: 52.6384043\ttotal: 6.32s\tremaining: 15.4s\n",
      "291:\tlearn: 52.6367507\ttotal: 6.35s\tremaining: 15.4s\n",
      "292:\tlearn: 52.6324275\ttotal: 6.37s\tremaining: 15.4s\n",
      "293:\tlearn: 52.6298086\ttotal: 6.39s\tremaining: 15.3s\n",
      "294:\tlearn: 52.6279665\ttotal: 6.41s\tremaining: 15.3s\n",
      "295:\tlearn: 52.6125107\ttotal: 6.43s\tremaining: 15.3s\n",
      "296:\tlearn: 52.5978363\ttotal: 6.46s\tremaining: 15.3s\n",
      "297:\tlearn: 52.5975222\ttotal: 6.48s\tremaining: 15.3s\n",
      "298:\tlearn: 52.5819391\ttotal: 6.5s\tremaining: 15.3s\n",
      "299:\tlearn: 52.5806205\ttotal: 6.52s\tremaining: 15.2s\n",
      "300:\tlearn: 52.5760678\ttotal: 6.55s\tremaining: 15.2s\n",
      "301:\tlearn: 52.5694453\ttotal: 6.57s\tremaining: 15.2s\n",
      "302:\tlearn: 52.5665373\ttotal: 6.59s\tremaining: 15.2s\n",
      "303:\tlearn: 52.5638544\ttotal: 6.61s\tremaining: 15.1s\n",
      "304:\tlearn: 52.5635583\ttotal: 6.63s\tremaining: 15.1s\n",
      "305:\tlearn: 52.5596514\ttotal: 6.66s\tremaining: 15.1s\n",
      "306:\tlearn: 52.5554073\ttotal: 6.68s\tremaining: 15.1s\n",
      "307:\tlearn: 52.5523278\ttotal: 6.7s\tremaining: 15.1s\n",
      "308:\tlearn: 52.5391103\ttotal: 6.73s\tremaining: 15s\n",
      "309:\tlearn: 52.5364897\ttotal: 6.75s\tremaining: 15s\n",
      "310:\tlearn: 52.5310053\ttotal: 6.78s\tremaining: 15s\n",
      "311:\tlearn: 52.5169034\ttotal: 6.8s\tremaining: 15s\n",
      "312:\tlearn: 52.5077949\ttotal: 6.82s\tremaining: 15s\n",
      "313:\tlearn: 52.5042969\ttotal: 6.84s\tremaining: 14.9s\n",
      "314:\tlearn: 52.5015353\ttotal: 6.86s\tremaining: 14.9s\n",
      "315:\tlearn: 52.4983528\ttotal: 6.89s\tremaining: 14.9s\n",
      "316:\tlearn: 52.4943522\ttotal: 6.91s\tremaining: 14.9s\n",
      "317:\tlearn: 52.4821794\ttotal: 6.93s\tremaining: 14.9s\n",
      "318:\tlearn: 52.4777652\ttotal: 6.95s\tremaining: 14.8s\n",
      "319:\tlearn: 52.4736913\ttotal: 6.97s\tremaining: 14.8s\n",
      "320:\tlearn: 52.4722336\ttotal: 6.99s\tremaining: 14.8s\n",
      "321:\tlearn: 52.4605862\ttotal: 7.01s\tremaining: 14.8s\n",
      "322:\tlearn: 52.4552503\ttotal: 7.03s\tremaining: 14.7s\n",
      "323:\tlearn: 52.4520716\ttotal: 7.05s\tremaining: 14.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324:\tlearn: 52.4518012\ttotal: 7.07s\tremaining: 14.7s\n",
      "325:\tlearn: 52.4496579\ttotal: 7.09s\tremaining: 14.7s\n",
      "326:\tlearn: 52.4474403\ttotal: 7.12s\tremaining: 14.6s\n",
      "327:\tlearn: 52.4447733\ttotal: 7.14s\tremaining: 14.6s\n",
      "328:\tlearn: 52.4429594\ttotal: 7.16s\tremaining: 14.6s\n",
      "329:\tlearn: 52.4399386\ttotal: 7.18s\tremaining: 14.6s\n",
      "330:\tlearn: 52.4370152\ttotal: 7.2s\tremaining: 14.6s\n",
      "331:\tlearn: 52.4353890\ttotal: 7.22s\tremaining: 14.5s\n",
      "332:\tlearn: 52.4319153\ttotal: 7.25s\tremaining: 14.5s\n",
      "333:\tlearn: 52.4284708\ttotal: 7.26s\tremaining: 14.5s\n",
      "334:\tlearn: 52.4244990\ttotal: 7.28s\tremaining: 14.5s\n",
      "335:\tlearn: 52.4223864\ttotal: 7.3s\tremaining: 14.4s\n",
      "336:\tlearn: 52.4116505\ttotal: 7.32s\tremaining: 14.4s\n",
      "337:\tlearn: 52.4097554\ttotal: 7.34s\tremaining: 14.4s\n",
      "338:\tlearn: 52.4026207\ttotal: 7.36s\tremaining: 14.4s\n",
      "339:\tlearn: 52.3998513\ttotal: 7.38s\tremaining: 14.3s\n",
      "340:\tlearn: 52.3972738\ttotal: 7.41s\tremaining: 14.3s\n",
      "341:\tlearn: 52.3940641\ttotal: 7.42s\tremaining: 14.3s\n",
      "342:\tlearn: 52.3920621\ttotal: 7.44s\tremaining: 14.3s\n",
      "343:\tlearn: 52.3877953\ttotal: 7.46s\tremaining: 14.2s\n",
      "344:\tlearn: 52.3851832\ttotal: 7.49s\tremaining: 14.2s\n",
      "345:\tlearn: 52.3818731\ttotal: 7.51s\tremaining: 14.2s\n",
      "346:\tlearn: 52.3789396\ttotal: 7.53s\tremaining: 14.2s\n",
      "347:\tlearn: 52.3761156\ttotal: 7.56s\tremaining: 14.2s\n",
      "348:\tlearn: 52.3618899\ttotal: 7.58s\tremaining: 14.1s\n",
      "349:\tlearn: 52.3590669\ttotal: 7.6s\tremaining: 14.1s\n",
      "350:\tlearn: 52.3552772\ttotal: 7.62s\tremaining: 14.1s\n",
      "351:\tlearn: 52.3526415\ttotal: 7.64s\tremaining: 14.1s\n",
      "352:\tlearn: 52.3488748\ttotal: 7.66s\tremaining: 14s\n",
      "353:\tlearn: 52.3465809\ttotal: 7.68s\tremaining: 14s\n",
      "354:\tlearn: 52.3440900\ttotal: 7.71s\tremaining: 14s\n",
      "355:\tlearn: 52.3429134\ttotal: 7.72s\tremaining: 14s\n",
      "356:\tlearn: 52.3400653\ttotal: 7.74s\tremaining: 13.9s\n",
      "357:\tlearn: 52.3383709\ttotal: 7.77s\tremaining: 13.9s\n",
      "358:\tlearn: 52.3329736\ttotal: 7.79s\tremaining: 13.9s\n",
      "359:\tlearn: 52.3305099\ttotal: 7.81s\tremaining: 13.9s\n",
      "360:\tlearn: 52.3248203\ttotal: 7.84s\tremaining: 13.9s\n",
      "361:\tlearn: 52.3207274\ttotal: 7.86s\tremaining: 13.8s\n",
      "362:\tlearn: 52.3176660\ttotal: 7.87s\tremaining: 13.8s\n",
      "363:\tlearn: 52.3150212\ttotal: 7.89s\tremaining: 13.8s\n",
      "364:\tlearn: 52.3045348\ttotal: 7.91s\tremaining: 13.8s\n",
      "365:\tlearn: 52.3013924\ttotal: 7.93s\tremaining: 13.7s\n",
      "366:\tlearn: 52.2988287\ttotal: 7.96s\tremaining: 13.7s\n",
      "367:\tlearn: 52.2964561\ttotal: 7.98s\tremaining: 13.7s\n",
      "368:\tlearn: 52.2945574\ttotal: 8s\tremaining: 13.7s\n",
      "369:\tlearn: 52.2922880\ttotal: 8.02s\tremaining: 13.7s\n",
      "370:\tlearn: 52.2898065\ttotal: 8.05s\tremaining: 13.6s\n",
      "371:\tlearn: 52.2860081\ttotal: 8.07s\tremaining: 13.6s\n",
      "372:\tlearn: 52.2798015\ttotal: 8.09s\tremaining: 13.6s\n",
      "373:\tlearn: 52.2772126\ttotal: 8.11s\tremaining: 13.6s\n",
      "374:\tlearn: 52.2745187\ttotal: 8.13s\tremaining: 13.6s\n",
      "375:\tlearn: 52.2728579\ttotal: 8.15s\tremaining: 13.5s\n",
      "376:\tlearn: 52.2705195\ttotal: 8.18s\tremaining: 13.5s\n",
      "377:\tlearn: 52.2684936\ttotal: 8.2s\tremaining: 13.5s\n",
      "378:\tlearn: 52.2655890\ttotal: 8.22s\tremaining: 13.5s\n",
      "379:\tlearn: 52.2622621\ttotal: 8.24s\tremaining: 13.4s\n",
      "380:\tlearn: 52.2596710\ttotal: 8.26s\tremaining: 13.4s\n",
      "381:\tlearn: 52.2566469\ttotal: 8.28s\tremaining: 13.4s\n",
      "382:\tlearn: 52.2541802\ttotal: 8.3s\tremaining: 13.4s\n",
      "383:\tlearn: 52.2508044\ttotal: 8.32s\tremaining: 13.3s\n",
      "384:\tlearn: 52.2480325\ttotal: 8.34s\tremaining: 13.3s\n",
      "385:\tlearn: 52.2438516\ttotal: 8.36s\tremaining: 13.3s\n",
      "386:\tlearn: 52.2416634\ttotal: 8.38s\tremaining: 13.3s\n",
      "387:\tlearn: 52.2391468\ttotal: 8.41s\tremaining: 13.3s\n",
      "388:\tlearn: 52.2342762\ttotal: 8.43s\tremaining: 13.2s\n",
      "389:\tlearn: 52.2293795\ttotal: 8.46s\tremaining: 13.2s\n",
      "390:\tlearn: 52.2263964\ttotal: 8.48s\tremaining: 13.2s\n",
      "391:\tlearn: 52.2225619\ttotal: 8.51s\tremaining: 13.2s\n",
      "392:\tlearn: 52.2199605\ttotal: 8.53s\tremaining: 13.2s\n",
      "393:\tlearn: 52.2163335\ttotal: 8.55s\tremaining: 13.2s\n",
      "394:\tlearn: 52.2135767\ttotal: 8.57s\tremaining: 13.1s\n",
      "395:\tlearn: 52.2109246\ttotal: 8.6s\tremaining: 13.1s\n",
      "396:\tlearn: 52.2085744\ttotal: 8.63s\tremaining: 13.1s\n",
      "397:\tlearn: 52.2049683\ttotal: 8.65s\tremaining: 13.1s\n",
      "398:\tlearn: 52.2026586\ttotal: 8.68s\tremaining: 13.1s\n",
      "399:\tlearn: 52.1991579\ttotal: 8.7s\tremaining: 13.1s\n",
      "400:\tlearn: 52.1965213\ttotal: 8.72s\tremaining: 13s\n",
      "401:\tlearn: 52.1941382\ttotal: 8.75s\tremaining: 13s\n",
      "402:\tlearn: 52.1923376\ttotal: 8.77s\tremaining: 13s\n",
      "403:\tlearn: 52.1877033\ttotal: 8.79s\tremaining: 13s\n",
      "404:\tlearn: 52.1856668\ttotal: 8.81s\tremaining: 12.9s\n",
      "405:\tlearn: 52.1822533\ttotal: 8.84s\tremaining: 12.9s\n",
      "406:\tlearn: 52.1798794\ttotal: 8.86s\tremaining: 12.9s\n",
      "407:\tlearn: 52.1729316\ttotal: 8.88s\tremaining: 12.9s\n",
      "408:\tlearn: 52.1668537\ttotal: 8.92s\tremaining: 12.9s\n",
      "409:\tlearn: 52.1640264\ttotal: 8.95s\tremaining: 12.9s\n",
      "410:\tlearn: 52.1612922\ttotal: 8.97s\tremaining: 12.9s\n",
      "411:\tlearn: 52.1580438\ttotal: 9s\tremaining: 12.8s\n",
      "412:\tlearn: 52.1554810\ttotal: 9.03s\tremaining: 12.8s\n",
      "413:\tlearn: 52.1537731\ttotal: 9.06s\tremaining: 12.8s\n",
      "414:\tlearn: 52.1498097\ttotal: 9.09s\tremaining: 12.8s\n",
      "415:\tlearn: 52.1456206\ttotal: 9.11s\tremaining: 12.8s\n",
      "416:\tlearn: 52.1425264\ttotal: 9.13s\tremaining: 12.8s\n",
      "417:\tlearn: 52.1409926\ttotal: 9.16s\tremaining: 12.7s\n",
      "418:\tlearn: 52.1381870\ttotal: 9.18s\tremaining: 12.7s\n",
      "419:\tlearn: 52.1340836\ttotal: 9.21s\tremaining: 12.7s\n",
      "420:\tlearn: 52.1320469\ttotal: 9.23s\tremaining: 12.7s\n",
      "421:\tlearn: 52.1293684\ttotal: 9.26s\tremaining: 12.7s\n",
      "422:\tlearn: 52.1247112\ttotal: 9.28s\tremaining: 12.7s\n",
      "423:\tlearn: 52.1232133\ttotal: 9.3s\tremaining: 12.6s\n",
      "424:\tlearn: 52.1190980\ttotal: 9.33s\tremaining: 12.6s\n",
      "425:\tlearn: 52.1143926\ttotal: 9.35s\tremaining: 12.6s\n",
      "426:\tlearn: 52.1106442\ttotal: 9.37s\tremaining: 12.6s\n",
      "427:\tlearn: 52.0989983\ttotal: 9.39s\tremaining: 12.6s\n",
      "428:\tlearn: 52.0972144\ttotal: 9.42s\tremaining: 12.5s\n",
      "429:\tlearn: 52.0940311\ttotal: 9.44s\tremaining: 12.5s\n",
      "430:\tlearn: 52.0906709\ttotal: 9.46s\tremaining: 12.5s\n",
      "431:\tlearn: 52.0868089\ttotal: 9.48s\tremaining: 12.5s\n",
      "432:\tlearn: 52.0826244\ttotal: 9.51s\tremaining: 12.5s\n",
      "433:\tlearn: 52.0783739\ttotal: 9.54s\tremaining: 12.4s\n",
      "434:\tlearn: 52.0745195\ttotal: 9.57s\tremaining: 12.4s\n",
      "435:\tlearn: 52.0726134\ttotal: 9.6s\tremaining: 12.4s\n",
      "436:\tlearn: 52.0606481\ttotal: 9.63s\tremaining: 12.4s\n",
      "437:\tlearn: 52.0580992\ttotal: 9.65s\tremaining: 12.4s\n",
      "438:\tlearn: 52.0558126\ttotal: 9.68s\tremaining: 12.4s\n",
      "439:\tlearn: 52.0515276\ttotal: 9.71s\tremaining: 12.4s\n",
      "440:\tlearn: 52.0476219\ttotal: 9.75s\tremaining: 12.4s\n",
      "441:\tlearn: 52.0453753\ttotal: 9.78s\tremaining: 12.3s\n",
      "442:\tlearn: 52.0432344\ttotal: 9.8s\tremaining: 12.3s\n",
      "443:\tlearn: 52.0406209\ttotal: 9.83s\tremaining: 12.3s\n",
      "444:\tlearn: 52.0379905\ttotal: 9.86s\tremaining: 12.3s\n",
      "445:\tlearn: 52.0354372\ttotal: 9.88s\tremaining: 12.3s\n",
      "446:\tlearn: 52.0327830\ttotal: 9.9s\tremaining: 12.3s\n",
      "447:\tlearn: 52.0297968\ttotal: 9.93s\tremaining: 12.2s\n",
      "448:\tlearn: 52.0276268\ttotal: 9.95s\tremaining: 12.2s\n",
      "449:\tlearn: 52.0246755\ttotal: 9.97s\tremaining: 12.2s\n",
      "450:\tlearn: 52.0221488\ttotal: 9.99s\tremaining: 12.2s\n",
      "451:\tlearn: 52.0198426\ttotal: 10s\tremaining: 12.1s\n",
      "452:\tlearn: 52.0183537\ttotal: 10s\tremaining: 12.1s\n",
      "453:\tlearn: 52.0169204\ttotal: 10.1s\tremaining: 12.1s\n",
      "454:\tlearn: 52.0131914\ttotal: 10.1s\tremaining: 12.1s\n",
      "455:\tlearn: 52.0070418\ttotal: 10.1s\tremaining: 12.1s\n",
      "456:\tlearn: 52.0047070\ttotal: 10.1s\tremaining: 12s\n",
      "457:\tlearn: 52.0017661\ttotal: 10.2s\tremaining: 12s\n",
      "458:\tlearn: 51.9990161\ttotal: 10.2s\tremaining: 12s\n",
      "459:\tlearn: 51.9943812\ttotal: 10.2s\tremaining: 12s\n",
      "460:\tlearn: 51.9894221\ttotal: 10.2s\tremaining: 12s\n",
      "461:\tlearn: 51.9804381\ttotal: 10.2s\tremaining: 11.9s\n",
      "462:\tlearn: 51.9790800\ttotal: 10.3s\tremaining: 11.9s\n",
      "463:\tlearn: 51.9767123\ttotal: 10.3s\tremaining: 11.9s\n",
      "464:\tlearn: 51.9727379\ttotal: 10.3s\tremaining: 11.9s\n",
      "465:\tlearn: 51.9713145\ttotal: 10.3s\tremaining: 11.9s\n",
      "466:\tlearn: 51.9677962\ttotal: 10.4s\tremaining: 11.8s\n",
      "467:\tlearn: 51.9650702\ttotal: 10.4s\tremaining: 11.8s\n",
      "468:\tlearn: 51.9627331\ttotal: 10.4s\tremaining: 11.8s\n",
      "469:\tlearn: 51.9597265\ttotal: 10.4s\tremaining: 11.8s\n",
      "470:\tlearn: 51.9583036\ttotal: 10.5s\tremaining: 11.7s\n",
      "471:\tlearn: 51.9578307\ttotal: 10.5s\tremaining: 11.7s\n",
      "472:\tlearn: 51.9567300\ttotal: 10.5s\tremaining: 11.7s\n",
      "473:\tlearn: 51.9557696\ttotal: 10.5s\tremaining: 11.7s\n",
      "474:\tlearn: 51.9519289\ttotal: 10.6s\tremaining: 11.7s\n",
      "475:\tlearn: 51.9479231\ttotal: 10.6s\tremaining: 11.6s\n",
      "476:\tlearn: 51.9368495\ttotal: 10.6s\tremaining: 11.6s\n",
      "477:\tlearn: 51.9349102\ttotal: 10.6s\tremaining: 11.6s\n",
      "478:\tlearn: 51.9314189\ttotal: 10.6s\tremaining: 11.6s\n",
      "479:\tlearn: 51.9265058\ttotal: 10.7s\tremaining: 11.6s\n",
      "480:\tlearn: 51.9232167\ttotal: 10.7s\tremaining: 11.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481:\tlearn: 51.9194108\ttotal: 10.7s\tremaining: 11.5s\n",
      "482:\tlearn: 51.9146145\ttotal: 10.7s\tremaining: 11.5s\n",
      "483:\tlearn: 51.9122090\ttotal: 10.8s\tremaining: 11.5s\n",
      "484:\tlearn: 51.9114910\ttotal: 10.8s\tremaining: 11.5s\n",
      "485:\tlearn: 51.9072300\ttotal: 10.8s\tremaining: 11.4s\n",
      "486:\tlearn: 51.9021424\ttotal: 10.8s\tremaining: 11.4s\n",
      "487:\tlearn: 51.9005626\ttotal: 10.9s\tremaining: 11.4s\n",
      "488:\tlearn: 51.8968184\ttotal: 10.9s\tremaining: 11.4s\n",
      "489:\tlearn: 51.8966366\ttotal: 10.9s\tremaining: 11.3s\n",
      "490:\tlearn: 51.8936948\ttotal: 10.9s\tremaining: 11.3s\n",
      "491:\tlearn: 51.8855795\ttotal: 11s\tremaining: 11.3s\n",
      "492:\tlearn: 51.8810905\ttotal: 11s\tremaining: 11.3s\n",
      "493:\tlearn: 51.8784940\ttotal: 11s\tremaining: 11.3s\n",
      "494:\tlearn: 51.8710511\ttotal: 11s\tremaining: 11.2s\n",
      "495:\tlearn: 51.8683771\ttotal: 11.1s\tremaining: 11.2s\n",
      "496:\tlearn: 51.8631542\ttotal: 11.1s\tremaining: 11.2s\n",
      "497:\tlearn: 51.8603523\ttotal: 11.1s\tremaining: 11.2s\n",
      "498:\tlearn: 51.8520004\ttotal: 11.1s\tremaining: 11.2s\n",
      "499:\tlearn: 51.8489768\ttotal: 11.1s\tremaining: 11.1s\n",
      "500:\tlearn: 51.8476353\ttotal: 11.2s\tremaining: 11.1s\n",
      "501:\tlearn: 51.8445667\ttotal: 11.2s\tremaining: 11.1s\n",
      "502:\tlearn: 51.8423417\ttotal: 11.2s\tremaining: 11.1s\n",
      "503:\tlearn: 51.8396334\ttotal: 11.2s\tremaining: 11s\n",
      "504:\tlearn: 51.8365112\ttotal: 11.2s\tremaining: 11s\n",
      "505:\tlearn: 51.8345627\ttotal: 11.3s\tremaining: 11s\n",
      "506:\tlearn: 51.8320726\ttotal: 11.3s\tremaining: 11s\n",
      "507:\tlearn: 51.8298891\ttotal: 11.3s\tremaining: 10.9s\n",
      "508:\tlearn: 51.8259832\ttotal: 11.3s\tremaining: 10.9s\n",
      "509:\tlearn: 51.8223089\ttotal: 11.4s\tremaining: 10.9s\n",
      "510:\tlearn: 51.8186210\ttotal: 11.4s\tremaining: 10.9s\n",
      "511:\tlearn: 51.8107947\ttotal: 11.4s\tremaining: 10.9s\n",
      "512:\tlearn: 51.8097137\ttotal: 11.4s\tremaining: 10.9s\n",
      "513:\tlearn: 51.8072822\ttotal: 11.5s\tremaining: 10.8s\n",
      "514:\tlearn: 51.8034497\ttotal: 11.5s\tremaining: 10.8s\n",
      "515:\tlearn: 51.8012037\ttotal: 11.5s\tremaining: 10.8s\n",
      "516:\tlearn: 51.7981819\ttotal: 11.5s\tremaining: 10.8s\n",
      "517:\tlearn: 51.7947675\ttotal: 11.5s\tremaining: 10.7s\n",
      "518:\tlearn: 51.7928048\ttotal: 11.6s\tremaining: 10.7s\n",
      "519:\tlearn: 51.7894959\ttotal: 11.6s\tremaining: 10.7s\n",
      "520:\tlearn: 51.7868988\ttotal: 11.6s\tremaining: 10.7s\n",
      "521:\tlearn: 51.7847449\ttotal: 11.6s\tremaining: 10.7s\n",
      "522:\tlearn: 51.7821862\ttotal: 11.7s\tremaining: 10.6s\n",
      "523:\tlearn: 51.7786497\ttotal: 11.7s\tremaining: 10.6s\n",
      "524:\tlearn: 51.7756591\ttotal: 11.7s\tremaining: 10.6s\n",
      "525:\tlearn: 51.7715534\ttotal: 11.7s\tremaining: 10.6s\n",
      "526:\tlearn: 51.7620803\ttotal: 11.8s\tremaining: 10.5s\n",
      "527:\tlearn: 51.7570567\ttotal: 11.8s\tremaining: 10.5s\n",
      "528:\tlearn: 51.7541385\ttotal: 11.8s\tremaining: 10.5s\n",
      "529:\tlearn: 51.7516628\ttotal: 11.8s\tremaining: 10.5s\n",
      "530:\tlearn: 51.7411040\ttotal: 11.8s\tremaining: 10.5s\n",
      "531:\tlearn: 51.7379249\ttotal: 11.9s\tremaining: 10.4s\n",
      "532:\tlearn: 51.7354200\ttotal: 11.9s\tremaining: 10.4s\n",
      "533:\tlearn: 51.7319722\ttotal: 11.9s\tremaining: 10.4s\n",
      "534:\tlearn: 51.7290152\ttotal: 11.9s\tremaining: 10.4s\n",
      "535:\tlearn: 51.7266989\ttotal: 12s\tremaining: 10.4s\n",
      "536:\tlearn: 51.7247261\ttotal: 12s\tremaining: 10.3s\n",
      "537:\tlearn: 51.7226795\ttotal: 12s\tremaining: 10.3s\n",
      "538:\tlearn: 51.7207367\ttotal: 12s\tremaining: 10.3s\n",
      "539:\tlearn: 51.7200855\ttotal: 12.1s\tremaining: 10.3s\n",
      "540:\tlearn: 51.7178371\ttotal: 12.1s\tremaining: 10.2s\n",
      "541:\tlearn: 51.7158393\ttotal: 12.1s\tremaining: 10.2s\n",
      "542:\tlearn: 51.7130735\ttotal: 12.1s\tremaining: 10.2s\n",
      "543:\tlearn: 51.7113532\ttotal: 12.1s\tremaining: 10.2s\n",
      "544:\tlearn: 51.7101172\ttotal: 12.2s\tremaining: 10.2s\n",
      "545:\tlearn: 51.7056972\ttotal: 12.2s\tremaining: 10.1s\n",
      "546:\tlearn: 51.7033084\ttotal: 12.2s\tremaining: 10.1s\n",
      "547:\tlearn: 51.7006108\ttotal: 12.2s\tremaining: 10.1s\n",
      "548:\tlearn: 51.6974806\ttotal: 12.2s\tremaining: 10.1s\n",
      "549:\tlearn: 51.6927556\ttotal: 12.3s\tremaining: 10s\n",
      "550:\tlearn: 51.6908955\ttotal: 12.3s\tremaining: 10s\n",
      "551:\tlearn: 51.6897333\ttotal: 12.3s\tremaining: 9.99s\n",
      "552:\tlearn: 51.6828411\ttotal: 12.3s\tremaining: 9.96s\n",
      "553:\tlearn: 51.6779983\ttotal: 12.3s\tremaining: 9.94s\n",
      "554:\tlearn: 51.6748818\ttotal: 12.4s\tremaining: 9.92s\n",
      "555:\tlearn: 51.6727462\ttotal: 12.4s\tremaining: 9.89s\n",
      "556:\tlearn: 51.6702899\ttotal: 12.4s\tremaining: 9.87s\n",
      "557:\tlearn: 51.6694117\ttotal: 12.4s\tremaining: 9.85s\n",
      "558:\tlearn: 51.6669613\ttotal: 12.5s\tremaining: 9.83s\n",
      "559:\tlearn: 51.6624321\ttotal: 12.5s\tremaining: 9.81s\n",
      "560:\tlearn: 51.6582511\ttotal: 12.5s\tremaining: 9.79s\n",
      "561:\tlearn: 51.6554920\ttotal: 12.5s\tremaining: 9.77s\n",
      "562:\tlearn: 51.6532391\ttotal: 12.6s\tremaining: 9.74s\n",
      "563:\tlearn: 51.6508971\ttotal: 12.6s\tremaining: 9.72s\n",
      "564:\tlearn: 51.6482074\ttotal: 12.6s\tremaining: 9.7s\n",
      "565:\tlearn: 51.6437255\ttotal: 12.6s\tremaining: 9.67s\n",
      "566:\tlearn: 51.6426644\ttotal: 12.6s\tremaining: 9.65s\n",
      "567:\tlearn: 51.6404392\ttotal: 12.7s\tremaining: 9.63s\n",
      "568:\tlearn: 51.6349046\ttotal: 12.7s\tremaining: 9.6s\n",
      "569:\tlearn: 51.6324036\ttotal: 12.7s\tremaining: 9.58s\n",
      "570:\tlearn: 51.6226161\ttotal: 12.7s\tremaining: 9.56s\n",
      "571:\tlearn: 51.6193354\ttotal: 12.7s\tremaining: 9.54s\n",
      "572:\tlearn: 51.6170479\ttotal: 12.8s\tremaining: 9.51s\n",
      "573:\tlearn: 51.6155079\ttotal: 12.8s\tremaining: 9.49s\n",
      "574:\tlearn: 51.6092902\ttotal: 12.8s\tremaining: 9.47s\n",
      "575:\tlearn: 51.6060752\ttotal: 12.8s\tremaining: 9.45s\n",
      "576:\tlearn: 51.6024934\ttotal: 12.9s\tremaining: 9.42s\n",
      "577:\tlearn: 51.5942467\ttotal: 12.9s\tremaining: 9.4s\n",
      "578:\tlearn: 51.5914078\ttotal: 12.9s\tremaining: 9.37s\n",
      "579:\tlearn: 51.5893782\ttotal: 12.9s\tremaining: 9.35s\n",
      "580:\tlearn: 51.5845096\ttotal: 12.9s\tremaining: 9.33s\n",
      "581:\tlearn: 51.5836727\ttotal: 13s\tremaining: 9.3s\n",
      "582:\tlearn: 51.5803173\ttotal: 13s\tremaining: 9.28s\n",
      "583:\tlearn: 51.5795165\ttotal: 13s\tremaining: 9.26s\n",
      "584:\tlearn: 51.5767760\ttotal: 13s\tremaining: 9.24s\n",
      "585:\tlearn: 51.5748562\ttotal: 13s\tremaining: 9.22s\n",
      "586:\tlearn: 51.5684107\ttotal: 13.1s\tremaining: 9.19s\n",
      "587:\tlearn: 51.5672040\ttotal: 13.1s\tremaining: 9.17s\n",
      "588:\tlearn: 51.5640678\ttotal: 13.1s\tremaining: 9.15s\n",
      "589:\tlearn: 51.5614406\ttotal: 13.1s\tremaining: 9.13s\n",
      "590:\tlearn: 51.5586180\ttotal: 13.2s\tremaining: 9.1s\n",
      "591:\tlearn: 51.5505520\ttotal: 13.2s\tremaining: 9.08s\n",
      "592:\tlearn: 51.5463012\ttotal: 13.2s\tremaining: 9.06s\n",
      "593:\tlearn: 51.5410044\ttotal: 13.2s\tremaining: 9.04s\n",
      "594:\tlearn: 51.5380358\ttotal: 13.2s\tremaining: 9.01s\n",
      "595:\tlearn: 51.5344479\ttotal: 13.3s\tremaining: 8.99s\n",
      "596:\tlearn: 51.5325709\ttotal: 13.3s\tremaining: 8.97s\n",
      "597:\tlearn: 51.5315460\ttotal: 13.3s\tremaining: 8.95s\n",
      "598:\tlearn: 51.5288532\ttotal: 13.3s\tremaining: 8.93s\n",
      "599:\tlearn: 51.5244002\ttotal: 13.4s\tremaining: 8.9s\n",
      "600:\tlearn: 51.5226492\ttotal: 13.4s\tremaining: 8.88s\n",
      "601:\tlearn: 51.5134031\ttotal: 13.4s\tremaining: 8.86s\n",
      "602:\tlearn: 51.5105804\ttotal: 13.4s\tremaining: 8.84s\n",
      "603:\tlearn: 51.5078743\ttotal: 13.4s\tremaining: 8.81s\n",
      "604:\tlearn: 51.5051552\ttotal: 13.5s\tremaining: 8.79s\n",
      "605:\tlearn: 51.5040919\ttotal: 13.5s\tremaining: 8.77s\n",
      "606:\tlearn: 51.4994012\ttotal: 13.5s\tremaining: 8.74s\n",
      "607:\tlearn: 51.4963872\ttotal: 13.5s\tremaining: 8.72s\n",
      "608:\tlearn: 51.4939752\ttotal: 13.5s\tremaining: 8.7s\n",
      "609:\tlearn: 51.4914919\ttotal: 13.6s\tremaining: 8.68s\n",
      "610:\tlearn: 51.4879050\ttotal: 13.6s\tremaining: 8.65s\n",
      "611:\tlearn: 51.4864536\ttotal: 13.6s\tremaining: 8.63s\n",
      "612:\tlearn: 51.4825628\ttotal: 13.6s\tremaining: 8.6s\n",
      "613:\tlearn: 51.4789797\ttotal: 13.7s\tremaining: 8.58s\n",
      "614:\tlearn: 51.4778697\ttotal: 13.7s\tremaining: 8.56s\n",
      "615:\tlearn: 51.4763030\ttotal: 13.7s\tremaining: 8.54s\n",
      "616:\tlearn: 51.4742878\ttotal: 13.7s\tremaining: 8.52s\n",
      "617:\tlearn: 51.4722325\ttotal: 13.7s\tremaining: 8.49s\n",
      "618:\tlearn: 51.4695225\ttotal: 13.8s\tremaining: 8.47s\n",
      "619:\tlearn: 51.4679889\ttotal: 13.8s\tremaining: 8.45s\n",
      "620:\tlearn: 51.4671849\ttotal: 13.8s\tremaining: 8.43s\n",
      "621:\tlearn: 51.4650776\ttotal: 13.8s\tremaining: 8.41s\n",
      "622:\tlearn: 51.4626950\ttotal: 13.9s\tremaining: 8.39s\n",
      "623:\tlearn: 51.4564022\ttotal: 13.9s\tremaining: 8.36s\n",
      "624:\tlearn: 51.4542356\ttotal: 13.9s\tremaining: 8.34s\n",
      "625:\tlearn: 51.4522962\ttotal: 13.9s\tremaining: 8.32s\n",
      "626:\tlearn: 51.4498441\ttotal: 13.9s\tremaining: 8.3s\n",
      "627:\tlearn: 51.4479779\ttotal: 14s\tremaining: 8.28s\n",
      "628:\tlearn: 51.4473401\ttotal: 14s\tremaining: 8.25s\n",
      "629:\tlearn: 51.4464788\ttotal: 14s\tremaining: 8.23s\n",
      "630:\tlearn: 51.4433839\ttotal: 14s\tremaining: 8.21s\n",
      "631:\tlearn: 51.4400274\ttotal: 14.1s\tremaining: 8.19s\n",
      "632:\tlearn: 51.4329200\ttotal: 14.1s\tremaining: 8.16s\n",
      "633:\tlearn: 51.4305559\ttotal: 14.1s\tremaining: 8.14s\n",
      "634:\tlearn: 51.4243351\ttotal: 14.1s\tremaining: 8.12s\n",
      "635:\tlearn: 51.4208604\ttotal: 14.1s\tremaining: 8.09s\n",
      "636:\tlearn: 51.4182891\ttotal: 14.2s\tremaining: 8.07s\n",
      "637:\tlearn: 51.4134759\ttotal: 14.2s\tremaining: 8.05s\n",
      "638:\tlearn: 51.4110633\ttotal: 14.2s\tremaining: 8.02s\n",
      "639:\tlearn: 51.4084923\ttotal: 14.2s\tremaining: 8s\n",
      "640:\tlearn: 51.4058685\ttotal: 14.2s\tremaining: 7.98s\n",
      "641:\tlearn: 51.4042239\ttotal: 14.3s\tremaining: 7.95s\n",
      "642:\tlearn: 51.4013305\ttotal: 14.3s\tremaining: 7.93s\n",
      "643:\tlearn: 51.3981804\ttotal: 14.3s\tremaining: 7.91s\n",
      "644:\tlearn: 51.3956849\ttotal: 14.3s\tremaining: 7.88s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645:\tlearn: 51.3903901\ttotal: 14.3s\tremaining: 7.86s\n",
      "646:\tlearn: 51.3842567\ttotal: 14.4s\tremaining: 7.84s\n",
      "647:\tlearn: 51.3820029\ttotal: 14.4s\tremaining: 7.82s\n",
      "648:\tlearn: 51.3787724\ttotal: 14.4s\tremaining: 7.79s\n",
      "649:\tlearn: 51.3738152\ttotal: 14.4s\tremaining: 7.77s\n",
      "650:\tlearn: 51.3695031\ttotal: 14.4s\tremaining: 7.74s\n",
      "651:\tlearn: 51.3668916\ttotal: 14.5s\tremaining: 7.72s\n",
      "652:\tlearn: 51.3639653\ttotal: 14.5s\tremaining: 7.7s\n",
      "653:\tlearn: 51.3603389\ttotal: 14.5s\tremaining: 7.67s\n",
      "654:\tlearn: 51.3568555\ttotal: 14.5s\tremaining: 7.65s\n",
      "655:\tlearn: 51.3486172\ttotal: 14.5s\tremaining: 7.63s\n",
      "656:\tlearn: 51.3468928\ttotal: 14.6s\tremaining: 7.6s\n",
      "657:\tlearn: 51.3446626\ttotal: 14.6s\tremaining: 7.58s\n",
      "658:\tlearn: 51.3417201\ttotal: 14.6s\tremaining: 7.56s\n",
      "659:\tlearn: 51.3385301\ttotal: 14.6s\tremaining: 7.54s\n",
      "660:\tlearn: 51.3362330\ttotal: 14.7s\tremaining: 7.51s\n",
      "661:\tlearn: 51.3330344\ttotal: 14.7s\tremaining: 7.49s\n",
      "662:\tlearn: 51.3302188\ttotal: 14.7s\tremaining: 7.47s\n",
      "663:\tlearn: 51.3270551\ttotal: 14.7s\tremaining: 7.44s\n",
      "664:\tlearn: 51.3198409\ttotal: 14.7s\tremaining: 7.42s\n",
      "665:\tlearn: 51.3172971\ttotal: 14.7s\tremaining: 7.4s\n",
      "666:\tlearn: 51.3132808\ttotal: 14.8s\tremaining: 7.37s\n",
      "667:\tlearn: 51.3108483\ttotal: 14.8s\tremaining: 7.35s\n",
      "668:\tlearn: 51.3059070\ttotal: 14.8s\tremaining: 7.33s\n",
      "669:\tlearn: 51.3027913\ttotal: 14.8s\tremaining: 7.31s\n",
      "670:\tlearn: 51.2952800\ttotal: 14.9s\tremaining: 7.28s\n",
      "671:\tlearn: 51.2943143\ttotal: 14.9s\tremaining: 7.26s\n",
      "672:\tlearn: 51.2886845\ttotal: 14.9s\tremaining: 7.24s\n",
      "673:\tlearn: 51.2867945\ttotal: 14.9s\tremaining: 7.22s\n",
      "674:\tlearn: 51.2850332\ttotal: 14.9s\tremaining: 7.19s\n",
      "675:\tlearn: 51.2828220\ttotal: 15s\tremaining: 7.17s\n",
      "676:\tlearn: 51.2806367\ttotal: 15s\tremaining: 7.15s\n",
      "677:\tlearn: 51.2787881\ttotal: 15s\tremaining: 7.13s\n",
      "678:\tlearn: 51.2741134\ttotal: 15s\tremaining: 7.11s\n",
      "679:\tlearn: 51.2715654\ttotal: 15.1s\tremaining: 7.08s\n",
      "680:\tlearn: 51.2691114\ttotal: 15.1s\tremaining: 7.06s\n",
      "681:\tlearn: 51.2657722\ttotal: 15.1s\tremaining: 7.04s\n",
      "682:\tlearn: 51.2642819\ttotal: 15.1s\tremaining: 7.02s\n",
      "683:\tlearn: 51.2611721\ttotal: 15.1s\tremaining: 7s\n",
      "684:\tlearn: 51.2578028\ttotal: 15.2s\tremaining: 6.97s\n",
      "685:\tlearn: 51.2500280\ttotal: 15.2s\tremaining: 6.95s\n",
      "686:\tlearn: 51.2463748\ttotal: 15.2s\tremaining: 6.93s\n",
      "687:\tlearn: 51.2444260\ttotal: 15.2s\tremaining: 6.91s\n",
      "688:\tlearn: 51.2419816\ttotal: 15.3s\tremaining: 6.88s\n",
      "689:\tlearn: 51.2396248\ttotal: 15.3s\tremaining: 6.86s\n",
      "690:\tlearn: 51.2373261\ttotal: 15.3s\tremaining: 6.84s\n",
      "691:\tlearn: 51.2345415\ttotal: 15.3s\tremaining: 6.82s\n",
      "692:\tlearn: 51.2321425\ttotal: 15.3s\tremaining: 6.8s\n",
      "693:\tlearn: 51.2299669\ttotal: 15.4s\tremaining: 6.78s\n",
      "694:\tlearn: 51.2223984\ttotal: 15.4s\tremaining: 6.75s\n",
      "695:\tlearn: 51.2205410\ttotal: 15.4s\tremaining: 6.73s\n",
      "696:\tlearn: 51.2178168\ttotal: 15.4s\tremaining: 6.71s\n",
      "697:\tlearn: 51.2113422\ttotal: 15.5s\tremaining: 6.69s\n",
      "698:\tlearn: 51.2092963\ttotal: 15.5s\tremaining: 6.67s\n",
      "699:\tlearn: 51.2083793\ttotal: 15.5s\tremaining: 6.64s\n",
      "700:\tlearn: 51.2061970\ttotal: 15.5s\tremaining: 6.62s\n",
      "701:\tlearn: 51.2027493\ttotal: 15.5s\tremaining: 6.6s\n",
      "702:\tlearn: 51.1983235\ttotal: 15.6s\tremaining: 6.58s\n",
      "703:\tlearn: 51.1951912\ttotal: 15.6s\tremaining: 6.55s\n",
      "704:\tlearn: 51.1935332\ttotal: 15.6s\tremaining: 6.53s\n",
      "705:\tlearn: 51.1923790\ttotal: 15.6s\tremaining: 6.51s\n",
      "706:\tlearn: 51.1899266\ttotal: 15.7s\tremaining: 6.49s\n",
      "707:\tlearn: 51.1852336\ttotal: 15.7s\tremaining: 6.47s\n",
      "708:\tlearn: 51.1822202\ttotal: 15.7s\tremaining: 6.45s\n",
      "709:\tlearn: 51.1793466\ttotal: 15.7s\tremaining: 6.42s\n",
      "710:\tlearn: 51.1754348\ttotal: 15.8s\tremaining: 6.4s\n",
      "711:\tlearn: 51.1732603\ttotal: 15.8s\tremaining: 6.38s\n",
      "712:\tlearn: 51.1717165\ttotal: 15.8s\tremaining: 6.36s\n",
      "713:\tlearn: 51.1694824\ttotal: 15.8s\tremaining: 6.34s\n",
      "714:\tlearn: 51.1638662\ttotal: 15.8s\tremaining: 6.31s\n",
      "715:\tlearn: 51.1611817\ttotal: 15.9s\tremaining: 6.29s\n",
      "716:\tlearn: 51.1587355\ttotal: 15.9s\tremaining: 6.27s\n",
      "717:\tlearn: 51.1564540\ttotal: 15.9s\tremaining: 6.24s\n",
      "718:\tlearn: 51.1538845\ttotal: 15.9s\tremaining: 6.22s\n",
      "719:\tlearn: 51.1509910\ttotal: 15.9s\tremaining: 6.2s\n",
      "720:\tlearn: 51.1485396\ttotal: 16s\tremaining: 6.18s\n",
      "721:\tlearn: 51.1471603\ttotal: 16s\tremaining: 6.16s\n",
      "722:\tlearn: 51.1439851\ttotal: 16s\tremaining: 6.13s\n",
      "723:\tlearn: 51.1416139\ttotal: 16s\tremaining: 6.11s\n",
      "724:\tlearn: 51.1367320\ttotal: 16.1s\tremaining: 6.09s\n",
      "725:\tlearn: 51.1348795\ttotal: 16.1s\tremaining: 6.07s\n",
      "726:\tlearn: 51.1312496\ttotal: 16.1s\tremaining: 6.05s\n",
      "727:\tlearn: 51.1280183\ttotal: 16.1s\tremaining: 6.02s\n",
      "728:\tlearn: 51.1237687\ttotal: 16.1s\tremaining: 6s\n",
      "729:\tlearn: 51.1221073\ttotal: 16.2s\tremaining: 5.98s\n",
      "730:\tlearn: 51.1197981\ttotal: 16.2s\tremaining: 5.96s\n",
      "731:\tlearn: 51.1182297\ttotal: 16.2s\tremaining: 5.93s\n",
      "732:\tlearn: 51.1153591\ttotal: 16.2s\tremaining: 5.91s\n",
      "733:\tlearn: 51.1124570\ttotal: 16.2s\tremaining: 5.89s\n",
      "734:\tlearn: 51.1111485\ttotal: 16.3s\tremaining: 5.86s\n",
      "735:\tlearn: 51.1028236\ttotal: 16.3s\tremaining: 5.84s\n",
      "736:\tlearn: 51.1003879\ttotal: 16.3s\tremaining: 5.82s\n",
      "737:\tlearn: 51.0986451\ttotal: 16.3s\tremaining: 5.8s\n",
      "738:\tlearn: 51.0971532\ttotal: 16.4s\tremaining: 5.78s\n",
      "739:\tlearn: 51.0963093\ttotal: 16.4s\tremaining: 5.75s\n",
      "740:\tlearn: 51.0935078\ttotal: 16.4s\tremaining: 5.73s\n",
      "741:\tlearn: 51.0918103\ttotal: 16.4s\tremaining: 5.71s\n",
      "742:\tlearn: 51.0886187\ttotal: 16.4s\tremaining: 5.68s\n",
      "743:\tlearn: 51.0857885\ttotal: 16.5s\tremaining: 5.66s\n",
      "744:\tlearn: 51.0842197\ttotal: 16.5s\tremaining: 5.64s\n",
      "745:\tlearn: 51.0817922\ttotal: 16.5s\tremaining: 5.62s\n",
      "746:\tlearn: 51.0803517\ttotal: 16.5s\tremaining: 5.59s\n",
      "747:\tlearn: 51.0783345\ttotal: 16.5s\tremaining: 5.57s\n",
      "748:\tlearn: 51.0759034\ttotal: 16.6s\tremaining: 5.55s\n",
      "749:\tlearn: 51.0743190\ttotal: 16.6s\tremaining: 5.53s\n",
      "750:\tlearn: 51.0724219\ttotal: 16.6s\tremaining: 5.51s\n",
      "751:\tlearn: 51.0692583\ttotal: 16.6s\tremaining: 5.49s\n",
      "752:\tlearn: 51.0671674\ttotal: 16.7s\tremaining: 5.46s\n",
      "753:\tlearn: 51.0656722\ttotal: 16.7s\tremaining: 5.44s\n",
      "754:\tlearn: 51.0613902\ttotal: 16.7s\tremaining: 5.42s\n",
      "755:\tlearn: 51.0591766\ttotal: 16.7s\tremaining: 5.4s\n",
      "756:\tlearn: 51.0568950\ttotal: 16.8s\tremaining: 5.38s\n",
      "757:\tlearn: 51.0547217\ttotal: 16.8s\tremaining: 5.36s\n",
      "758:\tlearn: 51.0521512\ttotal: 16.8s\tremaining: 5.33s\n",
      "759:\tlearn: 51.0502671\ttotal: 16.8s\tremaining: 5.31s\n",
      "760:\tlearn: 51.0472940\ttotal: 16.8s\tremaining: 5.29s\n",
      "761:\tlearn: 51.0444565\ttotal: 16.9s\tremaining: 5.27s\n",
      "762:\tlearn: 51.0430435\ttotal: 16.9s\tremaining: 5.25s\n",
      "763:\tlearn: 51.0403253\ttotal: 16.9s\tremaining: 5.22s\n",
      "764:\tlearn: 51.0388621\ttotal: 16.9s\tremaining: 5.2s\n",
      "765:\tlearn: 51.0366429\ttotal: 17s\tremaining: 5.18s\n",
      "766:\tlearn: 51.0336897\ttotal: 17s\tremaining: 5.16s\n",
      "767:\tlearn: 51.0303741\ttotal: 17s\tremaining: 5.14s\n",
      "768:\tlearn: 51.0277131\ttotal: 17s\tremaining: 5.12s\n",
      "769:\tlearn: 51.0258724\ttotal: 17.1s\tremaining: 5.09s\n",
      "770:\tlearn: 51.0223755\ttotal: 17.1s\tremaining: 5.07s\n",
      "771:\tlearn: 51.0208789\ttotal: 17.1s\tremaining: 5.05s\n",
      "772:\tlearn: 51.0163039\ttotal: 17.1s\tremaining: 5.03s\n",
      "773:\tlearn: 51.0145043\ttotal: 17.2s\tremaining: 5.01s\n",
      "774:\tlearn: 51.0122413\ttotal: 17.2s\tremaining: 4.99s\n",
      "775:\tlearn: 51.0038378\ttotal: 17.2s\tremaining: 4.97s\n",
      "776:\tlearn: 51.0001787\ttotal: 17.2s\tremaining: 4.94s\n",
      "777:\tlearn: 50.9988008\ttotal: 17.2s\tremaining: 4.92s\n",
      "778:\tlearn: 50.9980093\ttotal: 17.3s\tremaining: 4.9s\n",
      "779:\tlearn: 50.9938343\ttotal: 17.3s\tremaining: 4.88s\n",
      "780:\tlearn: 50.9914049\ttotal: 17.3s\tremaining: 4.85s\n",
      "781:\tlearn: 50.9885889\ttotal: 17.3s\tremaining: 4.83s\n",
      "782:\tlearn: 50.9874119\ttotal: 17.3s\tremaining: 4.81s\n",
      "783:\tlearn: 50.9841005\ttotal: 17.4s\tremaining: 4.78s\n",
      "784:\tlearn: 50.9827206\ttotal: 17.4s\tremaining: 4.76s\n",
      "785:\tlearn: 50.9804066\ttotal: 17.4s\tremaining: 4.74s\n",
      "786:\tlearn: 50.9784279\ttotal: 17.4s\tremaining: 4.71s\n",
      "787:\tlearn: 50.9754324\ttotal: 17.4s\tremaining: 4.69s\n",
      "788:\tlearn: 50.9728703\ttotal: 17.5s\tremaining: 4.67s\n",
      "789:\tlearn: 50.9686957\ttotal: 17.5s\tremaining: 4.65s\n",
      "790:\tlearn: 50.9669821\ttotal: 17.5s\tremaining: 4.63s\n",
      "791:\tlearn: 50.9656799\ttotal: 17.5s\tremaining: 4.6s\n",
      "792:\tlearn: 50.9652577\ttotal: 17.5s\tremaining: 4.58s\n",
      "793:\tlearn: 50.9630475\ttotal: 17.6s\tremaining: 4.56s\n",
      "794:\tlearn: 50.9586185\ttotal: 17.6s\tremaining: 4.54s\n",
      "795:\tlearn: 50.9563006\ttotal: 17.6s\tremaining: 4.51s\n",
      "796:\tlearn: 50.9543631\ttotal: 17.6s\tremaining: 4.49s\n",
      "797:\tlearn: 50.9532461\ttotal: 17.7s\tremaining: 4.47s\n",
      "798:\tlearn: 50.9504175\ttotal: 17.7s\tremaining: 4.45s\n",
      "799:\tlearn: 50.9478531\ttotal: 17.7s\tremaining: 4.42s\n",
      "800:\tlearn: 50.9460319\ttotal: 17.7s\tremaining: 4.4s\n",
      "801:\tlearn: 50.9456311\ttotal: 17.8s\tremaining: 4.38s\n",
      "802:\tlearn: 50.9442401\ttotal: 17.8s\tremaining: 4.36s\n",
      "803:\tlearn: 50.9415373\ttotal: 17.8s\tremaining: 4.34s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804:\tlearn: 50.9379309\ttotal: 17.8s\tremaining: 4.32s\n",
      "805:\tlearn: 50.9364707\ttotal: 17.8s\tremaining: 4.29s\n",
      "806:\tlearn: 50.9313529\ttotal: 17.9s\tremaining: 4.27s\n",
      "807:\tlearn: 50.9296449\ttotal: 17.9s\tremaining: 4.25s\n",
      "808:\tlearn: 50.9251045\ttotal: 17.9s\tremaining: 4.23s\n",
      "809:\tlearn: 50.9247244\ttotal: 17.9s\tremaining: 4.21s\n",
      "810:\tlearn: 50.9205128\ttotal: 17.9s\tremaining: 4.18s\n",
      "811:\tlearn: 50.9128077\ttotal: 18s\tremaining: 4.16s\n",
      "812:\tlearn: 50.9110448\ttotal: 18s\tremaining: 4.14s\n",
      "813:\tlearn: 50.9096390\ttotal: 18s\tremaining: 4.12s\n",
      "814:\tlearn: 50.9092969\ttotal: 18s\tremaining: 4.09s\n",
      "815:\tlearn: 50.9080049\ttotal: 18.1s\tremaining: 4.07s\n",
      "816:\tlearn: 50.9039704\ttotal: 18.1s\tremaining: 4.05s\n",
      "817:\tlearn: 50.9018994\ttotal: 18.1s\tremaining: 4.03s\n",
      "818:\tlearn: 50.8959820\ttotal: 18.1s\tremaining: 4s\n",
      "819:\tlearn: 50.8925540\ttotal: 18.1s\tremaining: 3.98s\n",
      "820:\tlearn: 50.8891788\ttotal: 18.2s\tremaining: 3.96s\n",
      "821:\tlearn: 50.8876036\ttotal: 18.2s\tremaining: 3.94s\n",
      "822:\tlearn: 50.8847677\ttotal: 18.2s\tremaining: 3.92s\n",
      "823:\tlearn: 50.8830858\ttotal: 18.2s\tremaining: 3.89s\n",
      "824:\tlearn: 50.8792789\ttotal: 18.2s\tremaining: 3.87s\n",
      "825:\tlearn: 50.8742274\ttotal: 18.3s\tremaining: 3.85s\n",
      "826:\tlearn: 50.8710520\ttotal: 18.3s\tremaining: 3.83s\n",
      "827:\tlearn: 50.8698195\ttotal: 18.3s\tremaining: 3.8s\n",
      "828:\tlearn: 50.8631667\ttotal: 18.3s\tremaining: 3.78s\n",
      "829:\tlearn: 50.8600569\ttotal: 18.4s\tremaining: 3.76s\n",
      "830:\tlearn: 50.8575038\ttotal: 18.4s\tremaining: 3.74s\n",
      "831:\tlearn: 50.8507327\ttotal: 18.4s\tremaining: 3.72s\n",
      "832:\tlearn: 50.8466566\ttotal: 18.4s\tremaining: 3.69s\n",
      "833:\tlearn: 50.8410077\ttotal: 18.5s\tremaining: 3.67s\n",
      "834:\tlearn: 50.8383200\ttotal: 18.5s\tremaining: 3.65s\n",
      "835:\tlearn: 50.8362433\ttotal: 18.5s\tremaining: 3.63s\n",
      "836:\tlearn: 50.8334671\ttotal: 18.5s\tremaining: 3.61s\n",
      "837:\tlearn: 50.8318210\ttotal: 18.6s\tremaining: 3.59s\n",
      "838:\tlearn: 50.8252816\ttotal: 18.6s\tremaining: 3.56s\n",
      "839:\tlearn: 50.8225743\ttotal: 18.6s\tremaining: 3.54s\n",
      "840:\tlearn: 50.8213250\ttotal: 18.6s\tremaining: 3.52s\n",
      "841:\tlearn: 50.8167700\ttotal: 18.6s\tremaining: 3.5s\n",
      "842:\tlearn: 50.8143220\ttotal: 18.7s\tremaining: 3.48s\n",
      "843:\tlearn: 50.8129225\ttotal: 18.7s\tremaining: 3.45s\n",
      "844:\tlearn: 50.8088588\ttotal: 18.7s\tremaining: 3.43s\n",
      "845:\tlearn: 50.8055509\ttotal: 18.7s\tremaining: 3.41s\n",
      "846:\tlearn: 50.7961519\ttotal: 18.8s\tremaining: 3.39s\n",
      "847:\tlearn: 50.7946046\ttotal: 18.8s\tremaining: 3.37s\n",
      "848:\tlearn: 50.7915465\ttotal: 18.8s\tremaining: 3.35s\n",
      "849:\tlearn: 50.7896789\ttotal: 18.8s\tremaining: 3.32s\n",
      "850:\tlearn: 50.7874116\ttotal: 18.9s\tremaining: 3.3s\n",
      "851:\tlearn: 50.7853145\ttotal: 18.9s\tremaining: 3.28s\n",
      "852:\tlearn: 50.7834968\ttotal: 18.9s\tremaining: 3.26s\n",
      "853:\tlearn: 50.7811735\ttotal: 18.9s\tremaining: 3.23s\n",
      "854:\tlearn: 50.7772786\ttotal: 18.9s\tremaining: 3.21s\n",
      "855:\tlearn: 50.7739462\ttotal: 19s\tremaining: 3.19s\n",
      "856:\tlearn: 50.7726571\ttotal: 19s\tremaining: 3.17s\n",
      "857:\tlearn: 50.7711260\ttotal: 19s\tremaining: 3.15s\n",
      "858:\tlearn: 50.7692517\ttotal: 19s\tremaining: 3.12s\n",
      "859:\tlearn: 50.7673407\ttotal: 19.1s\tremaining: 3.1s\n",
      "860:\tlearn: 50.7626666\ttotal: 19.1s\tremaining: 3.08s\n",
      "861:\tlearn: 50.7606389\ttotal: 19.1s\tremaining: 3.06s\n",
      "862:\tlearn: 50.7563987\ttotal: 19.1s\tremaining: 3.04s\n",
      "863:\tlearn: 50.7526051\ttotal: 19.1s\tremaining: 3.01s\n",
      "864:\tlearn: 50.7471974\ttotal: 19.2s\tremaining: 2.99s\n",
      "865:\tlearn: 50.7459966\ttotal: 19.2s\tremaining: 2.97s\n",
      "866:\tlearn: 50.7401137\ttotal: 19.2s\tremaining: 2.95s\n",
      "867:\tlearn: 50.7386257\ttotal: 19.2s\tremaining: 2.92s\n",
      "868:\tlearn: 50.7375621\ttotal: 19.3s\tremaining: 2.9s\n",
      "869:\tlearn: 50.7335024\ttotal: 19.3s\tremaining: 2.88s\n",
      "870:\tlearn: 50.7307762\ttotal: 19.3s\tremaining: 2.86s\n",
      "871:\tlearn: 50.7275606\ttotal: 19.3s\tremaining: 2.83s\n",
      "872:\tlearn: 50.7252903\ttotal: 19.3s\tremaining: 2.81s\n",
      "873:\tlearn: 50.7239651\ttotal: 19.4s\tremaining: 2.79s\n",
      "874:\tlearn: 50.7200059\ttotal: 19.4s\tremaining: 2.77s\n",
      "875:\tlearn: 50.7178636\ttotal: 19.4s\tremaining: 2.75s\n",
      "876:\tlearn: 50.7133227\ttotal: 19.4s\tremaining: 2.72s\n",
      "877:\tlearn: 50.7113233\ttotal: 19.4s\tremaining: 2.7s\n",
      "878:\tlearn: 50.7101843\ttotal: 19.5s\tremaining: 2.68s\n",
      "879:\tlearn: 50.7083546\ttotal: 19.5s\tremaining: 2.65s\n",
      "880:\tlearn: 50.7062760\ttotal: 19.5s\tremaining: 2.63s\n",
      "881:\tlearn: 50.7051962\ttotal: 19.5s\tremaining: 2.61s\n",
      "882:\tlearn: 50.7015515\ttotal: 19.5s\tremaining: 2.59s\n",
      "883:\tlearn: 50.6993931\ttotal: 19.6s\tremaining: 2.57s\n",
      "884:\tlearn: 50.6965134\ttotal: 19.6s\tremaining: 2.54s\n",
      "885:\tlearn: 50.6954891\ttotal: 19.6s\tremaining: 2.52s\n",
      "886:\tlearn: 50.6930714\ttotal: 19.6s\tremaining: 2.5s\n",
      "887:\tlearn: 50.6916914\ttotal: 19.6s\tremaining: 2.48s\n",
      "888:\tlearn: 50.6895420\ttotal: 19.6s\tremaining: 2.45s\n",
      "889:\tlearn: 50.6859636\ttotal: 19.7s\tremaining: 2.43s\n",
      "890:\tlearn: 50.6851206\ttotal: 19.7s\tremaining: 2.41s\n",
      "891:\tlearn: 50.6841135\ttotal: 19.7s\tremaining: 2.38s\n",
      "892:\tlearn: 50.6814730\ttotal: 19.7s\tremaining: 2.36s\n",
      "893:\tlearn: 50.6791720\ttotal: 19.7s\tremaining: 2.34s\n",
      "894:\tlearn: 50.6776700\ttotal: 19.8s\tremaining: 2.32s\n",
      "895:\tlearn: 50.6755749\ttotal: 19.8s\tremaining: 2.3s\n",
      "896:\tlearn: 50.6740409\ttotal: 19.8s\tremaining: 2.27s\n",
      "897:\tlearn: 50.6718676\ttotal: 19.8s\tremaining: 2.25s\n",
      "898:\tlearn: 50.6708966\ttotal: 19.8s\tremaining: 2.23s\n",
      "899:\tlearn: 50.6665653\ttotal: 19.9s\tremaining: 2.21s\n",
      "900:\tlearn: 50.6631587\ttotal: 19.9s\tremaining: 2.19s\n",
      "901:\tlearn: 50.6603662\ttotal: 19.9s\tremaining: 2.16s\n",
      "902:\tlearn: 50.6579691\ttotal: 19.9s\tremaining: 2.14s\n",
      "903:\tlearn: 50.6548551\ttotal: 20s\tremaining: 2.12s\n",
      "904:\tlearn: 50.6527865\ttotal: 20s\tremaining: 2.1s\n",
      "905:\tlearn: 50.6518309\ttotal: 20s\tremaining: 2.08s\n",
      "906:\tlearn: 50.6500254\ttotal: 20s\tremaining: 2.05s\n",
      "907:\tlearn: 50.6460031\ttotal: 20s\tremaining: 2.03s\n",
      "908:\tlearn: 50.6422081\ttotal: 20.1s\tremaining: 2.01s\n",
      "909:\tlearn: 50.6401551\ttotal: 20.1s\tremaining: 1.99s\n",
      "910:\tlearn: 50.6377107\ttotal: 20.1s\tremaining: 1.96s\n",
      "911:\tlearn: 50.6347260\ttotal: 20.1s\tremaining: 1.94s\n",
      "912:\tlearn: 50.6328680\ttotal: 20.1s\tremaining: 1.92s\n",
      "913:\tlearn: 50.6310785\ttotal: 20.2s\tremaining: 1.9s\n",
      "914:\tlearn: 50.6216559\ttotal: 20.2s\tremaining: 1.88s\n",
      "915:\tlearn: 50.6197140\ttotal: 20.2s\tremaining: 1.85s\n",
      "916:\tlearn: 50.6171058\ttotal: 20.2s\tremaining: 1.83s\n",
      "917:\tlearn: 50.6149720\ttotal: 20.3s\tremaining: 1.81s\n",
      "918:\tlearn: 50.6129334\ttotal: 20.3s\tremaining: 1.79s\n",
      "919:\tlearn: 50.6107959\ttotal: 20.3s\tremaining: 1.76s\n",
      "920:\tlearn: 50.6089584\ttotal: 20.3s\tremaining: 1.74s\n",
      "921:\tlearn: 50.6080362\ttotal: 20.3s\tremaining: 1.72s\n",
      "922:\tlearn: 50.6054883\ttotal: 20.4s\tremaining: 1.7s\n",
      "923:\tlearn: 50.6027490\ttotal: 20.4s\tremaining: 1.68s\n",
      "924:\tlearn: 50.5988184\ttotal: 20.4s\tremaining: 1.65s\n",
      "925:\tlearn: 50.5958477\ttotal: 20.4s\tremaining: 1.63s\n",
      "926:\tlearn: 50.5941132\ttotal: 20.4s\tremaining: 1.61s\n",
      "927:\tlearn: 50.5911041\ttotal: 20.5s\tremaining: 1.59s\n",
      "928:\tlearn: 50.5888925\ttotal: 20.5s\tremaining: 1.56s\n",
      "929:\tlearn: 50.5860879\ttotal: 20.5s\tremaining: 1.54s\n",
      "930:\tlearn: 50.5840892\ttotal: 20.5s\tremaining: 1.52s\n",
      "931:\tlearn: 50.5814690\ttotal: 20.5s\tremaining: 1.5s\n",
      "932:\tlearn: 50.5797887\ttotal: 20.6s\tremaining: 1.48s\n",
      "933:\tlearn: 50.5780487\ttotal: 20.6s\tremaining: 1.45s\n",
      "934:\tlearn: 50.5763576\ttotal: 20.6s\tremaining: 1.43s\n",
      "935:\tlearn: 50.5719657\ttotal: 20.6s\tremaining: 1.41s\n",
      "936:\tlearn: 50.5678040\ttotal: 20.7s\tremaining: 1.39s\n",
      "937:\tlearn: 50.5624129\ttotal: 20.7s\tremaining: 1.37s\n",
      "938:\tlearn: 50.5528874\ttotal: 20.7s\tremaining: 1.34s\n",
      "939:\tlearn: 50.5511158\ttotal: 20.7s\tremaining: 1.32s\n",
      "940:\tlearn: 50.5483010\ttotal: 20.7s\tremaining: 1.3s\n",
      "941:\tlearn: 50.5469342\ttotal: 20.8s\tremaining: 1.28s\n",
      "942:\tlearn: 50.5442522\ttotal: 20.8s\tremaining: 1.25s\n",
      "943:\tlearn: 50.5427194\ttotal: 20.8s\tremaining: 1.23s\n",
      "944:\tlearn: 50.5401667\ttotal: 20.8s\tremaining: 1.21s\n",
      "945:\tlearn: 50.5372485\ttotal: 20.8s\tremaining: 1.19s\n",
      "946:\tlearn: 50.5344938\ttotal: 20.9s\tremaining: 1.17s\n",
      "947:\tlearn: 50.5336190\ttotal: 20.9s\tremaining: 1.15s\n",
      "948:\tlearn: 50.5313668\ttotal: 20.9s\tremaining: 1.12s\n",
      "949:\tlearn: 50.5251685\ttotal: 20.9s\tremaining: 1.1s\n",
      "950:\tlearn: 50.5206309\ttotal: 20.9s\tremaining: 1.08s\n",
      "951:\tlearn: 50.5183684\ttotal: 21s\tremaining: 1.06s\n",
      "952:\tlearn: 50.5165519\ttotal: 21s\tremaining: 1.03s\n",
      "953:\tlearn: 50.5081261\ttotal: 21s\tremaining: 1.01s\n",
      "954:\tlearn: 50.5057637\ttotal: 21s\tremaining: 991ms\n",
      "955:\tlearn: 50.5040193\ttotal: 21.1s\tremaining: 969ms\n",
      "956:\tlearn: 50.5023692\ttotal: 21.1s\tremaining: 947ms\n",
      "957:\tlearn: 50.4999482\ttotal: 21.1s\tremaining: 925ms\n",
      "958:\tlearn: 50.4991182\ttotal: 21.1s\tremaining: 903ms\n",
      "959:\tlearn: 50.4906044\ttotal: 21.1s\tremaining: 881ms\n",
      "960:\tlearn: 50.4816703\ttotal: 21.2s\tremaining: 858ms\n",
      "961:\tlearn: 50.4795913\ttotal: 21.2s\tremaining: 836ms\n",
      "962:\tlearn: 50.4770680\ttotal: 21.2s\tremaining: 814ms\n",
      "963:\tlearn: 50.4726799\ttotal: 21.2s\tremaining: 792ms\n",
      "964:\tlearn: 50.4688279\ttotal: 21.2s\tremaining: 770ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965:\tlearn: 50.4651286\ttotal: 21.3s\tremaining: 748ms\n",
      "966:\tlearn: 50.4640520\ttotal: 21.3s\tremaining: 726ms\n",
      "967:\tlearn: 50.4632374\ttotal: 21.3s\tremaining: 704ms\n",
      "968:\tlearn: 50.4609094\ttotal: 21.3s\tremaining: 682ms\n",
      "969:\tlearn: 50.4569442\ttotal: 21.3s\tremaining: 660ms\n",
      "970:\tlearn: 50.4542552\ttotal: 21.4s\tremaining: 638ms\n",
      "971:\tlearn: 50.4520632\ttotal: 21.4s\tremaining: 616ms\n",
      "972:\tlearn: 50.4498980\ttotal: 21.4s\tremaining: 594ms\n",
      "973:\tlearn: 50.4452481\ttotal: 21.4s\tremaining: 572ms\n",
      "974:\tlearn: 50.4435969\ttotal: 21.4s\tremaining: 550ms\n",
      "975:\tlearn: 50.4413999\ttotal: 21.5s\tremaining: 528ms\n",
      "976:\tlearn: 50.4398348\ttotal: 21.5s\tremaining: 506ms\n",
      "977:\tlearn: 50.4375388\ttotal: 21.5s\tremaining: 484ms\n",
      "978:\tlearn: 50.4354277\ttotal: 21.5s\tremaining: 462ms\n",
      "979:\tlearn: 50.4339453\ttotal: 21.5s\tremaining: 440ms\n",
      "980:\tlearn: 50.4298602\ttotal: 21.6s\tremaining: 418ms\n",
      "981:\tlearn: 50.4285642\ttotal: 21.6s\tremaining: 396ms\n",
      "982:\tlearn: 50.4218397\ttotal: 21.6s\tremaining: 374ms\n",
      "983:\tlearn: 50.4202568\ttotal: 21.6s\tremaining: 352ms\n",
      "984:\tlearn: 50.4188712\ttotal: 21.6s\tremaining: 330ms\n",
      "985:\tlearn: 50.4163644\ttotal: 21.7s\tremaining: 308ms\n",
      "986:\tlearn: 50.4138898\ttotal: 21.7s\tremaining: 286ms\n",
      "987:\tlearn: 50.4131233\ttotal: 21.7s\tremaining: 264ms\n",
      "988:\tlearn: 50.4106976\ttotal: 21.7s\tremaining: 242ms\n",
      "989:\tlearn: 50.4095063\ttotal: 21.8s\tremaining: 220ms\n",
      "990:\tlearn: 50.4065559\ttotal: 21.8s\tremaining: 198ms\n",
      "991:\tlearn: 50.4043365\ttotal: 21.8s\tremaining: 176ms\n",
      "992:\tlearn: 50.4033586\ttotal: 21.8s\tremaining: 154ms\n",
      "993:\tlearn: 50.4024797\ttotal: 21.8s\tremaining: 132ms\n",
      "994:\tlearn: 50.4006512\ttotal: 21.9s\tremaining: 110ms\n",
      "995:\tlearn: 50.3992466\ttotal: 21.9s\tremaining: 87.9ms\n",
      "996:\tlearn: 50.3911254\ttotal: 21.9s\tremaining: 65.9ms\n",
      "997:\tlearn: 50.3904669\ttotal: 21.9s\tremaining: 43.9ms\n",
      "998:\tlearn: 50.3856079\ttotal: 21.9s\tremaining: 22ms\n",
      "999:\tlearn: 50.3839632\ttotal: 22s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Creating and fitting the CatBoostRegressor model\n",
    "catboost_model = CatBoostRegressor()\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = catboost_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adf56590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 6.146300872404079\n",
      "Mean Squared Error (MSE): 2251.584130263647\n",
      "Root Mean Squared Error (RMSE): 47.450860163580245\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.47690099712967116\n",
      "R-squared (R2 score): 0.02461173492441815\n",
      "Adjusted R-squared: 0.024549319205981357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8412\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c1bc645",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.07 TiB for an array with shape (382893, 382893) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8412\\1411125266.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Create and fit the Kernel Ridge Regression model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mkernel_ridge_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKernelRidge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mkernel_ridge_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_transformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Make predictions on the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\kernel_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\kernel_ridge.py\u001b[0m in \u001b[0;36m_get_kernel\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"gamma\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"degree\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coef0\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpairwise_kernels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_kernels\u001b[1;34m(X, Y, metric, filter_params, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   2051\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown kernel %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2053\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mlinear_kernel\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \"\"\"\n\u001b[0;32m   1072\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.07 TiB for an array with shape (382893, 382893) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "# Create a Nystroem transformer\n",
    "nystroem_transformer = Nystroem(kernel='rbf', n_components=100, random_state=42)\n",
    "X_train_transformed = nystroem_transformer.fit_transform(X_train)\n",
    "X_test_transformed = nystroem_transformer.transform(X_test)\n",
    "\n",
    "# Create and fit the Kernel Ridge Regression model\n",
    "kernel_ridge_model = KernelRidge()\n",
    "kernel_ridge_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = kernel_ridge_model.predict(X_test_transformed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b311f0a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8412\\1572706448.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Creating and fitting the LGBM Regressor model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlgbm_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlgbm_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Creating and fitting the LGBM Regressor model\n",
    "lgbm_model = LGBMRegressor()\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = lgbm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5bffbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.1.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.23.5)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04be600d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1924\n",
      "[LightGBM] [Info] Number of data points in the train set: 382893, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 16.039123\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Creating and fitting the LGBM Regressor model\n",
    "lgbm_model = LGBMRegressor()\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = lgbm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6621ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 6.303278714565177\n",
      "Mean Squared Error (MSE): 2308.9852594061144\n",
      "Root Mean Squared Error (RMSE): 48.05190172517748\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.4791012820688099\n",
      "R-squared (R2 score): -0.0002544857133579548\n",
      "Adjusted R-squared: -0.00031849263714489595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8412\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e75f9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Creating and fitting the XGBoost Regressor model\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af7a1a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 6.718885837506519\n",
      "Mean Squared Error (MSE): 2317.7610973623077\n",
      "Root Mean Squared Error (RMSE): 48.14313136224427\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5164767199880647\n",
      "R-squared (R2 score): -0.004056186588587085\n",
      "Adjusted R-squared: -0.004120436785642667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8412\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e393e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Creating and fitting the Stochastic Gradient Descent (SGD) Regression model\n",
    "sgd_model = SGDRegressor()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = sgd_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abc8f8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 44736.23910237542\n",
      "Mean Squared Error (MSE): 6040965478.817526\n",
      "Root Mean Squared Error (RMSE): 77723.64813116743\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 7.85919660930974\n",
      "R-squared (R2 score): -2616950.6646377128\n",
      "Adjusted R-squared: -2617118.1250471836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8412\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logistic_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf5f0e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial Regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Creating polynomial features\n",
    "poly_degree = 3  # Define the degree of the polynomial\n",
    "poly = PolynomialFeatures(degree=poly_degree)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Creating and fitting the Polynomial Regression model\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "y_pred = poly_model.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f263b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.624376827757013\n",
      "Mean Squared Error (MSE): 126447.5333621007\n",
      "Root Mean Squared Error (RMSE): 355.5946194223145\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5245170008011678\n",
      "R-squared (R2 score): -53.77718488569393\n",
      "Adjusted R-squared: -53.78069011276196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6128\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e946c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_model = Ridge(alpha=1.0)  # You can adjust the alpha (regularization strength) as needed\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred = ridge_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4ec8412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.306425087615338\n",
      "Mean Squared Error (MSE): 2236.9519077489817\n",
      "Root Mean Squared Error (RMSE): 47.29642595111159\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5903086989413456\n",
      "R-squared (R2 score): 0.030950426844008172\n",
      "Adjusted R-squared: 0.0308884167425183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6128\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e6811e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (10000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6128\\4119193912.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mquantile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Fit the quantile regression model with increased max_iter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mquantile_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQuantReg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Store the fitted models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\quantile_regression.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, q, vcov, kernel, bandwidth, max_iter, p_tol, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mn_iter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mbeta0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m             \u001b[0mxtx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxstar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[0mxty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxstar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpinv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the quantile levels you're interested in (e.g., 0.25, 0.5, 0.75)\n",
    "quantiles = [0.25, 0.5, 0.75]\n",
    "\n",
    "# Loop through the quantiles and fit separate quantile regression models\n",
    "quantile_models = {}\n",
    "for quantile in quantiles:\n",
    "    # Fit the quantile regression model with increased max_iter\n",
    "    quantile_model = sm.QuantReg(y_train, sm.add_constant(X_train)).fit(q=quantile, max_iter=10000)\n",
    "    \n",
    "    # Store the fitted models\n",
    "    quantile_models[quantile] = quantile_model\n",
    "\n",
    "# Predict for each quantile\n",
    "y_preds = {}\n",
    "for quantile, model in quantile_models.items():\n",
    "    y_pred = model.predict(sm.add_constant(X_test))\n",
    "    y_preds[quantile] = y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "518503aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principal Components Regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming X_train and X_test are your feature matrices, and y_train is the target variable\n",
    "\n",
    "# Step 1: Scale the data (recommended before applying PCA)\n",
    "# (You can use other scaling methods like StandardScaler or MinMaxScaler as needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 2: Perform PCA and then fit the model\n",
    "n_components = 10  # Number of components (you can change this number)\n",
    "pca = PCA(n_components=n_components)\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "# Create a pipeline to chain PCA and Linear Regression\n",
    "pipeline = make_pipeline(pca, linear_regression)\n",
    "\n",
    "# Fit the model using the pipeline\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict using the test data\n",
    "y_pred = pipeline.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81975b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 8.298275211666338\n",
      "Mean Squared Error (MSE): 2263.8724085629074\n",
      "Root Mean Squared Error (RMSE): 47.58016822755997\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.671579993407913\n",
      "R-squared (R2 score): 0.019288441741641016\n",
      "Adjusted R-squared: 0.01922568538227143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6128\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "213eb5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "# Number of components to use in PLS\n",
    "n_components = 3  # You can change this to the desired number of components\n",
    "\n",
    "pls_model = PLSRegression(n_components=n_components)\n",
    "pls_model.fit(X_train, y_train)\n",
    "y_pred = pls_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be9c1347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6128\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 357. GiB for an array with shape (218797, 218797) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6128\\4288965996.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mrmsle_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Calculate Adjusted R-squared\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6128\\4288965996.py\u001b[0m in \u001b[0;36mrmsle\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Calculate Root Mean Squared Logarithmic Error (RMSLE)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mrmsle_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmsle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2099\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2100\u001b[0m     ):\n\u001b[1;32m-> 2101\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_ufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2103\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;31m# for binary ops, use our custom dunder methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_dispatch_ufunc_to_dunder_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\ops_dispatch.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__rsub__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__mul__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5638\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign_method_SERIES\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexOpsMixin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0m_bool_arith_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_cmp\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[1;31m# error: \"None\" not callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_TEST_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\roperator.py\u001b[0m in \u001b[0;36mrsub\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrsub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mright\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 357. GiB for an array with shape (218797, 218797) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47bb5987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Alpha (regularization strength) needs to be set. This is a hyperparameter that can be tuned.\n",
    "alpha = 0.1  # You can change the value of alpha as needed\n",
    "\n",
    "lasso_model = Lasso(alpha=alpha)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_pred = lasso_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1740e5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.294012272274062\n",
      "Mean Squared Error (MSE): 2236.068592403954\n",
      "Root Mean Squared Error (RMSE): 47.287086951978274\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5889797088208266\n",
      "R-squared (R2 score): 0.031333079843876455\n",
      "Adjusted R-squared: 0.03127109422859653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7b5c697",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mord'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6128\\4279984689.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmord\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Assuming X_train and y_train are your training features and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Assuming X_test is your test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mordinal_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticIT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mord'"
     ]
    }
   ],
   "source": [
    "#Ordinal Regression\n",
    "from mord import LogisticIT\n",
    "# Assuming X_train and y_train are your training features and labels\n",
    "# Assuming X_test is your test set\n",
    "\n",
    "ordinal_model = LogisticIT()\n",
    "ordinal_model.fit(X_train, y_train)\n",
    "y_pred = ordinal_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b75a2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mord\n",
      "  Downloading mord-0.7.tar.gz (8.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: mord\n",
      "  Building wheel for mord (setup.py): started\n",
      "  Building wheel for mord (setup.py): finished with status 'done'\n",
      "  Created wheel for mord: filename=mord-0.7-py3-none-any.whl size=9885 sha256=5079e33b73043436f8ce0d3f22fcf6c3b1d98c1bd74b5cd9f643bd9413574e2c\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\bb\\62\\6d\\f94a319e6f1bd5a8c0dd093afdd390b0e361710ed06ba7f3e3\n",
      "Successfully built mord\n",
      "Installing collected packages: mord\n",
      "Successfully installed mord-0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install mord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2c1a9d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Values in y must be [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273], instead got [    0     1     2     3     4     5     6     7     8     9    10    11\n    12    13    14    15    16    17    18    19    20    21    22    23\n    24    25    26    27    28    29    30    31    32    33    34    35\n    36    37    38    39    40    41    42    43    44    45    46    47\n    48    49    50    51    52    53    54    55    56    57    58    59\n    60    61    62    63    64    65    66    67    68    69    70    71\n    72    73    74    75    76    77    78    79    80    81    82    83\n    84    85    86    87    88    89    90    91    92    93    94    95\n    96    97    98    99   100   101   102   103   104   105   106   107\n   108   109   110   111   112   113   114   115   116   117   118   121\n   122   123   124   127   128   129   130   131   132   133   134   135\n   136   137   138   141   145   148   150   151   153   154   155   158\n   162   165   173   174   181   197   201   205   289   307   339   347\n   391   403   406   433   437   443   451   472   476   482   484   500\n   529   532   616   622   624   655   658   689   720   721   758   769\n   931   966   980   996  1017  1019  1041  1046  1112  1124  1138  1212\n  1250  1255  1282  1289  1305  1307  1323  1324  1330  1332  1335  1342\n  1347  1348  1351  1353  1357  1358  1362  1364  1373  1376  1377  1380\n  1382  1383  1384  1385  1387  1388  1389  1390  1391  1392  1393  1394\n  1395  1397  1398  1399  1400  1401  1402  1403  1404  1405  1406  1407\n  1408  1409  1410  1411  1412  1413  1414  1415  1416  1417  1418  1419\n  1420  1421  1422  1423  1424  1425  1426  1427  1428  1429  1430  1431\n  1432  1433  1434  1435  1436  1437  1438  1439  1440 32329]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6128\\4279984689.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mordinal_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticIT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mordinal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mordinal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mord\\threshold_based.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_class_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0my_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# we need classes that start at zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         self.coef_, self.theta_ = threshold_fit(\n\u001b[0m\u001b[0;32m    252\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_class_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0-1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mord\\threshold_based.py\u001b[0m in \u001b[0;36mthreshold_fit\u001b[1;34m(X, y, alpha, n_class, mode, max_iter, verbose, tol, sample_weight)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0munique_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_y\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     99\u001b[0m             \u001b[1;34m'Values in y must be %s, instead got %s'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             % (np.arange(unique_y.size), unique_y))\n",
      "\u001b[1;31mValueError\u001b[0m: Values in y must be [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n 270 271 272 273], instead got [    0     1     2     3     4     5     6     7     8     9    10    11\n    12    13    14    15    16    17    18    19    20    21    22    23\n    24    25    26    27    28    29    30    31    32    33    34    35\n    36    37    38    39    40    41    42    43    44    45    46    47\n    48    49    50    51    52    53    54    55    56    57    58    59\n    60    61    62    63    64    65    66    67    68    69    70    71\n    72    73    74    75    76    77    78    79    80    81    82    83\n    84    85    86    87    88    89    90    91    92    93    94    95\n    96    97    98    99   100   101   102   103   104   105   106   107\n   108   109   110   111   112   113   114   115   116   117   118   121\n   122   123   124   127   128   129   130   131   132   133   134   135\n   136   137   138   141   145   148   150   151   153   154   155   158\n   162   165   173   174   181   197   201   205   289   307   339   347\n   391   403   406   433   437   443   451   472   476   482   484   500\n   529   532   616   622   624   655   658   689   720   721   758   769\n   931   966   980   996  1017  1019  1041  1046  1112  1124  1138  1212\n  1250  1255  1282  1289  1305  1307  1323  1324  1330  1332  1335  1342\n  1347  1348  1351  1353  1357  1358  1362  1364  1373  1376  1377  1380\n  1382  1383  1384  1385  1387  1388  1389  1390  1391  1392  1393  1394\n  1395  1397  1398  1399  1400  1401  1402  1403  1404  1405  1406  1407\n  1408  1409  1410  1411  1412  1413  1414  1415  1416  1417  1418  1419\n  1420  1421  1422  1423  1424  1425  1426  1427  1428  1429  1430  1431\n  1432  1433  1434  1435  1436  1437  1438  1439  1440 32329]"
     ]
    }
   ],
   "source": [
    "#Ordinal Regression\n",
    "from mord import LogisticIT\n",
    "# Assuming X_train and y_train are your training features and labels\n",
    "# Assuming X_test is your test set\n",
    "\n",
    "ordinal_model = LogisticIT()\n",
    "ordinal_model.fit(X_train, y_train)\n",
    "y_pred = ordinal_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4005e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordinal Regression\n",
    "from mord import LogisticIT\n",
    "\n",
    "ordinal_model = LogisticIT()\n",
    "ordinal_model.fit(X_train, y_train_ordinal)\n",
    "y_pred = ordinal_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad20b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_train contains continuous values, transform it into ordinal classes\n",
    "# You can use a method like binning or discretization to create ordinal classes\n",
    "# For instance, using pandas.qcut to discretize into 10 ordinal classes\n",
    "import pandas as pd\n",
    "\n",
    "num_classes = 10  # You can change this based on your data or required number of classes\n",
    "y_train_ordinal = pd.qcut(y_train, q=num_classes, labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "797c0585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 11.796752240661435\n",
      "Mean Squared Error (MSE): 2409.251388273148\n",
      "Root Mean Squared Error (RMSE): 49.084125624005445\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 1.3567407802242466\n",
      "R-squared (R2 score): -0.043689862685040826\n",
      "Adjusted R-squared: -0.04375664906635901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ed7a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poisson Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming X_train and y_train are your training data\n",
    "poisson_model = sm.GLM(y_train, X_train, family=sm.families.Poisson())\n",
    "poisson_results = poisson_model.fit()\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = poisson_results.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da40af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 9.126143271338067\n",
      "Mean Squared Error (MSE): 2818.848436219818\n",
      "Root Mean Squared Error (RMSE): 53.092828482007036\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.7200430529426324\n",
      "R-squared (R2 score): -0.22112767129581723\n",
      "Adjusted R-squared: -0.22120581203590617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdb50fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative Binomial Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming X_train and y_train are your training features and target respectively\n",
    "\n",
    "# Fit the Negative Binomial Regression model\n",
    "nb_model = sm.GLM(y_train, X_train, family=sm.families.NegativeBinomial())\n",
    "nb_result = nb_model.fit()\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred = nb_result.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0382bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1837452.5591686254\n",
      "Mean Squared Error (MSE): 7.387007368778068e+17\n",
      "Root Mean Squared Error (RMSE): 859477013.583148\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5997601273658384\n",
      "R-squared (R2 score): -320005821887244.8\n",
      "Adjusted R-squared: -320026299264297.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b609e078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6128\\1257050187.py:14: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  trip_distance                  with p-value 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6128\\1257050187.py:14: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  passenger_count                with p-value 5.10499e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6128\\1257050187.py:14: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  dropoff_longitude              with p-value 3.88163e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6128\\1257050187.py:14: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  dropoff_latitude               with p-value 8.59054e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6128\\1257050187.py:14: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  pickup_month                   with p-value 8.61656e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6128\\1257050187.py:14: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    }
   ],
   "source": [
    "#Stepwise regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "# Assuming X_train and y_train are your training data\n",
    "selected_features = stepwise_selection(X_train, y_train)\n",
    "\n",
    "# After obtaining selected features, fit the model using sklearn LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train[selected_features], y_train)\n",
    "y_pred = lr_model.predict(X_test[selected_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69e4d37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.314274953808492\n",
      "Mean Squared Error (MSE): 2237.090802872275\n",
      "Root Mean Squared Error (RMSE): 47.29789427524523\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.590098337754407\n",
      "R-squared (R2 score): 0.030890257351997685\n",
      "Adjusted R-squared: 0.0308282434002235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6128\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88a5ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regression \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create a DecisionTreeRegressor model\n",
    "dt_model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the model with training data\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred = dt_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fa36dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 8.870921447734657\n",
      "Mean Squared Error (MSE): 6012.532269638066\n",
      "Root Mean Squared Error (RMSE): 77.54052017905262\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5214375493255099\n",
      "R-squared (R2 score): -1.6046343729143802\n",
      "Adjusted R-squared: -1.604801045132482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acaf4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7173538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.018680832004094\n",
      "Mean Squared Error (MSE): 2369.1474376581946\n",
      "Root Mean Squared Error (RMSE): 48.67388866382256\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5204694951744038\n",
      "R-squared (R2 score): -0.026316795302292917\n",
      "Adjusted R-squared: -0.026382469969926436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56940318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Nearest Neighbors Regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Create a K-Nearest Neighbors Regression model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)  # You can set the number of neighbors (K) as needed\n",
    "\n",
    "# Fit the KNN model with the training data\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the KNN model\n",
    "y_pred = knn_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a657d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 8.15548110805907\n",
      "Mean Squared Error (MSE): 3141.66086920753\n",
      "Root Mean Squared Error (RMSE): 56.0505206863195\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.556349497078561\n",
      "R-squared (R2 score): -0.360970306853851\n",
      "Adjusted R-squared: -0.36105739621356037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ab7c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Robust Regression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a RANSACRegressor model\n",
    "ransac_model = RANSACRegressor(base_estimator=LinearRegression(), random_state=0)\n",
    "\n",
    "# Fit the RANSAC model to the training data\n",
    "ransac_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = ransac_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc96843c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.686679573077273\n",
      "Mean Squared Error (MSE): 9669.243202706744\n",
      "Root Mean Squared Error (RMSE): 98.33231006493615\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.4979987453881462\n",
      "R-squared (R2 score): 0.004111477248444406\n",
      "Adjusted R-squared: 0.0040158828753315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6128\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b455b8c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.48 TiB for an array with shape (583457, 583457) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6128\\2076487482.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mRBF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Radial Basis Function (RBF) kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgp_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianProcessRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    270\u001b[0m             optima = [\n\u001b[0;32m    271\u001b[0m                 (\n\u001b[1;32m--> 272\u001b[1;33m                     self._constrained_optimization(\n\u001b[0m\u001b[0;32m    273\u001b[0m                         \u001b[0mobj_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m                     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\u001b[0m in \u001b[0;36m_constrained_optimization\u001b[1;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_constrained_optimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fmin_l_bfgs_b\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m             opt_res = scipy.optimize.minimize(\n\u001b[0m\u001b[0;32m    604\u001b[0m                 \u001b[0mobj_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m                 \u001b[0minitial_theta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    697\u001b[0m                                  **options)\n\u001b[0;32m    698\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    700\u001b[0m                                callback=callback, **options)\n\u001b[0;32m    701\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0miprint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[0m\u001b[0;32m    309\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[0;32m    264\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;31m# Gradient evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m             \u001b[1;31m# Make sure the function returns a true scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\u001b[0m in \u001b[0;36mobj_func\u001b[1;34m(theta, eval_gradient)\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m                     lml, grad = self.log_marginal_likelihood(\n\u001b[0m\u001b[0;32m    263\u001b[0m                         \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclone_kernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m                     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[1;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m             \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m    938\u001b[0m         \"\"\"\n\u001b[0;32m    939\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m             \u001b[0mK1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK1_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m             \u001b[0mK2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK2_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m             return K1 * K2, np.dstack(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Gradient can only be evaluated when Y is None.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m         K = np.full(\n\u001b[0m\u001b[0;32m   1254\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unsafe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.48 TiB for an array with shape (583457, 583457) and data type float64"
     ]
    }
   ],
   "source": [
    "#Gaussian Process Regression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "kernel = 1.0 * RBF(length_scale=1.0)  # Radial Basis Function (RBF) kernel\n",
    "gp_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "gp_model.fit(X_train, y_train)\n",
    "y_pred, sigma = gp_model.predict(X_test, return_std=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6c7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
