{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a98e6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id1080784</td>\n",
       "      <td>2</td>\n",
       "      <td>29-02-2016 16:40</td>\n",
       "      <td>29-02-2016 16:47</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.953918</td>\n",
       "      <td>40.778873</td>\n",
       "      <td>-73.963875</td>\n",
       "      <td>40.771164</td>\n",
       "      <td>N</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>id0889885</td>\n",
       "      <td>1</td>\n",
       "      <td>11-03-2016 23:35</td>\n",
       "      <td>11-03-2016 23:53</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.988312</td>\n",
       "      <td>40.731743</td>\n",
       "      <td>-73.994751</td>\n",
       "      <td>40.694931</td>\n",
       "      <td>N</td>\n",
       "      <td>1100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>id0857912</td>\n",
       "      <td>2</td>\n",
       "      <td>21-02-2016 17:59</td>\n",
       "      <td>21-02-2016 18:26</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.997314</td>\n",
       "      <td>40.721458</td>\n",
       "      <td>-73.948029</td>\n",
       "      <td>40.774918</td>\n",
       "      <td>N</td>\n",
       "      <td>1635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>id3744273</td>\n",
       "      <td>2</td>\n",
       "      <td>05-01-2016 9:44</td>\n",
       "      <td>05-01-2016 10:03</td>\n",
       "      <td>6</td>\n",
       "      <td>-73.961670</td>\n",
       "      <td>40.759720</td>\n",
       "      <td>-73.956779</td>\n",
       "      <td>40.780628</td>\n",
       "      <td>N</td>\n",
       "      <td>1141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>id0232939</td>\n",
       "      <td>1</td>\n",
       "      <td>17-02-2016 6:42</td>\n",
       "      <td>17-02-2016 6:56</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.017120</td>\n",
       "      <td>40.708469</td>\n",
       "      <td>-73.988182</td>\n",
       "      <td>40.740631</td>\n",
       "      <td>N</td>\n",
       "      <td>848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>399995</td>\n",
       "      <td>id0338454</td>\n",
       "      <td>1</td>\n",
       "      <td>23-05-2016 19:53</td>\n",
       "      <td>23-05-2016 19:53</td>\n",
       "      <td>3</td>\n",
       "      <td>-73.997131</td>\n",
       "      <td>40.731449</td>\n",
       "      <td>-73.997131</td>\n",
       "      <td>40.731449</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>399996</td>\n",
       "      <td>id2817401</td>\n",
       "      <td>2</td>\n",
       "      <td>09-06-2016 7:37</td>\n",
       "      <td>09-06-2016 7:51</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.978630</td>\n",
       "      <td>40.783371</td>\n",
       "      <td>-73.973839</td>\n",
       "      <td>40.754471</td>\n",
       "      <td>N</td>\n",
       "      <td>835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>399997</td>\n",
       "      <td>id3780539</td>\n",
       "      <td>1</td>\n",
       "      <td>15-02-2016 10:21</td>\n",
       "      <td>15-02-2016 10:33</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.971268</td>\n",
       "      <td>40.795601</td>\n",
       "      <td>-73.974106</td>\n",
       "      <td>40.762692</td>\n",
       "      <td>N</td>\n",
       "      <td>731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>399998</td>\n",
       "      <td>id3446645</td>\n",
       "      <td>1</td>\n",
       "      <td>28-03-2016 17:38</td>\n",
       "      <td>28-03-2016 17:48</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.971672</td>\n",
       "      <td>40.763691</td>\n",
       "      <td>-73.979935</td>\n",
       "      <td>40.748798</td>\n",
       "      <td>N</td>\n",
       "      <td>642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>399999</td>\n",
       "      <td>id0234021</td>\n",
       "      <td>1</td>\n",
       "      <td>11-01-2016 9:59</td>\n",
       "      <td>11-01-2016 10:10</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.966103</td>\n",
       "      <td>40.765060</td>\n",
       "      <td>-73.979187</td>\n",
       "      <td>40.752769</td>\n",
       "      <td>N</td>\n",
       "      <td>669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         id  vendor_id   pickup_datetime  dropoff_datetime  \\\n",
       "0                0  id1080784          2  29-02-2016 16:40  29-02-2016 16:47   \n",
       "1                1  id0889885          1  11-03-2016 23:35  11-03-2016 23:53   \n",
       "2                2  id0857912          2  21-02-2016 17:59  21-02-2016 18:26   \n",
       "3                3  id3744273          2   05-01-2016 9:44  05-01-2016 10:03   \n",
       "4                4  id0232939          1   17-02-2016 6:42   17-02-2016 6:56   \n",
       "...            ...        ...        ...               ...               ...   \n",
       "399995      399995  id0338454          1  23-05-2016 19:53  23-05-2016 19:53   \n",
       "399996      399996  id2817401          2   09-06-2016 7:37   09-06-2016 7:51   \n",
       "399997      399997  id3780539          1  15-02-2016 10:21  15-02-2016 10:33   \n",
       "399998      399998  id3446645          1  28-03-2016 17:38  28-03-2016 17:48   \n",
       "399999      399999  id0234021          1   11-01-2016 9:59  11-01-2016 10:10   \n",
       "\n",
       "        passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                     1        -73.953918        40.778873         -73.963875   \n",
       "1                     2        -73.988312        40.731743         -73.994751   \n",
       "2                     2        -73.997314        40.721458         -73.948029   \n",
       "3                     6        -73.961670        40.759720         -73.956779   \n",
       "4                     1        -74.017120        40.708469         -73.988182   \n",
       "...                 ...               ...              ...                ...   \n",
       "399995                3        -73.997131        40.731449         -73.997131   \n",
       "399996                1        -73.978630        40.783371         -73.973839   \n",
       "399997                1        -73.971268        40.795601         -73.974106   \n",
       "399998                1        -73.971672        40.763691         -73.979935   \n",
       "399999                1        -73.966103        40.765060         -73.979187   \n",
       "\n",
       "        dropoff_latitude store_and_fwd_flag  trip_duration  Unnamed: 11  \\\n",
       "0              40.771164                  N            400          NaN   \n",
       "1              40.694931                  N           1100          NaN   \n",
       "2              40.774918                  N           1635          NaN   \n",
       "3              40.780628                  N           1141          NaN   \n",
       "4              40.740631                  N            848          NaN   \n",
       "...                  ...                ...            ...          ...   \n",
       "399995         40.731449                  N              3          NaN   \n",
       "399996         40.754471                  N            835          NaN   \n",
       "399997         40.762692                  N            731          NaN   \n",
       "399998         40.748798                  N            642          NaN   \n",
       "399999         40.752769                  N            669          NaN   \n",
       "\n",
       "        Unnamed: 12  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "...             ...  \n",
       "399995          NaN  \n",
       "399996          NaN  \n",
       "399997          NaN  \n",
       "399998          NaN  \n",
       "399999          NaN  \n",
       "\n",
       "[400000 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "url = 'dataset1.csv'\n",
    "sample_df = pd.read_csv(url)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6a7c6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>pickup_month</th>\n",
       "      <th>pickup_day</th>\n",
       "      <th>pickup_weekday</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>latitude_difference</th>\n",
       "      <th>longitude_difference</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id1080784</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-29 16:40:00</td>\n",
       "      <td>2016-02-29 16:47:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.953918</td>\n",
       "      <td>40.778873</td>\n",
       "      <td>-73.963875</td>\n",
       "      <td>40.771164</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.007709</td>\n",
       "      <td>-0.009956</td>\n",
       "      <td>1.220593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>id0889885</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-11 23:35:00</td>\n",
       "      <td>2016-03-11 23:53:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.988312</td>\n",
       "      <td>40.731743</td>\n",
       "      <td>-73.994751</td>\n",
       "      <td>40.694931</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.036812</td>\n",
       "      <td>-0.006439</td>\n",
       "      <td>2.988357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>id0857912</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-21 17:59:00</td>\n",
       "      <td>2016-02-21 18:26:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.997314</td>\n",
       "      <td>40.721458</td>\n",
       "      <td>-73.948029</td>\n",
       "      <td>40.774918</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>0.049286</td>\n",
       "      <td>7.098995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>id3744273</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-05 09:44:00</td>\n",
       "      <td>2016-01-05 10:03:00</td>\n",
       "      <td>6</td>\n",
       "      <td>-73.961670</td>\n",
       "      <td>40.759720</td>\n",
       "      <td>-73.956779</td>\n",
       "      <td>40.780628</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>0.020908</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>1.782524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>id0232939</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-17 06:42:00</td>\n",
       "      <td>2016-02-17 06:56:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.017120</td>\n",
       "      <td>40.708469</td>\n",
       "      <td>-73.988182</td>\n",
       "      <td>40.740631</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.028938</td>\n",
       "      <td>4.221601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>id1918069</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-14 18:31:00</td>\n",
       "      <td>2016-02-14 18:55:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.993614</td>\n",
       "      <td>40.751884</td>\n",
       "      <td>-73.995422</td>\n",
       "      <td>40.723862</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.028023</td>\n",
       "      <td>-0.001808</td>\n",
       "      <td>2.061117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>id2429028</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-20 20:30:00</td>\n",
       "      <td>2016-04-20 20:36:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.965080</td>\n",
       "      <td>40.758915</td>\n",
       "      <td>-73.976807</td>\n",
       "      <td>40.764107</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>-0.011726</td>\n",
       "      <td>1.168933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>id1663798</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-19 16:48:00</td>\n",
       "      <td>2016-06-19 17:06:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.963890</td>\n",
       "      <td>40.765434</td>\n",
       "      <td>-73.872429</td>\n",
       "      <td>40.774200</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>0.008766</td>\n",
       "      <td>0.091461</td>\n",
       "      <td>6.925039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>id2436943</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-28 19:17:00</td>\n",
       "      <td>2016-03-28 19:48:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.872887</td>\n",
       "      <td>40.774281</td>\n",
       "      <td>-73.979019</td>\n",
       "      <td>40.761879</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.012402</td>\n",
       "      <td>-0.106133</td>\n",
       "      <td>8.189912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>id2933909</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-10 22:01:00</td>\n",
       "      <td>2016-04-10 22:25:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.987823</td>\n",
       "      <td>40.740982</td>\n",
       "      <td>-73.999153</td>\n",
       "      <td>40.686451</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054531</td>\n",
       "      <td>-0.011330</td>\n",
       "      <td>4.550537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id  vendor_id     pickup_datetime    dropoff_datetime  \\\n",
       "0           0  id1080784          2 2016-02-29 16:40:00 2016-02-29 16:47:00   \n",
       "1           1  id0889885          1 2016-03-11 23:35:00 2016-03-11 23:53:00   \n",
       "2           2  id0857912          2 2016-02-21 17:59:00 2016-02-21 18:26:00   \n",
       "3           3  id3744273          2 2016-01-05 09:44:00 2016-01-05 10:03:00   \n",
       "4           4  id0232939          1 2016-02-17 06:42:00 2016-02-17 06:56:00   \n",
       "5           5  id1918069          2 2016-02-14 18:31:00 2016-02-14 18:55:00   \n",
       "6           6  id2429028          1 2016-04-20 20:30:00 2016-04-20 20:36:00   \n",
       "7           7  id1663798          2 2016-06-19 16:48:00 2016-06-19 17:06:00   \n",
       "8           8  id2436943          2 2016-03-28 19:17:00 2016-03-28 19:48:00   \n",
       "9           9  id2933909          1 2016-04-10 22:01:00 2016-04-10 22:25:00   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.953918        40.778873         -73.963875   \n",
       "1                2        -73.988312        40.731743         -73.994751   \n",
       "2                2        -73.997314        40.721458         -73.948029   \n",
       "3                6        -73.961670        40.759720         -73.956779   \n",
       "4                1        -74.017120        40.708469         -73.988182   \n",
       "5                2        -73.993614        40.751884         -73.995422   \n",
       "6                1        -73.965080        40.758915         -73.976807   \n",
       "7                1        -73.963890        40.765434         -73.872429   \n",
       "8                2        -73.872887        40.774281         -73.979019   \n",
       "9                1        -73.987823        40.740982         -73.999153   \n",
       "\n",
       "   dropoff_latitude  ...  Unnamed: 11  Unnamed: 12  pickup_month  pickup_day  \\\n",
       "0         40.771164  ...          NaN          NaN             2          29   \n",
       "1         40.694931  ...          NaN          NaN             3          11   \n",
       "2         40.774918  ...          NaN          NaN             2          21   \n",
       "3         40.780628  ...          NaN          NaN             1           5   \n",
       "4         40.740631  ...          NaN          NaN             2          17   \n",
       "5         40.723862  ...          NaN          NaN             2          14   \n",
       "6         40.764107  ...          NaN          NaN             4          20   \n",
       "7         40.774200  ...          NaN          NaN             6          19   \n",
       "8         40.761879  ...          NaN          NaN             3          28   \n",
       "9         40.686451  ...          NaN          NaN             4          10   \n",
       "\n",
       "   pickup_weekday  pickup_hour  pickup_minute  latitude_difference  \\\n",
       "0               0           16             40            -0.007709   \n",
       "1               4           23             35            -0.036812   \n",
       "2               6           17             59             0.053459   \n",
       "3               1            9             44             0.020908   \n",
       "4               2            6             42             0.032162   \n",
       "5               6           18             31            -0.028023   \n",
       "6               2           20             30             0.005192   \n",
       "7               6           16             48             0.008766   \n",
       "8               0           19             17            -0.012402   \n",
       "9               6           22              1            -0.054531   \n",
       "\n",
       "   longitude_difference  trip_distance  \n",
       "0             -0.009956       1.220593  \n",
       "1             -0.006439       2.988357  \n",
       "2              0.049286       7.098995  \n",
       "3              0.004890       1.782524  \n",
       "4              0.028938       4.221601  \n",
       "5             -0.001808       2.061117  \n",
       "6             -0.011726       1.168933  \n",
       "7              0.091461       6.925039  \n",
       "8             -0.106133       8.189912  \n",
       "9             -0.011330       4.550537  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre-processing\n",
    "\n",
    "sample_df[\"store_and_fwd_flag\"].value_counts()\n",
    "#Convert character variables to numeric\n",
    "f = lambda x: 0 if x == 'N' else 1\n",
    "\n",
    "sample_df[\"store_and_fwd_flag\"] = sample_df[\"store_and_fwd_flag\"].apply(lambda x: f(x))\n",
    "#Check result\n",
    "sample_df[\"store_and_fwd_flag\"].value_counts()\n",
    "\n",
    "\n",
    "#First, convert datetime strings into datetime\n",
    "sample_df[\"dropoff_datetime\"] = pd.to_datetime(sample_df[\"dropoff_datetime\"], format='%d-%m-%Y %H:%M')\n",
    "sample_df[\"pickup_datetime\"] = pd.to_datetime(sample_df[\"pickup_datetime\"], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "#Now construct other variables, like month, date, etc.\n",
    "sample_df[\"pickup_month\"] = sample_df[\"pickup_datetime\"].dt.month\n",
    "sample_df[\"pickup_day\"] = sample_df[\"pickup_datetime\"].dt.day\n",
    "sample_df[\"pickup_weekday\"] = sample_df[\"pickup_datetime\"].dt.weekday #sample_df[\"pickup_weekday\"] = sample_df[\"pickup_datetime\"].dt.weekday_name\n",
    "sample_df[\"pickup_hour\"] = sample_df[\"pickup_datetime\"].dt.hour\n",
    "sample_df[\"pickup_minute\"] = sample_df[\"pickup_datetime\"].dt.minute\n",
    "\n",
    "#Get latitude and longitude differences\n",
    "sample_df[\"latitude_difference\"] = sample_df[\"dropoff_latitude\"] - sample_df[\"pickup_latitude\"]\n",
    "sample_df[\"longitude_difference\"] = sample_df[\"dropoff_longitude\"] - sample_df[\"pickup_longitude\"]\n",
    "\n",
    "#Convert duration to minutes for easier interpretation\n",
    "sample_df[\"trip_duration\"] = sample_df[\"trip_duration\"].apply(lambda x: round(x/60))\n",
    "\n",
    "#Convert trip distance from longitude and latitude differences to Manhattan distance.\n",
    "sample_df[\"trip_distance\"] = 0.621371 * 6371 * (abs(2 * np.arctan2(np.sqrt(np.square(np.sin((abs(sample_df[\"latitude_difference\"]) * np.pi / 180) / 2))),\n",
    "                                  np.sqrt(1-(np.square(np.sin((abs(sample_df[\"latitude_difference\"]) * np.pi / 180) / 2)))))) + \\\n",
    "                                     abs(2 * np.arctan2(np.sqrt(np.square(np.sin((abs(sample_df[\"longitude_difference\"]) * np.pi / 180) / 2))),\n",
    "                                  np.sqrt(1-(np.square(np.sin((abs(sample_df[\"longitude_difference\"]) * np.pi / 180) / 2)))))))\n",
    "\n",
    "sample_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79004a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = sample_df.drop([\"trip_duration\", \"id\", \"vendor_id\", \"pickup_datetime\", \"dropoff_datetime\", \"Unnamed: 11\",\"Unnamed: 12\"], axis=1)\n",
    "y = sample_df[\"trip_duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "527b125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2018)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a2bb7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78eacdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.385460864711088\n",
      "Mean Squared Error (MSE): 2713.8248792715635\n",
      "Root Mean Squared Error (RMSE): 52.09438433527709\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5551895579705758\n",
      "R-squared (R2 score): 0.013824453390151481\n",
      "Adjusted R-squared: 0.013701165008374483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26696\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cbddec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elastic Net Regression \n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Creating and fitting the Elastic Net Regression model\n",
    "elastic_net_model = ElasticNet()\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = elastic_net_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d8a7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.426174955577725\n",
      "Mean Squared Error (MSE): 2714.958701649071\n",
      "Root Mean Squared Error (RMSE): 52.10526558467072\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5641186930819356\n",
      "R-squared (R2 score): 0.013412434209607693\n",
      "Adjusted R-squared: 0.013289094318565176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00cb15ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Creating and fitting the Gradient Boosting Regression model\n",
    "gb_model = GradientBoostingRegressor()\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = gb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82904382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 6.86134679560485\n",
      "Mean Squared Error (MSE): 3346.9842704911775\n",
      "Root Mean Squared Error (RMSE): 57.85312671317928\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.4905793837325415\n",
      "R-squared (R2 score): -0.21625904002036034\n",
      "Adjusted R-squared: -0.2164110926740499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26696\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c151da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Creating and fitting the Stochastic Gradient Descent Regression model\n",
    "sgd_model = SGDRegressor()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = sgd_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "498d993d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 3.999977711762561e+18\n",
      "Mean Squared Error (MSE): 2.1348136546582396e+37\n",
      "Root Mean Squared Error (RMSE): 4.620404370461788e+18\n",
      "Root Mean Squared Logarithmic Error (RMSLE): nan\n",
      "R-squared (R2 score): -7.757689299973756e+33\n",
      "Adjusted R-squared: -7.758659140448315e+33\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    mask = (y_true > 0) & (y_pred > 0)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0:  # If all values are non-positive, handle this case\n",
    "        return 0  # Return a default value or handle it as needed\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "768aaafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Creating and fitting the Bayesian Ridge Regression model\n",
    "bayesian_model = BayesianRidge()\n",
    "bayesian_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = bayesian_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8284009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.39888827209841\n",
      "Mean Squared Error (MSE): 2718.3437967723025\n",
      "Root Mean Squared Error (RMSE): 52.13773870021889\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5567364084905849\n",
      "R-squared (R2 score): 0.012182326084732797\n",
      "Adjusted R-squared: 0.012058832409670095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b78b6273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.095299\n",
      "0:\tlearn: 85.2597864\ttotal: 158ms\tremaining: 2m 37s\n",
      "1:\tlearn: 83.8828356\ttotal: 175ms\tremaining: 1m 27s\n",
      "2:\tlearn: 82.5537762\ttotal: 194ms\tremaining: 1m 4s\n",
      "3:\tlearn: 81.5271153\ttotal: 212ms\tremaining: 52.7s\n",
      "4:\tlearn: 80.2934610\ttotal: 226ms\tremaining: 45s\n",
      "5:\tlearn: 79.0981410\ttotal: 241ms\tremaining: 39.9s\n",
      "6:\tlearn: 78.8430337\ttotal: 258ms\tremaining: 36.6s\n",
      "7:\tlearn: 77.6939330\ttotal: 274ms\tremaining: 34s\n",
      "8:\tlearn: 76.8131247\ttotal: 289ms\tremaining: 31.8s\n",
      "9:\tlearn: 75.7445403\ttotal: 299ms\tremaining: 29.6s\n",
      "10:\tlearn: 75.2849020\ttotal: 312ms\tremaining: 28s\n",
      "11:\tlearn: 74.2649829\ttotal: 324ms\tremaining: 26.7s\n",
      "12:\tlearn: 73.2897077\ttotal: 334ms\tremaining: 25.4s\n",
      "13:\tlearn: 72.5319235\ttotal: 348ms\tremaining: 24.5s\n",
      "14:\tlearn: 71.6183714\ttotal: 360ms\tremaining: 23.6s\n",
      "15:\tlearn: 70.7302207\ttotal: 373ms\tremaining: 23s\n",
      "16:\tlearn: 69.8730984\ttotal: 386ms\tremaining: 22.3s\n",
      "17:\tlearn: 69.0556959\ttotal: 398ms\tremaining: 21.7s\n",
      "18:\tlearn: 68.2599395\ttotal: 411ms\tremaining: 21.2s\n",
      "19:\tlearn: 67.4919376\ttotal: 424ms\tremaining: 20.8s\n",
      "20:\tlearn: 66.7525134\ttotal: 436ms\tremaining: 20.3s\n",
      "21:\tlearn: 66.0423212\ttotal: 449ms\tremaining: 20s\n",
      "22:\tlearn: 65.3608524\ttotal: 460ms\tremaining: 19.5s\n",
      "23:\tlearn: 64.7033611\ttotal: 472ms\tremaining: 19.2s\n",
      "24:\tlearn: 64.0706069\ttotal: 484ms\tremaining: 18.9s\n",
      "25:\tlearn: 63.4614022\ttotal: 495ms\tremaining: 18.6s\n",
      "26:\tlearn: 62.8765996\ttotal: 507ms\tremaining: 18.3s\n",
      "27:\tlearn: 62.3155459\ttotal: 518ms\tremaining: 18s\n",
      "28:\tlearn: 61.7742495\ttotal: 529ms\tremaining: 17.7s\n",
      "29:\tlearn: 61.2552872\ttotal: 540ms\tremaining: 17.5s\n",
      "30:\tlearn: 60.7572910\ttotal: 552ms\tremaining: 17.2s\n",
      "31:\tlearn: 60.2796748\ttotal: 564ms\tremaining: 17s\n",
      "32:\tlearn: 59.8206750\ttotal: 575ms\tremaining: 16.9s\n",
      "33:\tlearn: 59.3779794\ttotal: 588ms\tremaining: 16.7s\n",
      "34:\tlearn: 58.9546222\ttotal: 601ms\tremaining: 16.6s\n",
      "35:\tlearn: 58.5487724\ttotal: 614ms\tremaining: 16.4s\n",
      "36:\tlearn: 58.1596510\ttotal: 626ms\tremaining: 16.3s\n",
      "37:\tlearn: 58.1258780\ttotal: 638ms\tremaining: 16.1s\n",
      "38:\tlearn: 57.8417152\ttotal: 650ms\tremaining: 16s\n",
      "39:\tlearn: 57.4771439\ttotal: 661ms\tremaining: 15.9s\n",
      "40:\tlearn: 57.1312175\ttotal: 673ms\tremaining: 15.7s\n",
      "41:\tlearn: 56.7960501\ttotal: 684ms\tremaining: 15.6s\n",
      "42:\tlearn: 56.4765710\ttotal: 695ms\tremaining: 15.5s\n",
      "43:\tlearn: 56.1693306\ttotal: 706ms\tremaining: 15.3s\n",
      "44:\tlearn: 55.8778463\ttotal: 718ms\tremaining: 15.2s\n",
      "45:\tlearn: 55.5978494\ttotal: 730ms\tremaining: 15.1s\n",
      "46:\tlearn: 55.4835274\ttotal: 743ms\tremaining: 15.1s\n",
      "47:\tlearn: 55.2210162\ttotal: 754ms\tremaining: 15s\n",
      "48:\tlearn: 54.9682438\ttotal: 766ms\tremaining: 14.9s\n",
      "49:\tlearn: 54.8751378\ttotal: 778ms\tremaining: 14.8s\n",
      "50:\tlearn: 54.6360300\ttotal: 789ms\tremaining: 14.7s\n",
      "51:\tlearn: 54.4034464\ttotal: 801ms\tremaining: 14.6s\n",
      "52:\tlearn: 54.1833574\ttotal: 816ms\tremaining: 14.6s\n",
      "53:\tlearn: 54.1618580\ttotal: 830ms\tremaining: 14.5s\n",
      "54:\tlearn: 53.9530496\ttotal: 843ms\tremaining: 14.5s\n",
      "55:\tlearn: 53.9349068\ttotal: 854ms\tremaining: 14.4s\n",
      "56:\tlearn: 53.7343287\ttotal: 867ms\tremaining: 14.3s\n",
      "57:\tlearn: 53.7225259\ttotal: 880ms\tremaining: 14.3s\n",
      "58:\tlearn: 53.7066384\ttotal: 894ms\tremaining: 14.3s\n",
      "59:\tlearn: 53.5158588\ttotal: 909ms\tremaining: 14.2s\n",
      "60:\tlearn: 53.3326988\ttotal: 921ms\tremaining: 14.2s\n",
      "61:\tlearn: 53.1582408\ttotal: 932ms\tremaining: 14.1s\n",
      "62:\tlearn: 52.9926934\ttotal: 945ms\tremaining: 14.1s\n",
      "63:\tlearn: 52.8335021\ttotal: 957ms\tremaining: 14s\n",
      "64:\tlearn: 52.8234313\ttotal: 970ms\tremaining: 14s\n",
      "65:\tlearn: 52.7217348\ttotal: 983ms\tremaining: 13.9s\n",
      "66:\tlearn: 52.7169024\ttotal: 995ms\tremaining: 13.9s\n",
      "67:\tlearn: 52.5661471\ttotal: 1.01s\tremaining: 13.8s\n",
      "68:\tlearn: 52.4535813\ttotal: 1.02s\tremaining: 13.8s\n",
      "69:\tlearn: 52.3163194\ttotal: 1.03s\tremaining: 13.7s\n",
      "70:\tlearn: 52.3052572\ttotal: 1.05s\tremaining: 13.7s\n",
      "71:\tlearn: 52.2862677\ttotal: 1.06s\tremaining: 13.6s\n",
      "72:\tlearn: 52.1542769\ttotal: 1.07s\tremaining: 13.6s\n",
      "73:\tlearn: 52.1453624\ttotal: 1.08s\tremaining: 13.5s\n",
      "74:\tlearn: 52.1216495\ttotal: 1.09s\tremaining: 13.5s\n",
      "75:\tlearn: 52.1125448\ttotal: 1.1s\tremaining: 13.4s\n",
      "76:\tlearn: 52.0977020\ttotal: 1.12s\tremaining: 13.4s\n",
      "77:\tlearn: 51.9740683\ttotal: 1.13s\tremaining: 13.4s\n",
      "78:\tlearn: 51.8527387\ttotal: 1.14s\tremaining: 13.3s\n",
      "79:\tlearn: 51.7385428\ttotal: 1.16s\tremaining: 13.3s\n",
      "80:\tlearn: 51.6291717\ttotal: 1.17s\tremaining: 13.2s\n",
      "81:\tlearn: 51.5246034\ttotal: 1.18s\tremaining: 13.2s\n",
      "82:\tlearn: 51.5159172\ttotal: 1.19s\tremaining: 13.2s\n",
      "83:\tlearn: 51.4525513\ttotal: 1.2s\tremaining: 13.1s\n",
      "84:\tlearn: 51.3560622\ttotal: 1.22s\tremaining: 13.1s\n",
      "85:\tlearn: 51.3500431\ttotal: 1.23s\tremaining: 13.1s\n",
      "86:\tlearn: 51.3118318\ttotal: 1.25s\tremaining: 13.1s\n",
      "87:\tlearn: 51.2233020\ttotal: 1.26s\tremaining: 13s\n",
      "88:\tlearn: 51.2183541\ttotal: 1.27s\tremaining: 13s\n",
      "89:\tlearn: 51.2116655\ttotal: 1.28s\tremaining: 13s\n",
      "90:\tlearn: 51.2040722\ttotal: 1.29s\tremaining: 12.9s\n",
      "91:\tlearn: 51.1971106\ttotal: 1.31s\tremaining: 12.9s\n",
      "92:\tlearn: 51.1845946\ttotal: 1.32s\tremaining: 12.9s\n",
      "93:\tlearn: 51.1227496\ttotal: 1.33s\tremaining: 12.8s\n",
      "94:\tlearn: 51.1189009\ttotal: 1.34s\tremaining: 12.8s\n",
      "95:\tlearn: 51.1121599\ttotal: 1.35s\tremaining: 12.7s\n",
      "96:\tlearn: 51.1043361\ttotal: 1.36s\tremaining: 12.7s\n",
      "97:\tlearn: 51.0946624\ttotal: 1.37s\tremaining: 12.6s\n",
      "98:\tlearn: 51.0118078\ttotal: 1.39s\tremaining: 12.6s\n",
      "99:\tlearn: 51.0056186\ttotal: 1.4s\tremaining: 12.6s\n",
      "100:\tlearn: 50.9975241\ttotal: 1.41s\tremaining: 12.5s\n",
      "101:\tlearn: 50.9860844\ttotal: 1.42s\tremaining: 12.5s\n",
      "102:\tlearn: 50.9691593\ttotal: 1.44s\tremaining: 12.5s\n",
      "103:\tlearn: 50.9580838\ttotal: 1.45s\tremaining: 12.5s\n",
      "104:\tlearn: 50.9526350\ttotal: 1.46s\tremaining: 12.5s\n",
      "105:\tlearn: 50.8969363\ttotal: 1.47s\tremaining: 12.4s\n",
      "106:\tlearn: 50.8202135\ttotal: 1.48s\tremaining: 12.4s\n",
      "107:\tlearn: 50.8034350\ttotal: 1.5s\tremaining: 12.4s\n",
      "108:\tlearn: 50.7293579\ttotal: 1.51s\tremaining: 12.3s\n",
      "109:\tlearn: 50.6600906\ttotal: 1.52s\tremaining: 12.3s\n",
      "110:\tlearn: 50.5944508\ttotal: 1.54s\tremaining: 12.3s\n",
      "111:\tlearn: 50.5293597\ttotal: 1.55s\tremaining: 12.3s\n",
      "112:\tlearn: 50.5242647\ttotal: 1.56s\tremaining: 12.3s\n",
      "113:\tlearn: 50.5064627\ttotal: 1.57s\tremaining: 12.2s\n",
      "114:\tlearn: 50.4572946\ttotal: 1.58s\tremaining: 12.2s\n",
      "115:\tlearn: 50.4520113\ttotal: 1.59s\tremaining: 12.1s\n",
      "116:\tlearn: 50.4465385\ttotal: 1.6s\tremaining: 12.1s\n",
      "117:\tlearn: 50.4340802\ttotal: 1.61s\tremaining: 12s\n",
      "118:\tlearn: 50.4031304\ttotal: 1.62s\tremaining: 12s\n",
      "119:\tlearn: 50.3455333\ttotal: 1.63s\tremaining: 12s\n",
      "120:\tlearn: 50.3402433\ttotal: 1.64s\tremaining: 11.9s\n",
      "121:\tlearn: 50.3318731\ttotal: 1.65s\tremaining: 11.9s\n",
      "122:\tlearn: 50.3154616\ttotal: 1.66s\tremaining: 11.8s\n",
      "123:\tlearn: 50.3096703\ttotal: 1.67s\tremaining: 11.8s\n",
      "124:\tlearn: 50.3050669\ttotal: 1.68s\tremaining: 11.8s\n",
      "125:\tlearn: 50.3015356\ttotal: 1.69s\tremaining: 11.7s\n",
      "126:\tlearn: 50.2475904\ttotal: 1.7s\tremaining: 11.7s\n",
      "127:\tlearn: 50.2391573\ttotal: 1.71s\tremaining: 11.7s\n",
      "128:\tlearn: 50.2332395\ttotal: 1.72s\tremaining: 11.6s\n",
      "129:\tlearn: 50.1824060\ttotal: 1.73s\tremaining: 11.6s\n",
      "130:\tlearn: 50.1669179\ttotal: 1.74s\tremaining: 11.5s\n",
      "131:\tlearn: 50.1624274\ttotal: 1.75s\tremaining: 11.5s\n",
      "132:\tlearn: 50.1120509\ttotal: 1.76s\tremaining: 11.5s\n",
      "133:\tlearn: 50.0643559\ttotal: 1.77s\tremaining: 11.4s\n",
      "134:\tlearn: 50.0206371\ttotal: 1.78s\tremaining: 11.4s\n",
      "135:\tlearn: 50.0088121\ttotal: 1.79s\tremaining: 11.4s\n",
      "136:\tlearn: 50.0032677\ttotal: 1.8s\tremaining: 11.3s\n",
      "137:\tlearn: 49.9991552\ttotal: 1.81s\tremaining: 11.3s\n",
      "138:\tlearn: 49.9934332\ttotal: 1.82s\tremaining: 11.3s\n",
      "139:\tlearn: 49.9892516\ttotal: 1.83s\tremaining: 11.2s\n",
      "140:\tlearn: 49.9809019\ttotal: 1.84s\tremaining: 11.2s\n",
      "141:\tlearn: 49.9390001\ttotal: 1.85s\tremaining: 11.2s\n",
      "142:\tlearn: 49.9355454\ttotal: 1.86s\tremaining: 11.2s\n",
      "143:\tlearn: 49.9293738\ttotal: 1.87s\tremaining: 11.1s\n",
      "144:\tlearn: 49.9252924\ttotal: 1.88s\tremaining: 11.1s\n",
      "145:\tlearn: 49.8851365\ttotal: 1.89s\tremaining: 11s\n",
      "146:\tlearn: 49.8780157\ttotal: 1.9s\tremaining: 11s\n",
      "147:\tlearn: 49.8741068\ttotal: 1.91s\tremaining: 11s\n",
      "148:\tlearn: 49.8356383\ttotal: 1.92s\tremaining: 11s\n",
      "149:\tlearn: 49.8317219\ttotal: 1.93s\tremaining: 10.9s\n",
      "150:\tlearn: 49.8274258\ttotal: 1.94s\tremaining: 10.9s\n",
      "151:\tlearn: 49.8236648\ttotal: 1.95s\tremaining: 10.9s\n",
      "152:\tlearn: 49.7862406\ttotal: 1.96s\tremaining: 10.9s\n",
      "153:\tlearn: 49.7768830\ttotal: 1.97s\tremaining: 10.8s\n",
      "154:\tlearn: 49.7687467\ttotal: 1.98s\tremaining: 10.8s\n",
      "155:\tlearn: 49.7304021\ttotal: 1.99s\tremaining: 10.8s\n",
      "156:\tlearn: 49.7273981\ttotal: 2s\tremaining: 10.7s\n",
      "157:\tlearn: 49.6898043\ttotal: 2.01s\tremaining: 10.7s\n",
      "158:\tlearn: 49.6536592\ttotal: 2.02s\tremaining: 10.7s\n",
      "159:\tlearn: 49.6501355\ttotal: 2.03s\tremaining: 10.7s\n",
      "160:\tlearn: 49.6480601\ttotal: 2.04s\tremaining: 10.6s\n",
      "161:\tlearn: 49.6416953\ttotal: 2.05s\tremaining: 10.6s\n",
      "162:\tlearn: 49.6388399\ttotal: 2.06s\tremaining: 10.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163:\tlearn: 49.6239983\ttotal: 2.08s\tremaining: 10.6s\n",
      "164:\tlearn: 49.6153433\ttotal: 2.09s\tremaining: 10.6s\n",
      "165:\tlearn: 49.6076363\ttotal: 2.1s\tremaining: 10.5s\n",
      "166:\tlearn: 49.6031913\ttotal: 2.11s\tremaining: 10.5s\n",
      "167:\tlearn: 49.5709738\ttotal: 2.12s\tremaining: 10.5s\n",
      "168:\tlearn: 49.5661821\ttotal: 2.13s\tremaining: 10.5s\n",
      "169:\tlearn: 49.5628548\ttotal: 2.13s\tremaining: 10.4s\n",
      "170:\tlearn: 49.5502766\ttotal: 2.14s\tremaining: 10.4s\n",
      "171:\tlearn: 49.5457798\ttotal: 2.15s\tremaining: 10.4s\n",
      "172:\tlearn: 49.5404681\ttotal: 2.16s\tremaining: 10.3s\n",
      "173:\tlearn: 49.5102647\ttotal: 2.17s\tremaining: 10.3s\n",
      "174:\tlearn: 49.5027402\ttotal: 2.18s\tremaining: 10.3s\n",
      "175:\tlearn: 49.4932884\ttotal: 2.19s\tremaining: 10.3s\n",
      "176:\tlearn: 49.4832100\ttotal: 2.2s\tremaining: 10.2s\n",
      "177:\tlearn: 49.4823799\ttotal: 2.21s\tremaining: 10.2s\n",
      "178:\tlearn: 49.4705881\ttotal: 2.22s\tremaining: 10.2s\n",
      "179:\tlearn: 49.4395505\ttotal: 2.23s\tremaining: 10.2s\n",
      "180:\tlearn: 49.4295919\ttotal: 2.24s\tremaining: 10.1s\n",
      "181:\tlearn: 49.4264229\ttotal: 2.25s\tremaining: 10.1s\n",
      "182:\tlearn: 49.4117297\ttotal: 2.26s\tremaining: 10.1s\n",
      "183:\tlearn: 49.4057683\ttotal: 2.27s\tremaining: 10.1s\n",
      "184:\tlearn: 49.4019624\ttotal: 2.28s\tremaining: 10s\n",
      "185:\tlearn: 49.3725928\ttotal: 2.29s\tremaining: 10s\n",
      "186:\tlearn: 49.3666149\ttotal: 2.3s\tremaining: 10s\n",
      "187:\tlearn: 49.3605971\ttotal: 2.31s\tremaining: 9.97s\n",
      "188:\tlearn: 49.3563896\ttotal: 2.32s\tremaining: 9.95s\n",
      "189:\tlearn: 49.3491258\ttotal: 2.33s\tremaining: 9.93s\n",
      "190:\tlearn: 49.3362690\ttotal: 2.34s\tremaining: 9.9s\n",
      "191:\tlearn: 49.3106555\ttotal: 2.35s\tremaining: 9.87s\n",
      "192:\tlearn: 49.3007426\ttotal: 2.35s\tremaining: 9.84s\n",
      "193:\tlearn: 49.2916952\ttotal: 2.36s\tremaining: 9.82s\n",
      "194:\tlearn: 49.2887878\ttotal: 2.37s\tremaining: 9.79s\n",
      "195:\tlearn: 49.2802523\ttotal: 2.38s\tremaining: 9.77s\n",
      "196:\tlearn: 49.2719803\ttotal: 2.39s\tremaining: 9.74s\n",
      "197:\tlearn: 49.2690393\ttotal: 2.4s\tremaining: 9.73s\n",
      "198:\tlearn: 49.2660252\ttotal: 2.41s\tremaining: 9.7s\n",
      "199:\tlearn: 49.2592507\ttotal: 2.42s\tremaining: 9.67s\n",
      "200:\tlearn: 49.2328657\ttotal: 2.43s\tremaining: 9.65s\n",
      "201:\tlearn: 49.2069844\ttotal: 2.44s\tremaining: 9.63s\n",
      "202:\tlearn: 49.1953363\ttotal: 2.45s\tremaining: 9.61s\n",
      "203:\tlearn: 49.1875813\ttotal: 2.46s\tremaining: 9.59s\n",
      "204:\tlearn: 49.1803062\ttotal: 2.47s\tremaining: 9.57s\n",
      "205:\tlearn: 49.1697923\ttotal: 2.48s\tremaining: 9.55s\n",
      "206:\tlearn: 49.1662073\ttotal: 2.49s\tremaining: 9.53s\n",
      "207:\tlearn: 49.1623823\ttotal: 2.5s\tremaining: 9.51s\n",
      "208:\tlearn: 49.1577456\ttotal: 2.51s\tremaining: 9.49s\n",
      "209:\tlearn: 49.1330608\ttotal: 2.52s\tremaining: 9.47s\n",
      "210:\tlearn: 49.1095410\ttotal: 2.53s\tremaining: 9.45s\n",
      "211:\tlearn: 49.1029609\ttotal: 2.54s\tremaining: 9.43s\n",
      "212:\tlearn: 49.0984588\ttotal: 2.55s\tremaining: 9.41s\n",
      "213:\tlearn: 49.0955771\ttotal: 2.56s\tremaining: 9.39s\n",
      "214:\tlearn: 49.0894064\ttotal: 2.57s\tremaining: 9.37s\n",
      "215:\tlearn: 49.0669873\ttotal: 2.58s\tremaining: 9.36s\n",
      "216:\tlearn: 49.0484431\ttotal: 2.59s\tremaining: 9.34s\n",
      "217:\tlearn: 49.0450671\ttotal: 2.6s\tremaining: 9.32s\n",
      "218:\tlearn: 49.0386726\ttotal: 2.61s\tremaining: 9.3s\n",
      "219:\tlearn: 49.0359288\ttotal: 2.62s\tremaining: 9.27s\n",
      "220:\tlearn: 49.0291665\ttotal: 2.63s\tremaining: 9.26s\n",
      "221:\tlearn: 49.0106113\ttotal: 2.63s\tremaining: 9.23s\n",
      "222:\tlearn: 49.0028594\ttotal: 2.64s\tremaining: 9.21s\n",
      "223:\tlearn: 48.9975252\ttotal: 2.65s\tremaining: 9.2s\n",
      "224:\tlearn: 48.9940050\ttotal: 2.67s\tremaining: 9.18s\n",
      "225:\tlearn: 48.9829497\ttotal: 2.67s\tremaining: 9.16s\n",
      "226:\tlearn: 48.9788435\ttotal: 2.69s\tremaining: 9.14s\n",
      "227:\tlearn: 48.9707123\ttotal: 2.7s\tremaining: 9.13s\n",
      "228:\tlearn: 48.9667948\ttotal: 2.71s\tremaining: 9.11s\n",
      "229:\tlearn: 48.9460586\ttotal: 2.72s\tremaining: 9.1s\n",
      "230:\tlearn: 48.9429506\ttotal: 2.73s\tremaining: 9.08s\n",
      "231:\tlearn: 48.9403353\ttotal: 2.73s\tremaining: 9.05s\n",
      "232:\tlearn: 48.9277026\ttotal: 2.75s\tremaining: 9.04s\n",
      "233:\tlearn: 48.9086561\ttotal: 2.76s\tremaining: 9.02s\n",
      "234:\tlearn: 48.9023257\ttotal: 2.77s\tremaining: 9s\n",
      "235:\tlearn: 48.8886912\ttotal: 2.77s\tremaining: 8.98s\n",
      "236:\tlearn: 48.8728385\ttotal: 2.78s\tremaining: 8.96s\n",
      "237:\tlearn: 48.8699644\ttotal: 2.79s\tremaining: 8.94s\n",
      "238:\tlearn: 48.8679776\ttotal: 2.8s\tremaining: 8.93s\n",
      "239:\tlearn: 48.8624998\ttotal: 2.81s\tremaining: 8.91s\n",
      "240:\tlearn: 48.8578600\ttotal: 2.82s\tremaining: 8.89s\n",
      "241:\tlearn: 48.8396992\ttotal: 2.83s\tremaining: 8.88s\n",
      "242:\tlearn: 48.8231168\ttotal: 2.84s\tremaining: 8.86s\n",
      "243:\tlearn: 48.8086058\ttotal: 2.85s\tremaining: 8.84s\n",
      "244:\tlearn: 48.8016776\ttotal: 2.86s\tremaining: 8.82s\n",
      "245:\tlearn: 48.7911074\ttotal: 2.87s\tremaining: 8.81s\n",
      "246:\tlearn: 48.7867522\ttotal: 2.88s\tremaining: 8.79s\n",
      "247:\tlearn: 48.7786761\ttotal: 2.9s\tremaining: 8.78s\n",
      "248:\tlearn: 48.7627470\ttotal: 2.91s\tremaining: 8.77s\n",
      "249:\tlearn: 48.7494318\ttotal: 2.92s\tremaining: 8.75s\n",
      "250:\tlearn: 48.7335172\ttotal: 2.93s\tremaining: 8.74s\n",
      "251:\tlearn: 48.7189179\ttotal: 2.94s\tremaining: 8.72s\n",
      "252:\tlearn: 48.7104632\ttotal: 2.95s\tremaining: 8.7s\n",
      "253:\tlearn: 48.7051266\ttotal: 2.96s\tremaining: 8.69s\n",
      "254:\tlearn: 48.7001783\ttotal: 2.97s\tremaining: 8.67s\n",
      "255:\tlearn: 48.6935792\ttotal: 2.98s\tremaining: 8.65s\n",
      "256:\tlearn: 48.6821875\ttotal: 2.99s\tremaining: 8.64s\n",
      "257:\tlearn: 48.6773130\ttotal: 3s\tremaining: 8.63s\n",
      "258:\tlearn: 48.6743357\ttotal: 3.01s\tremaining: 8.6s\n",
      "259:\tlearn: 48.6718334\ttotal: 3.02s\tremaining: 8.58s\n",
      "260:\tlearn: 48.6647210\ttotal: 3.02s\tremaining: 8.56s\n",
      "261:\tlearn: 48.6508011\ttotal: 3.03s\tremaining: 8.55s\n",
      "262:\tlearn: 48.6443977\ttotal: 3.04s\tremaining: 8.53s\n",
      "263:\tlearn: 48.6387153\ttotal: 3.06s\tremaining: 8.52s\n",
      "264:\tlearn: 48.6254651\ttotal: 3.07s\tremaining: 8.5s\n",
      "265:\tlearn: 48.6179833\ttotal: 3.08s\tremaining: 8.49s\n",
      "266:\tlearn: 48.6139075\ttotal: 3.09s\tremaining: 8.48s\n",
      "267:\tlearn: 48.6004385\ttotal: 3.1s\tremaining: 8.46s\n",
      "268:\tlearn: 48.5926568\ttotal: 3.11s\tremaining: 8.45s\n",
      "269:\tlearn: 48.5896943\ttotal: 3.12s\tremaining: 8.43s\n",
      "270:\tlearn: 48.5879257\ttotal: 3.13s\tremaining: 8.41s\n",
      "271:\tlearn: 48.5733177\ttotal: 3.13s\tremaining: 8.39s\n",
      "272:\tlearn: 48.5622308\ttotal: 3.15s\tremaining: 8.38s\n",
      "273:\tlearn: 48.5552721\ttotal: 3.15s\tremaining: 8.36s\n",
      "274:\tlearn: 48.5502388\ttotal: 3.16s\tremaining: 8.34s\n",
      "275:\tlearn: 48.5478520\ttotal: 3.17s\tremaining: 8.32s\n",
      "276:\tlearn: 48.5423505\ttotal: 3.18s\tremaining: 8.31s\n",
      "277:\tlearn: 48.5316248\ttotal: 3.19s\tremaining: 8.29s\n",
      "278:\tlearn: 48.5171783\ttotal: 3.2s\tremaining: 8.28s\n",
      "279:\tlearn: 48.5154969\ttotal: 3.21s\tremaining: 8.26s\n",
      "280:\tlearn: 48.5075076\ttotal: 3.22s\tremaining: 8.24s\n",
      "281:\tlearn: 48.4939847\ttotal: 3.23s\tremaining: 8.22s\n",
      "282:\tlearn: 48.4856020\ttotal: 3.24s\tremaining: 8.21s\n",
      "283:\tlearn: 48.4672647\ttotal: 3.25s\tremaining: 8.2s\n",
      "284:\tlearn: 48.4606972\ttotal: 3.26s\tremaining: 8.18s\n",
      "285:\tlearn: 48.4552451\ttotal: 3.27s\tremaining: 8.17s\n",
      "286:\tlearn: 48.4502836\ttotal: 3.28s\tremaining: 8.15s\n",
      "287:\tlearn: 48.4432949\ttotal: 3.29s\tremaining: 8.14s\n",
      "288:\tlearn: 48.4369484\ttotal: 3.3s\tremaining: 8.12s\n",
      "289:\tlearn: 48.4274517\ttotal: 3.31s\tremaining: 8.11s\n",
      "290:\tlearn: 48.4227736\ttotal: 3.32s\tremaining: 8.1s\n",
      "291:\tlearn: 48.4211717\ttotal: 3.33s\tremaining: 8.08s\n",
      "292:\tlearn: 48.4136450\ttotal: 3.34s\tremaining: 8.06s\n",
      "293:\tlearn: 48.4029885\ttotal: 3.35s\tremaining: 8.05s\n",
      "294:\tlearn: 48.3976015\ttotal: 3.36s\tremaining: 8.03s\n",
      "295:\tlearn: 48.3911031\ttotal: 3.37s\tremaining: 8.02s\n",
      "296:\tlearn: 48.3789106\ttotal: 3.38s\tremaining: 8s\n",
      "297:\tlearn: 48.3712311\ttotal: 3.39s\tremaining: 7.98s\n",
      "298:\tlearn: 48.3614412\ttotal: 3.4s\tremaining: 7.97s\n",
      "299:\tlearn: 48.3600171\ttotal: 3.41s\tremaining: 7.95s\n",
      "300:\tlearn: 48.3544758\ttotal: 3.42s\tremaining: 7.93s\n",
      "301:\tlearn: 48.3477843\ttotal: 3.43s\tremaining: 7.93s\n",
      "302:\tlearn: 48.3429430\ttotal: 3.44s\tremaining: 7.91s\n",
      "303:\tlearn: 48.3390626\ttotal: 3.45s\tremaining: 7.9s\n",
      "304:\tlearn: 48.3323059\ttotal: 3.46s\tremaining: 7.88s\n",
      "305:\tlearn: 48.3258555\ttotal: 3.47s\tremaining: 7.87s\n",
      "306:\tlearn: 48.3204827\ttotal: 3.48s\tremaining: 7.86s\n",
      "307:\tlearn: 48.3094046\ttotal: 3.49s\tremaining: 7.84s\n",
      "308:\tlearn: 48.3005399\ttotal: 3.5s\tremaining: 7.82s\n",
      "309:\tlearn: 48.2961750\ttotal: 3.51s\tremaining: 7.81s\n",
      "310:\tlearn: 48.2914140\ttotal: 3.52s\tremaining: 7.8s\n",
      "311:\tlearn: 48.2878332\ttotal: 3.53s\tremaining: 7.79s\n",
      "312:\tlearn: 48.2826712\ttotal: 3.54s\tremaining: 7.77s\n",
      "313:\tlearn: 48.2738098\ttotal: 3.55s\tremaining: 7.76s\n",
      "314:\tlearn: 48.2709593\ttotal: 3.56s\tremaining: 7.74s\n",
      "315:\tlearn: 48.2587178\ttotal: 3.57s\tremaining: 7.73s\n",
      "316:\tlearn: 48.2546548\ttotal: 3.58s\tremaining: 7.72s\n",
      "317:\tlearn: 48.2515918\ttotal: 3.59s\tremaining: 7.7s\n",
      "318:\tlearn: 48.2430188\ttotal: 3.6s\tremaining: 7.68s\n",
      "319:\tlearn: 48.2361051\ttotal: 3.61s\tremaining: 7.67s\n",
      "320:\tlearn: 48.2303897\ttotal: 3.62s\tremaining: 7.66s\n",
      "321:\tlearn: 48.2274738\ttotal: 3.63s\tremaining: 7.63s\n",
      "322:\tlearn: 48.2229927\ttotal: 3.64s\tremaining: 7.62s\n",
      "323:\tlearn: 48.2192571\ttotal: 3.65s\tremaining: 7.61s\n",
      "324:\tlearn: 48.2041843\ttotal: 3.66s\tremaining: 7.6s\n",
      "325:\tlearn: 48.1967489\ttotal: 3.67s\tremaining: 7.58s\n",
      "326:\tlearn: 48.1857430\ttotal: 3.68s\tremaining: 7.57s\n",
      "327:\tlearn: 48.1811391\ttotal: 3.69s\tremaining: 7.55s\n",
      "328:\tlearn: 48.1773438\ttotal: 3.69s\tremaining: 7.53s\n",
      "329:\tlearn: 48.1668623\ttotal: 3.7s\tremaining: 7.52s\n",
      "330:\tlearn: 48.1609757\ttotal: 3.71s\tremaining: 7.51s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331:\tlearn: 48.1563643\ttotal: 3.73s\tremaining: 7.5s\n",
      "332:\tlearn: 48.1413600\ttotal: 3.74s\tremaining: 7.49s\n",
      "333:\tlearn: 48.1316160\ttotal: 3.75s\tremaining: 7.48s\n",
      "334:\tlearn: 48.1290482\ttotal: 3.76s\tremaining: 7.46s\n",
      "335:\tlearn: 48.1214575\ttotal: 3.77s\tremaining: 7.45s\n",
      "336:\tlearn: 48.1179326\ttotal: 3.78s\tremaining: 7.44s\n",
      "337:\tlearn: 48.1089052\ttotal: 3.79s\tremaining: 7.43s\n",
      "338:\tlearn: 48.1073249\ttotal: 3.8s\tremaining: 7.42s\n",
      "339:\tlearn: 48.0997854\ttotal: 3.81s\tremaining: 7.41s\n",
      "340:\tlearn: 48.0835243\ttotal: 3.83s\tremaining: 7.4s\n",
      "341:\tlearn: 48.0735630\ttotal: 3.84s\tremaining: 7.39s\n",
      "342:\tlearn: 48.0693158\ttotal: 3.85s\tremaining: 7.38s\n",
      "343:\tlearn: 48.0623806\ttotal: 3.87s\tremaining: 7.37s\n",
      "344:\tlearn: 48.0587764\ttotal: 3.88s\tremaining: 7.36s\n",
      "345:\tlearn: 48.0533595\ttotal: 3.89s\tremaining: 7.34s\n",
      "346:\tlearn: 48.0468163\ttotal: 3.9s\tremaining: 7.33s\n",
      "347:\tlearn: 48.0394062\ttotal: 3.91s\tremaining: 7.32s\n",
      "348:\tlearn: 48.0351635\ttotal: 3.92s\tremaining: 7.32s\n",
      "349:\tlearn: 48.0195834\ttotal: 3.94s\tremaining: 7.31s\n",
      "350:\tlearn: 48.0133578\ttotal: 3.95s\tremaining: 7.3s\n",
      "351:\tlearn: 48.0050778\ttotal: 3.96s\tremaining: 7.29s\n",
      "352:\tlearn: 47.9973754\ttotal: 3.97s\tremaining: 7.28s\n",
      "353:\tlearn: 47.9961987\ttotal: 3.98s\tremaining: 7.27s\n",
      "354:\tlearn: 47.9940287\ttotal: 4s\tremaining: 7.26s\n",
      "355:\tlearn: 47.9877764\ttotal: 4.01s\tremaining: 7.25s\n",
      "356:\tlearn: 47.9794289\ttotal: 4.02s\tremaining: 7.24s\n",
      "357:\tlearn: 47.9768673\ttotal: 4.03s\tremaining: 7.23s\n",
      "358:\tlearn: 47.9694658\ttotal: 4.04s\tremaining: 7.22s\n",
      "359:\tlearn: 47.9651065\ttotal: 4.06s\tremaining: 7.21s\n",
      "360:\tlearn: 47.9570241\ttotal: 4.07s\tremaining: 7.21s\n",
      "361:\tlearn: 47.9486983\ttotal: 4.08s\tremaining: 7.2s\n",
      "362:\tlearn: 47.9373869\ttotal: 4.09s\tremaining: 7.18s\n",
      "363:\tlearn: 47.9298210\ttotal: 4.11s\tremaining: 7.18s\n",
      "364:\tlearn: 47.9237751\ttotal: 4.12s\tremaining: 7.16s\n",
      "365:\tlearn: 47.9054410\ttotal: 4.13s\tremaining: 7.15s\n",
      "366:\tlearn: 47.8969361\ttotal: 4.14s\tremaining: 7.14s\n",
      "367:\tlearn: 47.8919136\ttotal: 4.15s\tremaining: 7.13s\n",
      "368:\tlearn: 47.8855936\ttotal: 4.17s\tremaining: 7.12s\n",
      "369:\tlearn: 47.8806278\ttotal: 4.18s\tremaining: 7.11s\n",
      "370:\tlearn: 47.8751197\ttotal: 4.19s\tremaining: 7.1s\n",
      "371:\tlearn: 47.8688033\ttotal: 4.2s\tremaining: 7.09s\n",
      "372:\tlearn: 47.8611566\ttotal: 4.21s\tremaining: 7.08s\n",
      "373:\tlearn: 47.8531019\ttotal: 4.22s\tremaining: 7.07s\n",
      "374:\tlearn: 47.8436544\ttotal: 4.24s\tremaining: 7.06s\n",
      "375:\tlearn: 47.8359436\ttotal: 4.25s\tremaining: 7.05s\n",
      "376:\tlearn: 47.8338807\ttotal: 4.26s\tremaining: 7.04s\n",
      "377:\tlearn: 47.8286746\ttotal: 4.28s\tremaining: 7.03s\n",
      "378:\tlearn: 47.8232232\ttotal: 4.29s\tremaining: 7.03s\n",
      "379:\tlearn: 47.8197438\ttotal: 4.3s\tremaining: 7.01s\n",
      "380:\tlearn: 47.8128562\ttotal: 4.31s\tremaining: 7.01s\n",
      "381:\tlearn: 47.8066770\ttotal: 4.32s\tremaining: 6.99s\n",
      "382:\tlearn: 47.7949277\ttotal: 4.33s\tremaining: 6.98s\n",
      "383:\tlearn: 47.7902376\ttotal: 4.35s\tremaining: 6.97s\n",
      "384:\tlearn: 47.7861972\ttotal: 4.36s\tremaining: 6.96s\n",
      "385:\tlearn: 47.7776294\ttotal: 4.37s\tremaining: 6.95s\n",
      "386:\tlearn: 47.7707170\ttotal: 4.38s\tremaining: 6.94s\n",
      "387:\tlearn: 47.7638030\ttotal: 4.39s\tremaining: 6.93s\n",
      "388:\tlearn: 47.7493942\ttotal: 4.41s\tremaining: 6.92s\n",
      "389:\tlearn: 47.7425711\ttotal: 4.42s\tremaining: 6.91s\n",
      "390:\tlearn: 47.7346146\ttotal: 4.43s\tremaining: 6.9s\n",
      "391:\tlearn: 47.7299970\ttotal: 4.44s\tremaining: 6.89s\n",
      "392:\tlearn: 47.7254515\ttotal: 4.45s\tremaining: 6.88s\n",
      "393:\tlearn: 47.7162170\ttotal: 4.47s\tremaining: 6.87s\n",
      "394:\tlearn: 47.7096293\ttotal: 4.48s\tremaining: 6.86s\n",
      "395:\tlearn: 47.7063365\ttotal: 4.49s\tremaining: 6.85s\n",
      "396:\tlearn: 47.6986008\ttotal: 4.5s\tremaining: 6.84s\n",
      "397:\tlearn: 47.6828705\ttotal: 4.51s\tremaining: 6.83s\n",
      "398:\tlearn: 47.6742691\ttotal: 4.53s\tremaining: 6.82s\n",
      "399:\tlearn: 47.6682570\ttotal: 4.54s\tremaining: 6.81s\n",
      "400:\tlearn: 47.6621380\ttotal: 4.55s\tremaining: 6.8s\n",
      "401:\tlearn: 47.6570068\ttotal: 4.56s\tremaining: 6.79s\n",
      "402:\tlearn: 47.6551263\ttotal: 4.57s\tremaining: 6.78s\n",
      "403:\tlearn: 47.6485136\ttotal: 4.59s\tremaining: 6.77s\n",
      "404:\tlearn: 47.6438309\ttotal: 4.6s\tremaining: 6.76s\n",
      "405:\tlearn: 47.6403867\ttotal: 4.61s\tremaining: 6.75s\n",
      "406:\tlearn: 47.6361636\ttotal: 4.62s\tremaining: 6.74s\n",
      "407:\tlearn: 47.6292120\ttotal: 4.63s\tremaining: 6.72s\n",
      "408:\tlearn: 47.6229711\ttotal: 4.64s\tremaining: 6.71s\n",
      "409:\tlearn: 47.6170772\ttotal: 4.66s\tremaining: 6.7s\n",
      "410:\tlearn: 47.6084325\ttotal: 4.67s\tremaining: 6.69s\n",
      "411:\tlearn: 47.6042931\ttotal: 4.68s\tremaining: 6.68s\n",
      "412:\tlearn: 47.5903364\ttotal: 4.69s\tremaining: 6.67s\n",
      "413:\tlearn: 47.5783555\ttotal: 4.7s\tremaining: 6.66s\n",
      "414:\tlearn: 47.5678521\ttotal: 4.71s\tremaining: 6.65s\n",
      "415:\tlearn: 47.5555478\ttotal: 4.73s\tremaining: 6.64s\n",
      "416:\tlearn: 47.5508356\ttotal: 4.74s\tremaining: 6.63s\n",
      "417:\tlearn: 47.5430262\ttotal: 4.76s\tremaining: 6.62s\n",
      "418:\tlearn: 47.5407234\ttotal: 4.77s\tremaining: 6.61s\n",
      "419:\tlearn: 47.5355872\ttotal: 4.78s\tremaining: 6.6s\n",
      "420:\tlearn: 47.5293010\ttotal: 4.79s\tremaining: 6.59s\n",
      "421:\tlearn: 47.5224358\ttotal: 4.8s\tremaining: 6.58s\n",
      "422:\tlearn: 47.5206408\ttotal: 4.81s\tremaining: 6.56s\n",
      "423:\tlearn: 47.5124484\ttotal: 4.83s\tremaining: 6.55s\n",
      "424:\tlearn: 47.5041466\ttotal: 4.84s\tremaining: 6.54s\n",
      "425:\tlearn: 47.4993097\ttotal: 4.85s\tremaining: 6.53s\n",
      "426:\tlearn: 47.4941046\ttotal: 4.86s\tremaining: 6.52s\n",
      "427:\tlearn: 47.4801783\ttotal: 4.87s\tremaining: 6.51s\n",
      "428:\tlearn: 47.4750546\ttotal: 4.88s\tremaining: 6.5s\n",
      "429:\tlearn: 47.4733423\ttotal: 4.89s\tremaining: 6.49s\n",
      "430:\tlearn: 47.4660995\ttotal: 4.91s\tremaining: 6.48s\n",
      "431:\tlearn: 47.4639028\ttotal: 4.91s\tremaining: 6.46s\n",
      "432:\tlearn: 47.4585421\ttotal: 4.93s\tremaining: 6.45s\n",
      "433:\tlearn: 47.4526106\ttotal: 4.94s\tremaining: 6.44s\n",
      "434:\tlearn: 47.4378063\ttotal: 4.95s\tremaining: 6.43s\n",
      "435:\tlearn: 47.4240929\ttotal: 4.96s\tremaining: 6.42s\n",
      "436:\tlearn: 47.4199431\ttotal: 4.97s\tremaining: 6.41s\n",
      "437:\tlearn: 47.4153973\ttotal: 4.99s\tremaining: 6.4s\n",
      "438:\tlearn: 47.4126593\ttotal: 5s\tremaining: 6.39s\n",
      "439:\tlearn: 47.4069370\ttotal: 5.01s\tremaining: 6.38s\n",
      "440:\tlearn: 47.4024174\ttotal: 5.02s\tremaining: 6.37s\n",
      "441:\tlearn: 47.3954910\ttotal: 5.04s\tremaining: 6.36s\n",
      "442:\tlearn: 47.3883736\ttotal: 5.05s\tremaining: 6.35s\n",
      "443:\tlearn: 47.3834535\ttotal: 5.06s\tremaining: 6.34s\n",
      "444:\tlearn: 47.3707684\ttotal: 5.07s\tremaining: 6.33s\n",
      "445:\tlearn: 47.3614927\ttotal: 5.09s\tremaining: 6.32s\n",
      "446:\tlearn: 47.3517615\ttotal: 5.1s\tremaining: 6.31s\n",
      "447:\tlearn: 47.3501260\ttotal: 5.11s\tremaining: 6.29s\n",
      "448:\tlearn: 47.3370062\ttotal: 5.12s\tremaining: 6.28s\n",
      "449:\tlearn: 47.3343993\ttotal: 5.13s\tremaining: 6.27s\n",
      "450:\tlearn: 47.3190624\ttotal: 5.14s\tremaining: 6.26s\n",
      "451:\tlearn: 47.3132893\ttotal: 5.15s\tremaining: 6.25s\n",
      "452:\tlearn: 47.3081797\ttotal: 5.16s\tremaining: 6.24s\n",
      "453:\tlearn: 47.3040516\ttotal: 5.18s\tremaining: 6.23s\n",
      "454:\tlearn: 47.2964437\ttotal: 5.19s\tremaining: 6.22s\n",
      "455:\tlearn: 47.2886904\ttotal: 5.21s\tremaining: 6.21s\n",
      "456:\tlearn: 47.2834210\ttotal: 5.22s\tremaining: 6.21s\n",
      "457:\tlearn: 47.2719023\ttotal: 5.24s\tremaining: 6.2s\n",
      "458:\tlearn: 47.2693202\ttotal: 5.25s\tremaining: 6.19s\n",
      "459:\tlearn: 47.2662988\ttotal: 5.26s\tremaining: 6.18s\n",
      "460:\tlearn: 47.2537483\ttotal: 5.27s\tremaining: 6.17s\n",
      "461:\tlearn: 47.2479361\ttotal: 5.28s\tremaining: 6.15s\n",
      "462:\tlearn: 47.2327889\ttotal: 5.3s\tremaining: 6.14s\n",
      "463:\tlearn: 47.2271211\ttotal: 5.31s\tremaining: 6.13s\n",
      "464:\tlearn: 47.2226681\ttotal: 5.32s\tremaining: 6.12s\n",
      "465:\tlearn: 47.2162844\ttotal: 5.33s\tremaining: 6.11s\n",
      "466:\tlearn: 47.2120972\ttotal: 5.34s\tremaining: 6.1s\n",
      "467:\tlearn: 47.2084779\ttotal: 5.35s\tremaining: 6.09s\n",
      "468:\tlearn: 47.1996862\ttotal: 5.37s\tremaining: 6.08s\n",
      "469:\tlearn: 47.1910586\ttotal: 5.38s\tremaining: 6.06s\n",
      "470:\tlearn: 47.1837777\ttotal: 5.39s\tremaining: 6.05s\n",
      "471:\tlearn: 47.1685981\ttotal: 5.4s\tremaining: 6.04s\n",
      "472:\tlearn: 47.1637543\ttotal: 5.41s\tremaining: 6.03s\n",
      "473:\tlearn: 47.1546240\ttotal: 5.43s\tremaining: 6.02s\n",
      "474:\tlearn: 47.1516606\ttotal: 5.44s\tremaining: 6.01s\n",
      "475:\tlearn: 47.1470375\ttotal: 5.45s\tremaining: 6s\n",
      "476:\tlearn: 47.1414405\ttotal: 5.46s\tremaining: 5.99s\n",
      "477:\tlearn: 47.1348104\ttotal: 5.47s\tremaining: 5.98s\n",
      "478:\tlearn: 47.1297491\ttotal: 5.49s\tremaining: 5.97s\n",
      "479:\tlearn: 47.1254166\ttotal: 5.5s\tremaining: 5.96s\n",
      "480:\tlearn: 47.1207417\ttotal: 5.51s\tremaining: 5.95s\n",
      "481:\tlearn: 47.1158805\ttotal: 5.52s\tremaining: 5.93s\n",
      "482:\tlearn: 47.1111204\ttotal: 5.54s\tremaining: 5.92s\n",
      "483:\tlearn: 47.1083451\ttotal: 5.55s\tremaining: 5.91s\n",
      "484:\tlearn: 47.1067826\ttotal: 5.55s\tremaining: 5.9s\n",
      "485:\tlearn: 47.1027777\ttotal: 5.57s\tremaining: 5.89s\n",
      "486:\tlearn: 47.0964560\ttotal: 5.58s\tremaining: 5.88s\n",
      "487:\tlearn: 47.0930766\ttotal: 5.59s\tremaining: 5.87s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488:\tlearn: 47.0891396\ttotal: 5.6s\tremaining: 5.86s\n",
      "489:\tlearn: 47.0818364\ttotal: 5.62s\tremaining: 5.84s\n",
      "490:\tlearn: 47.0758681\ttotal: 5.63s\tremaining: 5.83s\n",
      "491:\tlearn: 47.0680409\ttotal: 5.64s\tremaining: 5.82s\n",
      "492:\tlearn: 47.0619410\ttotal: 5.65s\tremaining: 5.81s\n",
      "493:\tlearn: 47.0558340\ttotal: 5.67s\tremaining: 5.8s\n",
      "494:\tlearn: 47.0521098\ttotal: 5.68s\tremaining: 5.79s\n",
      "495:\tlearn: 47.0473333\ttotal: 5.69s\tremaining: 5.78s\n",
      "496:\tlearn: 47.0387250\ttotal: 5.7s\tremaining: 5.77s\n",
      "497:\tlearn: 47.0351314\ttotal: 5.71s\tremaining: 5.76s\n",
      "498:\tlearn: 47.0208200\ttotal: 5.72s\tremaining: 5.75s\n",
      "499:\tlearn: 47.0141585\ttotal: 5.74s\tremaining: 5.74s\n",
      "500:\tlearn: 47.0067118\ttotal: 5.75s\tremaining: 5.73s\n",
      "501:\tlearn: 46.9964006\ttotal: 5.76s\tremaining: 5.72s\n",
      "502:\tlearn: 46.9903974\ttotal: 5.78s\tremaining: 5.71s\n",
      "503:\tlearn: 46.9773062\ttotal: 5.79s\tremaining: 5.7s\n",
      "504:\tlearn: 46.9723988\ttotal: 5.8s\tremaining: 5.68s\n",
      "505:\tlearn: 46.9603479\ttotal: 5.81s\tremaining: 5.67s\n",
      "506:\tlearn: 46.9491677\ttotal: 5.82s\tremaining: 5.66s\n",
      "507:\tlearn: 46.9449053\ttotal: 5.84s\tremaining: 5.65s\n",
      "508:\tlearn: 46.9378079\ttotal: 5.85s\tremaining: 5.64s\n",
      "509:\tlearn: 46.9349558\ttotal: 5.86s\tremaining: 5.63s\n",
      "510:\tlearn: 46.9232317\ttotal: 5.87s\tremaining: 5.62s\n",
      "511:\tlearn: 46.9175044\ttotal: 5.88s\tremaining: 5.61s\n",
      "512:\tlearn: 46.9113912\ttotal: 5.89s\tremaining: 5.59s\n",
      "513:\tlearn: 46.9093011\ttotal: 5.91s\tremaining: 5.58s\n",
      "514:\tlearn: 46.9054392\ttotal: 5.92s\tremaining: 5.57s\n",
      "515:\tlearn: 46.8972467\ttotal: 5.93s\tremaining: 5.56s\n",
      "516:\tlearn: 46.8918225\ttotal: 5.94s\tremaining: 5.55s\n",
      "517:\tlearn: 46.8879490\ttotal: 5.95s\tremaining: 5.54s\n",
      "518:\tlearn: 46.8810804\ttotal: 5.97s\tremaining: 5.53s\n",
      "519:\tlearn: 46.8692242\ttotal: 5.98s\tremaining: 5.52s\n",
      "520:\tlearn: 46.8634168\ttotal: 5.99s\tremaining: 5.51s\n",
      "521:\tlearn: 46.8548372\ttotal: 6s\tremaining: 5.5s\n",
      "522:\tlearn: 46.8503187\ttotal: 6.01s\tremaining: 5.49s\n",
      "523:\tlearn: 46.8445069\ttotal: 6.03s\tremaining: 5.47s\n",
      "524:\tlearn: 46.8402128\ttotal: 6.04s\tremaining: 5.46s\n",
      "525:\tlearn: 46.8325726\ttotal: 6.05s\tremaining: 5.45s\n",
      "526:\tlearn: 46.8244215\ttotal: 6.06s\tremaining: 5.44s\n",
      "527:\tlearn: 46.8205117\ttotal: 6.08s\tremaining: 5.43s\n",
      "528:\tlearn: 46.8150356\ttotal: 6.09s\tremaining: 5.42s\n",
      "529:\tlearn: 46.8132722\ttotal: 6.1s\tremaining: 5.41s\n",
      "530:\tlearn: 46.8080045\ttotal: 6.11s\tremaining: 5.4s\n",
      "531:\tlearn: 46.8008122\ttotal: 6.12s\tremaining: 5.39s\n",
      "532:\tlearn: 46.7984588\ttotal: 6.14s\tremaining: 5.38s\n",
      "533:\tlearn: 46.7946613\ttotal: 6.15s\tremaining: 5.37s\n",
      "534:\tlearn: 46.7874306\ttotal: 6.16s\tremaining: 5.36s\n",
      "535:\tlearn: 46.7800080\ttotal: 6.17s\tremaining: 5.34s\n",
      "536:\tlearn: 46.7762877\ttotal: 6.18s\tremaining: 5.33s\n",
      "537:\tlearn: 46.7724018\ttotal: 6.2s\tremaining: 5.32s\n",
      "538:\tlearn: 46.7688541\ttotal: 6.21s\tremaining: 5.31s\n",
      "539:\tlearn: 46.7664048\ttotal: 6.22s\tremaining: 5.3s\n",
      "540:\tlearn: 46.7602924\ttotal: 6.24s\tremaining: 5.29s\n",
      "541:\tlearn: 46.7558885\ttotal: 6.25s\tremaining: 5.28s\n",
      "542:\tlearn: 46.7521693\ttotal: 6.26s\tremaining: 5.27s\n",
      "543:\tlearn: 46.7461900\ttotal: 6.28s\tremaining: 5.26s\n",
      "544:\tlearn: 46.7421024\ttotal: 6.29s\tremaining: 5.25s\n",
      "545:\tlearn: 46.7354478\ttotal: 6.31s\tremaining: 5.25s\n",
      "546:\tlearn: 46.7310544\ttotal: 6.32s\tremaining: 5.24s\n",
      "547:\tlearn: 46.7251963\ttotal: 6.34s\tremaining: 5.23s\n",
      "548:\tlearn: 46.7184856\ttotal: 6.35s\tremaining: 5.22s\n",
      "549:\tlearn: 46.7142833\ttotal: 6.36s\tremaining: 5.21s\n",
      "550:\tlearn: 46.7065848\ttotal: 6.38s\tremaining: 5.2s\n",
      "551:\tlearn: 46.6966087\ttotal: 6.39s\tremaining: 5.18s\n",
      "552:\tlearn: 46.6920402\ttotal: 6.4s\tremaining: 5.17s\n",
      "553:\tlearn: 46.6855620\ttotal: 6.41s\tremaining: 5.16s\n",
      "554:\tlearn: 46.6780743\ttotal: 6.42s\tremaining: 5.15s\n",
      "555:\tlearn: 46.6745301\ttotal: 6.44s\tremaining: 5.14s\n",
      "556:\tlearn: 46.6706908\ttotal: 6.45s\tremaining: 5.13s\n",
      "557:\tlearn: 46.6678170\ttotal: 6.46s\tremaining: 5.12s\n",
      "558:\tlearn: 46.6571099\ttotal: 6.47s\tremaining: 5.11s\n",
      "559:\tlearn: 46.6507526\ttotal: 6.48s\tremaining: 5.09s\n",
      "560:\tlearn: 46.6457589\ttotal: 6.5s\tremaining: 5.08s\n",
      "561:\tlearn: 46.6355661\ttotal: 6.51s\tremaining: 5.07s\n",
      "562:\tlearn: 46.6305850\ttotal: 6.52s\tremaining: 5.06s\n",
      "563:\tlearn: 46.6232526\ttotal: 6.53s\tremaining: 5.05s\n",
      "564:\tlearn: 46.6213700\ttotal: 6.54s\tremaining: 5.04s\n",
      "565:\tlearn: 46.6166012\ttotal: 6.55s\tremaining: 5.02s\n",
      "566:\tlearn: 46.6141194\ttotal: 6.56s\tremaining: 5.01s\n",
      "567:\tlearn: 46.6096522\ttotal: 6.58s\tremaining: 5s\n",
      "568:\tlearn: 46.6043454\ttotal: 6.59s\tremaining: 4.99s\n",
      "569:\tlearn: 46.6004523\ttotal: 6.6s\tremaining: 4.98s\n",
      "570:\tlearn: 46.5909043\ttotal: 6.61s\tremaining: 4.97s\n",
      "571:\tlearn: 46.5839273\ttotal: 6.62s\tremaining: 4.96s\n",
      "572:\tlearn: 46.5779346\ttotal: 6.63s\tremaining: 4.94s\n",
      "573:\tlearn: 46.5732756\ttotal: 6.65s\tremaining: 4.93s\n",
      "574:\tlearn: 46.5690023\ttotal: 6.66s\tremaining: 4.92s\n",
      "575:\tlearn: 46.5637343\ttotal: 6.67s\tremaining: 4.91s\n",
      "576:\tlearn: 46.5587069\ttotal: 6.68s\tremaining: 4.9s\n",
      "577:\tlearn: 46.5518215\ttotal: 6.69s\tremaining: 4.89s\n",
      "578:\tlearn: 46.5474116\ttotal: 6.71s\tremaining: 4.88s\n",
      "579:\tlearn: 46.5423915\ttotal: 6.72s\tremaining: 4.87s\n",
      "580:\tlearn: 46.5387440\ttotal: 6.73s\tremaining: 4.85s\n",
      "581:\tlearn: 46.5335695\ttotal: 6.74s\tremaining: 4.84s\n",
      "582:\tlearn: 46.5327716\ttotal: 6.75s\tremaining: 4.83s\n",
      "583:\tlearn: 46.5234003\ttotal: 6.76s\tremaining: 4.81s\n",
      "584:\tlearn: 46.5193235\ttotal: 6.76s\tremaining: 4.8s\n",
      "585:\tlearn: 46.5138560\ttotal: 6.78s\tremaining: 4.79s\n",
      "586:\tlearn: 46.5124870\ttotal: 6.78s\tremaining: 4.77s\n",
      "587:\tlearn: 46.5074953\ttotal: 6.79s\tremaining: 4.76s\n",
      "588:\tlearn: 46.5036938\ttotal: 6.8s\tremaining: 4.75s\n",
      "589:\tlearn: 46.4974096\ttotal: 6.81s\tremaining: 4.73s\n",
      "590:\tlearn: 46.4896185\ttotal: 6.82s\tremaining: 4.72s\n",
      "591:\tlearn: 46.4844438\ttotal: 6.83s\tremaining: 4.71s\n",
      "592:\tlearn: 46.4836837\ttotal: 6.84s\tremaining: 4.69s\n",
      "593:\tlearn: 46.4767196\ttotal: 6.85s\tremaining: 4.68s\n",
      "594:\tlearn: 46.4723921\ttotal: 6.86s\tremaining: 4.67s\n",
      "595:\tlearn: 46.4688408\ttotal: 6.87s\tremaining: 4.66s\n",
      "596:\tlearn: 46.4583937\ttotal: 6.88s\tremaining: 4.65s\n",
      "597:\tlearn: 46.4536842\ttotal: 6.89s\tremaining: 4.63s\n",
      "598:\tlearn: 46.4523784\ttotal: 6.9s\tremaining: 4.62s\n",
      "599:\tlearn: 46.4490618\ttotal: 6.91s\tremaining: 4.61s\n",
      "600:\tlearn: 46.4478118\ttotal: 6.92s\tremaining: 4.59s\n",
      "601:\tlearn: 46.4312537\ttotal: 6.93s\tremaining: 4.58s\n",
      "602:\tlearn: 46.4173140\ttotal: 6.94s\tremaining: 4.57s\n",
      "603:\tlearn: 46.4119472\ttotal: 6.95s\tremaining: 4.56s\n",
      "604:\tlearn: 46.4047708\ttotal: 6.96s\tremaining: 4.54s\n",
      "605:\tlearn: 46.3989316\ttotal: 6.97s\tremaining: 4.53s\n",
      "606:\tlearn: 46.3957185\ttotal: 6.98s\tremaining: 4.52s\n",
      "607:\tlearn: 46.3925434\ttotal: 6.99s\tremaining: 4.51s\n",
      "608:\tlearn: 46.3884339\ttotal: 7s\tremaining: 4.5s\n",
      "609:\tlearn: 46.3853868\ttotal: 7.03s\tremaining: 4.49s\n",
      "610:\tlearn: 46.3820062\ttotal: 7.04s\tremaining: 4.48s\n",
      "611:\tlearn: 46.3676599\ttotal: 7.05s\tremaining: 4.47s\n",
      "612:\tlearn: 46.3658030\ttotal: 7.06s\tremaining: 4.46s\n",
      "613:\tlearn: 46.3632582\ttotal: 7.07s\tremaining: 4.44s\n",
      "614:\tlearn: 46.3575468\ttotal: 7.08s\tremaining: 4.43s\n",
      "615:\tlearn: 46.3529691\ttotal: 7.09s\tremaining: 4.42s\n",
      "616:\tlearn: 46.3480496\ttotal: 7.1s\tremaining: 4.41s\n",
      "617:\tlearn: 46.3417092\ttotal: 7.11s\tremaining: 4.39s\n",
      "618:\tlearn: 46.3349158\ttotal: 7.12s\tremaining: 4.38s\n",
      "619:\tlearn: 46.3279696\ttotal: 7.13s\tremaining: 4.37s\n",
      "620:\tlearn: 46.3247738\ttotal: 7.14s\tremaining: 4.36s\n",
      "621:\tlearn: 46.3157909\ttotal: 7.15s\tremaining: 4.34s\n",
      "622:\tlearn: 46.3000808\ttotal: 7.16s\tremaining: 4.33s\n",
      "623:\tlearn: 46.2907195\ttotal: 7.17s\tremaining: 4.32s\n",
      "624:\tlearn: 46.2750045\ttotal: 7.18s\tremaining: 4.31s\n",
      "625:\tlearn: 46.2704594\ttotal: 7.19s\tremaining: 4.3s\n",
      "626:\tlearn: 46.2603468\ttotal: 7.2s\tremaining: 4.28s\n",
      "627:\tlearn: 46.2551641\ttotal: 7.21s\tremaining: 4.27s\n",
      "628:\tlearn: 46.2519056\ttotal: 7.22s\tremaining: 4.26s\n",
      "629:\tlearn: 46.2486407\ttotal: 7.23s\tremaining: 4.25s\n",
      "630:\tlearn: 46.2442884\ttotal: 7.24s\tremaining: 4.23s\n",
      "631:\tlearn: 46.2361652\ttotal: 7.25s\tremaining: 4.22s\n",
      "632:\tlearn: 46.2313558\ttotal: 7.26s\tremaining: 4.21s\n",
      "633:\tlearn: 46.2237964\ttotal: 7.27s\tremaining: 4.2s\n",
      "634:\tlearn: 46.2225487\ttotal: 7.28s\tremaining: 4.18s\n",
      "635:\tlearn: 46.2192392\ttotal: 7.29s\tremaining: 4.17s\n",
      "636:\tlearn: 46.2080775\ttotal: 7.3s\tremaining: 4.16s\n",
      "637:\tlearn: 46.1957905\ttotal: 7.31s\tremaining: 4.15s\n",
      "638:\tlearn: 46.1898784\ttotal: 7.32s\tremaining: 4.14s\n",
      "639:\tlearn: 46.1786097\ttotal: 7.33s\tremaining: 4.13s\n",
      "640:\tlearn: 46.1736859\ttotal: 7.34s\tremaining: 4.11s\n",
      "641:\tlearn: 46.1633470\ttotal: 7.36s\tremaining: 4.1s\n",
      "642:\tlearn: 46.1600799\ttotal: 7.37s\tremaining: 4.09s\n",
      "643:\tlearn: 46.1506028\ttotal: 7.38s\tremaining: 4.08s\n",
      "644:\tlearn: 46.1418776\ttotal: 7.39s\tremaining: 4.07s\n",
      "645:\tlearn: 46.1396855\ttotal: 7.4s\tremaining: 4.05s\n",
      "646:\tlearn: 46.1336022\ttotal: 7.41s\tremaining: 4.04s\n",
      "647:\tlearn: 46.1287762\ttotal: 7.42s\tremaining: 4.03s\n",
      "648:\tlearn: 46.1250708\ttotal: 7.43s\tremaining: 4.02s\n",
      "649:\tlearn: 46.1172268\ttotal: 7.44s\tremaining: 4.01s\n",
      "650:\tlearn: 46.1106778\ttotal: 7.45s\tremaining: 4s\n",
      "651:\tlearn: 46.1065468\ttotal: 7.46s\tremaining: 3.98s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652:\tlearn: 46.1007695\ttotal: 7.47s\tremaining: 3.97s\n",
      "653:\tlearn: 46.0970003\ttotal: 7.49s\tremaining: 3.96s\n",
      "654:\tlearn: 46.0897892\ttotal: 7.5s\tremaining: 3.95s\n",
      "655:\tlearn: 46.0794456\ttotal: 7.51s\tremaining: 3.94s\n",
      "656:\tlearn: 46.0675906\ttotal: 7.52s\tremaining: 3.92s\n",
      "657:\tlearn: 46.0653960\ttotal: 7.53s\tremaining: 3.91s\n",
      "658:\tlearn: 46.0578564\ttotal: 7.54s\tremaining: 3.9s\n",
      "659:\tlearn: 46.0530245\ttotal: 7.55s\tremaining: 3.89s\n",
      "660:\tlearn: 46.0480225\ttotal: 7.56s\tremaining: 3.88s\n",
      "661:\tlearn: 46.0432957\ttotal: 7.57s\tremaining: 3.86s\n",
      "662:\tlearn: 46.0390562\ttotal: 7.58s\tremaining: 3.85s\n",
      "663:\tlearn: 46.0350113\ttotal: 7.59s\tremaining: 3.84s\n",
      "664:\tlearn: 46.0331275\ttotal: 7.6s\tremaining: 3.83s\n",
      "665:\tlearn: 46.0226840\ttotal: 7.61s\tremaining: 3.81s\n",
      "666:\tlearn: 46.0204522\ttotal: 7.62s\tremaining: 3.8s\n",
      "667:\tlearn: 46.0070857\ttotal: 7.63s\tremaining: 3.79s\n",
      "668:\tlearn: 46.0008698\ttotal: 7.64s\tremaining: 3.78s\n",
      "669:\tlearn: 45.9953082\ttotal: 7.65s\tremaining: 3.77s\n",
      "670:\tlearn: 45.9906451\ttotal: 7.66s\tremaining: 3.75s\n",
      "671:\tlearn: 45.9850661\ttotal: 7.67s\tremaining: 3.74s\n",
      "672:\tlearn: 45.9776355\ttotal: 7.68s\tremaining: 3.73s\n",
      "673:\tlearn: 45.9738875\ttotal: 7.69s\tremaining: 3.72s\n",
      "674:\tlearn: 45.9672501\ttotal: 7.7s\tremaining: 3.71s\n",
      "675:\tlearn: 45.9642851\ttotal: 7.71s\tremaining: 3.7s\n",
      "676:\tlearn: 45.9556925\ttotal: 7.72s\tremaining: 3.69s\n",
      "677:\tlearn: 45.9525787\ttotal: 7.74s\tremaining: 3.67s\n",
      "678:\tlearn: 45.9490599\ttotal: 7.75s\tremaining: 3.66s\n",
      "679:\tlearn: 45.9446294\ttotal: 7.76s\tremaining: 3.65s\n",
      "680:\tlearn: 45.9420213\ttotal: 7.77s\tremaining: 3.64s\n",
      "681:\tlearn: 45.9373020\ttotal: 7.78s\tremaining: 3.63s\n",
      "682:\tlearn: 45.9337089\ttotal: 7.79s\tremaining: 3.61s\n",
      "683:\tlearn: 45.9299162\ttotal: 7.8s\tremaining: 3.6s\n",
      "684:\tlearn: 45.9256940\ttotal: 7.81s\tremaining: 3.59s\n",
      "685:\tlearn: 45.9216671\ttotal: 7.82s\tremaining: 3.58s\n",
      "686:\tlearn: 45.9159957\ttotal: 7.83s\tremaining: 3.57s\n",
      "687:\tlearn: 45.9124634\ttotal: 7.84s\tremaining: 3.56s\n",
      "688:\tlearn: 45.9076727\ttotal: 7.85s\tremaining: 3.54s\n",
      "689:\tlearn: 45.9064790\ttotal: 7.86s\tremaining: 3.53s\n",
      "690:\tlearn: 45.8960216\ttotal: 7.87s\tremaining: 3.52s\n",
      "691:\tlearn: 45.8900971\ttotal: 7.88s\tremaining: 3.51s\n",
      "692:\tlearn: 45.8786600\ttotal: 7.89s\tremaining: 3.5s\n",
      "693:\tlearn: 45.8765441\ttotal: 7.91s\tremaining: 3.48s\n",
      "694:\tlearn: 45.8708403\ttotal: 7.92s\tremaining: 3.47s\n",
      "695:\tlearn: 45.8663304\ttotal: 7.93s\tremaining: 3.46s\n",
      "696:\tlearn: 45.8619751\ttotal: 7.94s\tremaining: 3.45s\n",
      "697:\tlearn: 45.8555102\ttotal: 7.95s\tremaining: 3.44s\n",
      "698:\tlearn: 45.8513553\ttotal: 7.96s\tremaining: 3.43s\n",
      "699:\tlearn: 45.8467497\ttotal: 7.97s\tremaining: 3.42s\n",
      "700:\tlearn: 45.8439452\ttotal: 7.99s\tremaining: 3.4s\n",
      "701:\tlearn: 45.8407781\ttotal: 8s\tremaining: 3.39s\n",
      "702:\tlearn: 45.8354300\ttotal: 8.01s\tremaining: 3.38s\n",
      "703:\tlearn: 45.8315879\ttotal: 8.02s\tremaining: 3.37s\n",
      "704:\tlearn: 45.8284099\ttotal: 8.03s\tremaining: 3.36s\n",
      "705:\tlearn: 45.8194083\ttotal: 8.04s\tremaining: 3.35s\n",
      "706:\tlearn: 45.8052663\ttotal: 8.05s\tremaining: 3.34s\n",
      "707:\tlearn: 45.7996950\ttotal: 8.06s\tremaining: 3.33s\n",
      "708:\tlearn: 45.7969606\ttotal: 8.07s\tremaining: 3.31s\n",
      "709:\tlearn: 45.7913173\ttotal: 8.09s\tremaining: 3.3s\n",
      "710:\tlearn: 45.7843710\ttotal: 8.1s\tremaining: 3.29s\n",
      "711:\tlearn: 45.7816797\ttotal: 8.11s\tremaining: 3.28s\n",
      "712:\tlearn: 45.7805389\ttotal: 8.12s\tremaining: 3.27s\n",
      "713:\tlearn: 45.7730989\ttotal: 8.13s\tremaining: 3.25s\n",
      "714:\tlearn: 45.7668672\ttotal: 8.14s\tremaining: 3.24s\n",
      "715:\tlearn: 45.7610220\ttotal: 8.15s\tremaining: 3.23s\n",
      "716:\tlearn: 45.7545545\ttotal: 8.16s\tremaining: 3.22s\n",
      "717:\tlearn: 45.7504422\ttotal: 8.17s\tremaining: 3.21s\n",
      "718:\tlearn: 45.7463613\ttotal: 8.18s\tremaining: 3.2s\n",
      "719:\tlearn: 45.7390985\ttotal: 8.19s\tremaining: 3.19s\n",
      "720:\tlearn: 45.7239800\ttotal: 8.2s\tremaining: 3.17s\n",
      "721:\tlearn: 45.7224677\ttotal: 8.21s\tremaining: 3.16s\n",
      "722:\tlearn: 45.7179545\ttotal: 8.22s\tremaining: 3.15s\n",
      "723:\tlearn: 45.7091741\ttotal: 8.23s\tremaining: 3.14s\n",
      "724:\tlearn: 45.7037591\ttotal: 8.24s\tremaining: 3.13s\n",
      "725:\tlearn: 45.6945285\ttotal: 8.26s\tremaining: 3.12s\n",
      "726:\tlearn: 45.6912722\ttotal: 8.27s\tremaining: 3.1s\n",
      "727:\tlearn: 45.6807160\ttotal: 8.28s\tremaining: 3.09s\n",
      "728:\tlearn: 45.6674429\ttotal: 8.29s\tremaining: 3.08s\n",
      "729:\tlearn: 45.6637705\ttotal: 8.3s\tremaining: 3.07s\n",
      "730:\tlearn: 45.6609810\ttotal: 8.31s\tremaining: 3.06s\n",
      "731:\tlearn: 45.6552920\ttotal: 8.32s\tremaining: 3.05s\n",
      "732:\tlearn: 45.6499055\ttotal: 8.34s\tremaining: 3.04s\n",
      "733:\tlearn: 45.6435347\ttotal: 8.35s\tremaining: 3.02s\n",
      "734:\tlearn: 45.6405976\ttotal: 8.36s\tremaining: 3.01s\n",
      "735:\tlearn: 45.6356715\ttotal: 8.37s\tremaining: 3s\n",
      "736:\tlearn: 45.6328456\ttotal: 8.38s\tremaining: 2.99s\n",
      "737:\tlearn: 45.6280447\ttotal: 8.39s\tremaining: 2.98s\n",
      "738:\tlearn: 45.6263004\ttotal: 8.4s\tremaining: 2.97s\n",
      "739:\tlearn: 45.6236425\ttotal: 8.41s\tremaining: 2.96s\n",
      "740:\tlearn: 45.6189359\ttotal: 8.42s\tremaining: 2.94s\n",
      "741:\tlearn: 45.6092252\ttotal: 8.43s\tremaining: 2.93s\n",
      "742:\tlearn: 45.6051234\ttotal: 8.44s\tremaining: 2.92s\n",
      "743:\tlearn: 45.6004941\ttotal: 8.45s\tremaining: 2.91s\n",
      "744:\tlearn: 45.5942762\ttotal: 8.46s\tremaining: 2.9s\n",
      "745:\tlearn: 45.5864923\ttotal: 8.47s\tremaining: 2.88s\n",
      "746:\tlearn: 45.5840664\ttotal: 8.48s\tremaining: 2.87s\n",
      "747:\tlearn: 45.5814975\ttotal: 8.5s\tremaining: 2.86s\n",
      "748:\tlearn: 45.5774531\ttotal: 8.51s\tremaining: 2.85s\n",
      "749:\tlearn: 45.5750143\ttotal: 8.52s\tremaining: 2.84s\n",
      "750:\tlearn: 45.5723337\ttotal: 8.53s\tremaining: 2.83s\n",
      "751:\tlearn: 45.5700259\ttotal: 8.54s\tremaining: 2.82s\n",
      "752:\tlearn: 45.5617219\ttotal: 8.55s\tremaining: 2.81s\n",
      "753:\tlearn: 45.5563097\ttotal: 8.56s\tremaining: 2.79s\n",
      "754:\tlearn: 45.5539924\ttotal: 8.58s\tremaining: 2.78s\n",
      "755:\tlearn: 45.5517904\ttotal: 8.59s\tremaining: 2.77s\n",
      "756:\tlearn: 45.5485245\ttotal: 8.6s\tremaining: 2.76s\n",
      "757:\tlearn: 45.5459523\ttotal: 8.61s\tremaining: 2.75s\n",
      "758:\tlearn: 45.5450248\ttotal: 8.63s\tremaining: 2.74s\n",
      "759:\tlearn: 45.5387275\ttotal: 8.64s\tremaining: 2.73s\n",
      "760:\tlearn: 45.5356476\ttotal: 8.65s\tremaining: 2.72s\n",
      "761:\tlearn: 45.5328106\ttotal: 8.66s\tremaining: 2.71s\n",
      "762:\tlearn: 45.5262506\ttotal: 8.68s\tremaining: 2.7s\n",
      "763:\tlearn: 45.5241566\ttotal: 8.69s\tremaining: 2.69s\n",
      "764:\tlearn: 45.5192664\ttotal: 8.71s\tremaining: 2.67s\n",
      "765:\tlearn: 45.5155126\ttotal: 8.72s\tremaining: 2.66s\n",
      "766:\tlearn: 45.5111566\ttotal: 8.73s\tremaining: 2.65s\n",
      "767:\tlearn: 45.5038844\ttotal: 8.74s\tremaining: 2.64s\n",
      "768:\tlearn: 45.4997490\ttotal: 8.75s\tremaining: 2.63s\n",
      "769:\tlearn: 45.4983685\ttotal: 8.76s\tremaining: 2.62s\n",
      "770:\tlearn: 45.4948572\ttotal: 8.77s\tremaining: 2.6s\n",
      "771:\tlearn: 45.4803464\ttotal: 8.78s\tremaining: 2.59s\n",
      "772:\tlearn: 45.4743297\ttotal: 8.79s\tremaining: 2.58s\n",
      "773:\tlearn: 45.4676640\ttotal: 8.8s\tremaining: 2.57s\n",
      "774:\tlearn: 45.4656693\ttotal: 8.81s\tremaining: 2.56s\n",
      "775:\tlearn: 45.4598978\ttotal: 8.82s\tremaining: 2.55s\n",
      "776:\tlearn: 45.4563831\ttotal: 8.83s\tremaining: 2.54s\n",
      "777:\tlearn: 45.4544846\ttotal: 8.85s\tremaining: 2.52s\n",
      "778:\tlearn: 45.4470869\ttotal: 8.86s\tremaining: 2.51s\n",
      "779:\tlearn: 45.4419992\ttotal: 8.87s\tremaining: 2.5s\n",
      "780:\tlearn: 45.4378939\ttotal: 8.88s\tremaining: 2.49s\n",
      "781:\tlearn: 45.4329505\ttotal: 8.89s\tremaining: 2.48s\n",
      "782:\tlearn: 45.4300497\ttotal: 8.9s\tremaining: 2.47s\n",
      "783:\tlearn: 45.4259887\ttotal: 8.91s\tremaining: 2.46s\n",
      "784:\tlearn: 45.4234140\ttotal: 8.92s\tremaining: 2.44s\n",
      "785:\tlearn: 45.4178740\ttotal: 8.94s\tremaining: 2.43s\n",
      "786:\tlearn: 45.4133944\ttotal: 8.95s\tremaining: 2.42s\n",
      "787:\tlearn: 45.3999186\ttotal: 8.96s\tremaining: 2.41s\n",
      "788:\tlearn: 45.3965620\ttotal: 8.97s\tremaining: 2.4s\n",
      "789:\tlearn: 45.3858328\ttotal: 8.98s\tremaining: 2.39s\n",
      "790:\tlearn: 45.3806190\ttotal: 9s\tremaining: 2.38s\n",
      "791:\tlearn: 45.3788027\ttotal: 9.01s\tremaining: 2.37s\n",
      "792:\tlearn: 45.3729337\ttotal: 9.02s\tremaining: 2.35s\n",
      "793:\tlearn: 45.3686471\ttotal: 9.03s\tremaining: 2.34s\n",
      "794:\tlearn: 45.3639116\ttotal: 9.04s\tremaining: 2.33s\n",
      "795:\tlearn: 45.3602668\ttotal: 9.05s\tremaining: 2.32s\n",
      "796:\tlearn: 45.3556504\ttotal: 9.06s\tremaining: 2.31s\n",
      "797:\tlearn: 45.3517892\ttotal: 9.07s\tremaining: 2.3s\n",
      "798:\tlearn: 45.3427924\ttotal: 9.09s\tremaining: 2.29s\n",
      "799:\tlearn: 45.3381218\ttotal: 9.1s\tremaining: 2.27s\n",
      "800:\tlearn: 45.3302283\ttotal: 9.11s\tremaining: 2.26s\n",
      "801:\tlearn: 45.3261960\ttotal: 9.12s\tremaining: 2.25s\n",
      "802:\tlearn: 45.3201637\ttotal: 9.13s\tremaining: 2.24s\n",
      "803:\tlearn: 45.3178282\ttotal: 9.14s\tremaining: 2.23s\n",
      "804:\tlearn: 45.3147969\ttotal: 9.15s\tremaining: 2.22s\n",
      "805:\tlearn: 45.3017085\ttotal: 9.16s\tremaining: 2.21s\n",
      "806:\tlearn: 45.2973201\ttotal: 9.17s\tremaining: 2.19s\n",
      "807:\tlearn: 45.2848755\ttotal: 9.19s\tremaining: 2.18s\n",
      "808:\tlearn: 45.2803801\ttotal: 9.2s\tremaining: 2.17s\n",
      "809:\tlearn: 45.2746381\ttotal: 9.21s\tremaining: 2.16s\n",
      "810:\tlearn: 45.2701044\ttotal: 9.22s\tremaining: 2.15s\n",
      "811:\tlearn: 45.2647806\ttotal: 9.23s\tremaining: 2.14s\n",
      "812:\tlearn: 45.2599470\ttotal: 9.24s\tremaining: 2.13s\n",
      "813:\tlearn: 45.2549212\ttotal: 9.25s\tremaining: 2.11s\n",
      "814:\tlearn: 45.2490329\ttotal: 9.26s\tremaining: 2.1s\n",
      "815:\tlearn: 45.2456545\ttotal: 9.28s\tremaining: 2.09s\n",
      "816:\tlearn: 45.2407717\ttotal: 9.29s\tremaining: 2.08s\n",
      "817:\tlearn: 45.2386019\ttotal: 9.3s\tremaining: 2.07s\n",
      "818:\tlearn: 45.2340888\ttotal: 9.31s\tremaining: 2.06s\n",
      "819:\tlearn: 45.2293836\ttotal: 9.32s\tremaining: 2.05s\n",
      "820:\tlearn: 45.2271832\ttotal: 9.33s\tremaining: 2.03s\n",
      "821:\tlearn: 45.2254554\ttotal: 9.35s\tremaining: 2.02s\n",
      "822:\tlearn: 45.2222503\ttotal: 9.36s\tremaining: 2.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823:\tlearn: 45.2087044\ttotal: 9.37s\tremaining: 2s\n",
      "824:\tlearn: 45.2001435\ttotal: 9.38s\tremaining: 1.99s\n",
      "825:\tlearn: 45.1966516\ttotal: 9.39s\tremaining: 1.98s\n",
      "826:\tlearn: 45.1910689\ttotal: 9.4s\tremaining: 1.97s\n",
      "827:\tlearn: 45.1841242\ttotal: 9.42s\tremaining: 1.96s\n",
      "828:\tlearn: 45.1788206\ttotal: 9.43s\tremaining: 1.94s\n",
      "829:\tlearn: 45.1726010\ttotal: 9.44s\tremaining: 1.93s\n",
      "830:\tlearn: 45.1675460\ttotal: 9.45s\tremaining: 1.92s\n",
      "831:\tlearn: 45.1610206\ttotal: 9.46s\tremaining: 1.91s\n",
      "832:\tlearn: 45.1562737\ttotal: 9.48s\tremaining: 1.9s\n",
      "833:\tlearn: 45.1517672\ttotal: 9.49s\tremaining: 1.89s\n",
      "834:\tlearn: 45.1475947\ttotal: 9.5s\tremaining: 1.88s\n",
      "835:\tlearn: 45.1430729\ttotal: 9.51s\tremaining: 1.86s\n",
      "836:\tlearn: 45.1374384\ttotal: 9.52s\tremaining: 1.85s\n",
      "837:\tlearn: 45.1347683\ttotal: 9.54s\tremaining: 1.84s\n",
      "838:\tlearn: 45.1277616\ttotal: 9.55s\tremaining: 1.83s\n",
      "839:\tlearn: 45.1215364\ttotal: 9.56s\tremaining: 1.82s\n",
      "840:\tlearn: 45.1195265\ttotal: 9.57s\tremaining: 1.81s\n",
      "841:\tlearn: 45.1150375\ttotal: 9.58s\tremaining: 1.8s\n",
      "842:\tlearn: 45.1092864\ttotal: 9.6s\tremaining: 1.79s\n",
      "843:\tlearn: 45.1032861\ttotal: 9.61s\tremaining: 1.78s\n",
      "844:\tlearn: 45.0946774\ttotal: 9.62s\tremaining: 1.76s\n",
      "845:\tlearn: 45.0927609\ttotal: 9.64s\tremaining: 1.75s\n",
      "846:\tlearn: 45.0867546\ttotal: 9.65s\tremaining: 1.74s\n",
      "847:\tlearn: 45.0832190\ttotal: 9.66s\tremaining: 1.73s\n",
      "848:\tlearn: 45.0774882\ttotal: 9.67s\tremaining: 1.72s\n",
      "849:\tlearn: 45.0544965\ttotal: 9.68s\tremaining: 1.71s\n",
      "850:\tlearn: 45.0471958\ttotal: 9.69s\tremaining: 1.7s\n",
      "851:\tlearn: 45.0415246\ttotal: 9.71s\tremaining: 1.69s\n",
      "852:\tlearn: 45.0381029\ttotal: 9.72s\tremaining: 1.67s\n",
      "853:\tlearn: 45.0320192\ttotal: 9.73s\tremaining: 1.66s\n",
      "854:\tlearn: 45.0303663\ttotal: 9.74s\tremaining: 1.65s\n",
      "855:\tlearn: 45.0238351\ttotal: 9.75s\tremaining: 1.64s\n",
      "856:\tlearn: 45.0225774\ttotal: 9.76s\tremaining: 1.63s\n",
      "857:\tlearn: 45.0124798\ttotal: 9.78s\tremaining: 1.62s\n",
      "858:\tlearn: 45.0098153\ttotal: 9.79s\tremaining: 1.61s\n",
      "859:\tlearn: 45.0082414\ttotal: 9.8s\tremaining: 1.59s\n",
      "860:\tlearn: 45.0015162\ttotal: 9.81s\tremaining: 1.58s\n",
      "861:\tlearn: 45.0004125\ttotal: 9.82s\tremaining: 1.57s\n",
      "862:\tlearn: 44.9963889\ttotal: 9.84s\tremaining: 1.56s\n",
      "863:\tlearn: 44.9857323\ttotal: 9.85s\tremaining: 1.55s\n",
      "864:\tlearn: 44.9785157\ttotal: 9.86s\tremaining: 1.54s\n",
      "865:\tlearn: 44.9750671\ttotal: 9.87s\tremaining: 1.53s\n",
      "866:\tlearn: 44.9677246\ttotal: 9.88s\tremaining: 1.52s\n",
      "867:\tlearn: 44.9598654\ttotal: 9.9s\tremaining: 1.5s\n",
      "868:\tlearn: 44.9586693\ttotal: 9.91s\tremaining: 1.49s\n",
      "869:\tlearn: 44.9543312\ttotal: 9.92s\tremaining: 1.48s\n",
      "870:\tlearn: 44.9528309\ttotal: 9.94s\tremaining: 1.47s\n",
      "871:\tlearn: 44.9514026\ttotal: 9.95s\tremaining: 1.46s\n",
      "872:\tlearn: 44.9491625\ttotal: 9.96s\tremaining: 1.45s\n",
      "873:\tlearn: 44.9436396\ttotal: 9.97s\tremaining: 1.44s\n",
      "874:\tlearn: 44.9365325\ttotal: 9.98s\tremaining: 1.43s\n",
      "875:\tlearn: 44.9310083\ttotal: 10s\tremaining: 1.42s\n",
      "876:\tlearn: 44.9259222\ttotal: 10s\tremaining: 1.4s\n",
      "877:\tlearn: 44.9239448\ttotal: 10s\tremaining: 1.39s\n",
      "878:\tlearn: 44.9181355\ttotal: 10s\tremaining: 1.38s\n",
      "879:\tlearn: 44.9127297\ttotal: 10s\tremaining: 1.37s\n",
      "880:\tlearn: 44.9070865\ttotal: 10.1s\tremaining: 1.36s\n",
      "881:\tlearn: 44.9034626\ttotal: 10.1s\tremaining: 1.35s\n",
      "882:\tlearn: 44.8904489\ttotal: 10.1s\tremaining: 1.33s\n",
      "883:\tlearn: 44.8854133\ttotal: 10.1s\tremaining: 1.32s\n",
      "884:\tlearn: 44.8648001\ttotal: 10.1s\tremaining: 1.31s\n",
      "885:\tlearn: 44.8637463\ttotal: 10.1s\tremaining: 1.3s\n",
      "886:\tlearn: 44.8586949\ttotal: 10.1s\tremaining: 1.29s\n",
      "887:\tlearn: 44.8527021\ttotal: 10.1s\tremaining: 1.28s\n",
      "888:\tlearn: 44.8461695\ttotal: 10.1s\tremaining: 1.27s\n",
      "889:\tlearn: 44.8391784\ttotal: 10.2s\tremaining: 1.25s\n",
      "890:\tlearn: 44.8350421\ttotal: 10.2s\tremaining: 1.24s\n",
      "891:\tlearn: 44.8301241\ttotal: 10.2s\tremaining: 1.23s\n",
      "892:\tlearn: 44.8266243\ttotal: 10.2s\tremaining: 1.22s\n",
      "893:\tlearn: 44.8219914\ttotal: 10.2s\tremaining: 1.21s\n",
      "894:\tlearn: 44.8109655\ttotal: 10.2s\tremaining: 1.2s\n",
      "895:\tlearn: 44.8057677\ttotal: 10.2s\tremaining: 1.19s\n",
      "896:\tlearn: 44.8044030\ttotal: 10.2s\tremaining: 1.18s\n",
      "897:\tlearn: 44.8002616\ttotal: 10.2s\tremaining: 1.16s\n",
      "898:\tlearn: 44.7980132\ttotal: 10.3s\tremaining: 1.15s\n",
      "899:\tlearn: 44.7961783\ttotal: 10.3s\tremaining: 1.14s\n",
      "900:\tlearn: 44.7915643\ttotal: 10.3s\tremaining: 1.13s\n",
      "901:\tlearn: 44.7869357\ttotal: 10.3s\tremaining: 1.12s\n",
      "902:\tlearn: 44.7787663\ttotal: 10.3s\tremaining: 1.11s\n",
      "903:\tlearn: 44.7721941\ttotal: 10.3s\tremaining: 1.09s\n",
      "904:\tlearn: 44.7680580\ttotal: 10.3s\tremaining: 1.08s\n",
      "905:\tlearn: 44.7611751\ttotal: 10.3s\tremaining: 1.07s\n",
      "906:\tlearn: 44.7519184\ttotal: 10.3s\tremaining: 1.06s\n",
      "907:\tlearn: 44.7468109\ttotal: 10.4s\tremaining: 1.05s\n",
      "908:\tlearn: 44.7406171\ttotal: 10.4s\tremaining: 1.04s\n",
      "909:\tlearn: 44.7377492\ttotal: 10.4s\tremaining: 1.03s\n",
      "910:\tlearn: 44.7345408\ttotal: 10.4s\tremaining: 1.01s\n",
      "911:\tlearn: 44.7278685\ttotal: 10.4s\tremaining: 1s\n",
      "912:\tlearn: 44.7257783\ttotal: 10.4s\tremaining: 993ms\n",
      "913:\tlearn: 44.7217260\ttotal: 10.4s\tremaining: 981ms\n",
      "914:\tlearn: 44.7121212\ttotal: 10.4s\tremaining: 970ms\n",
      "915:\tlearn: 44.7085511\ttotal: 10.4s\tremaining: 958ms\n",
      "916:\tlearn: 44.7056854\ttotal: 10.5s\tremaining: 947ms\n",
      "917:\tlearn: 44.7039183\ttotal: 10.5s\tremaining: 935ms\n",
      "918:\tlearn: 44.7026147\ttotal: 10.5s\tremaining: 924ms\n",
      "919:\tlearn: 44.6937941\ttotal: 10.5s\tremaining: 912ms\n",
      "920:\tlearn: 44.6918573\ttotal: 10.5s\tremaining: 901ms\n",
      "921:\tlearn: 44.6871718\ttotal: 10.5s\tremaining: 889ms\n",
      "922:\tlearn: 44.6796823\ttotal: 10.5s\tremaining: 878ms\n",
      "923:\tlearn: 44.6787230\ttotal: 10.5s\tremaining: 866ms\n",
      "924:\tlearn: 44.6717932\ttotal: 10.5s\tremaining: 855ms\n",
      "925:\tlearn: 44.6681115\ttotal: 10.6s\tremaining: 844ms\n",
      "926:\tlearn: 44.6639661\ttotal: 10.6s\tremaining: 832ms\n",
      "927:\tlearn: 44.6597757\ttotal: 10.6s\tremaining: 820ms\n",
      "928:\tlearn: 44.6518248\ttotal: 10.6s\tremaining: 809ms\n",
      "929:\tlearn: 44.6481818\ttotal: 10.6s\tremaining: 797ms\n",
      "930:\tlearn: 44.6382712\ttotal: 10.6s\tremaining: 786ms\n",
      "931:\tlearn: 44.6316130\ttotal: 10.6s\tremaining: 775ms\n",
      "932:\tlearn: 44.6207263\ttotal: 10.6s\tremaining: 763ms\n",
      "933:\tlearn: 44.6162840\ttotal: 10.6s\tremaining: 752ms\n",
      "934:\tlearn: 44.6144285\ttotal: 10.7s\tremaining: 740ms\n",
      "935:\tlearn: 44.6104283\ttotal: 10.7s\tremaining: 729ms\n",
      "936:\tlearn: 44.6086607\ttotal: 10.7s\tremaining: 718ms\n",
      "937:\tlearn: 44.6044010\ttotal: 10.7s\tremaining: 706ms\n",
      "938:\tlearn: 44.6004443\ttotal: 10.7s\tremaining: 695ms\n",
      "939:\tlearn: 44.5961163\ttotal: 10.7s\tremaining: 683ms\n",
      "940:\tlearn: 44.5906142\ttotal: 10.7s\tremaining: 672ms\n",
      "941:\tlearn: 44.5867524\ttotal: 10.7s\tremaining: 660ms\n",
      "942:\tlearn: 44.5856088\ttotal: 10.7s\tremaining: 649ms\n",
      "943:\tlearn: 44.5839221\ttotal: 10.7s\tremaining: 637ms\n",
      "944:\tlearn: 44.5793275\ttotal: 10.8s\tremaining: 626ms\n",
      "945:\tlearn: 44.5643763\ttotal: 10.8s\tremaining: 615ms\n",
      "946:\tlearn: 44.5587784\ttotal: 10.8s\tremaining: 603ms\n",
      "947:\tlearn: 44.5540558\ttotal: 10.8s\tremaining: 592ms\n",
      "948:\tlearn: 44.5426190\ttotal: 10.8s\tremaining: 581ms\n",
      "949:\tlearn: 44.5388421\ttotal: 10.8s\tremaining: 569ms\n",
      "950:\tlearn: 44.5339166\ttotal: 10.8s\tremaining: 558ms\n",
      "951:\tlearn: 44.5291207\ttotal: 10.8s\tremaining: 546ms\n",
      "952:\tlearn: 44.5192911\ttotal: 10.8s\tremaining: 535ms\n",
      "953:\tlearn: 44.5127836\ttotal: 10.9s\tremaining: 524ms\n",
      "954:\tlearn: 44.5091159\ttotal: 10.9s\tremaining: 512ms\n",
      "955:\tlearn: 44.5061847\ttotal: 10.9s\tremaining: 501ms\n",
      "956:\tlearn: 44.5042897\ttotal: 10.9s\tremaining: 489ms\n",
      "957:\tlearn: 44.5004531\ttotal: 10.9s\tremaining: 478ms\n",
      "958:\tlearn: 44.4954221\ttotal: 10.9s\tremaining: 467ms\n",
      "959:\tlearn: 44.4919895\ttotal: 10.9s\tremaining: 455ms\n",
      "960:\tlearn: 44.4886678\ttotal: 10.9s\tremaining: 444ms\n",
      "961:\tlearn: 44.4826608\ttotal: 10.9s\tremaining: 432ms\n",
      "962:\tlearn: 44.4782740\ttotal: 11s\tremaining: 421ms\n",
      "963:\tlearn: 44.4752343\ttotal: 11s\tremaining: 410ms\n",
      "964:\tlearn: 44.4720655\ttotal: 11s\tremaining: 398ms\n",
      "965:\tlearn: 44.4616493\ttotal: 11s\tremaining: 387ms\n",
      "966:\tlearn: 44.4553793\ttotal: 11s\tremaining: 376ms\n",
      "967:\tlearn: 44.4519928\ttotal: 11s\tremaining: 364ms\n",
      "968:\tlearn: 44.4473330\ttotal: 11s\tremaining: 353ms\n",
      "969:\tlearn: 44.4431728\ttotal: 11s\tremaining: 341ms\n",
      "970:\tlearn: 44.4384546\ttotal: 11.1s\tremaining: 330ms\n",
      "971:\tlearn: 44.4352216\ttotal: 11.1s\tremaining: 319ms\n",
      "972:\tlearn: 44.4301747\ttotal: 11.1s\tremaining: 307ms\n",
      "973:\tlearn: 44.4282121\ttotal: 11.1s\tremaining: 296ms\n",
      "974:\tlearn: 44.4214491\ttotal: 11.1s\tremaining: 285ms\n",
      "975:\tlearn: 44.4164549\ttotal: 11.1s\tremaining: 273ms\n",
      "976:\tlearn: 44.4123660\ttotal: 11.1s\tremaining: 262ms\n",
      "977:\tlearn: 44.4075653\ttotal: 11.1s\tremaining: 250ms\n",
      "978:\tlearn: 44.3988586\ttotal: 11.1s\tremaining: 239ms\n",
      "979:\tlearn: 44.3963918\ttotal: 11.1s\tremaining: 228ms\n",
      "980:\tlearn: 44.3910565\ttotal: 11.2s\tremaining: 216ms\n",
      "981:\tlearn: 44.3888993\ttotal: 11.2s\tremaining: 205ms\n",
      "982:\tlearn: 44.3864230\ttotal: 11.2s\tremaining: 193ms\n",
      "983:\tlearn: 44.3843194\ttotal: 11.2s\tremaining: 182ms\n",
      "984:\tlearn: 44.3822195\ttotal: 11.2s\tremaining: 171ms\n",
      "985:\tlearn: 44.3795650\ttotal: 11.2s\tremaining: 159ms\n",
      "986:\tlearn: 44.3741274\ttotal: 11.2s\tremaining: 148ms\n",
      "987:\tlearn: 44.3694619\ttotal: 11.2s\tremaining: 137ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988:\tlearn: 44.3646340\ttotal: 11.3s\tremaining: 125ms\n",
      "989:\tlearn: 44.3613662\ttotal: 11.3s\tremaining: 114ms\n",
      "990:\tlearn: 44.3573057\ttotal: 11.3s\tremaining: 102ms\n",
      "991:\tlearn: 44.3490212\ttotal: 11.3s\tremaining: 91ms\n",
      "992:\tlearn: 44.3477710\ttotal: 11.3s\tremaining: 79.6ms\n",
      "993:\tlearn: 44.3461655\ttotal: 11.3s\tremaining: 68.3ms\n",
      "994:\tlearn: 44.3444485\ttotal: 11.3s\tremaining: 56.9ms\n",
      "995:\tlearn: 44.3395147\ttotal: 11.3s\tremaining: 45.5ms\n",
      "996:\tlearn: 44.3342195\ttotal: 11.3s\tremaining: 34.1ms\n",
      "997:\tlearn: 44.3294894\ttotal: 11.4s\tremaining: 22.8ms\n",
      "998:\tlearn: 44.3247225\ttotal: 11.4s\tremaining: 11.4ms\n",
      "999:\tlearn: 44.3182926\ttotal: 11.4s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Creating and fitting the CatBoostRegressor model\n",
    "catboost_model = CatBoostRegressor()\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = catboost_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8914152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 6.672727148997322\n",
      "Mean Squared Error (MSE): 2876.008047937266\n",
      "Root Mean Squared Error (RMSE): 53.628425745468846\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.490507381886914\n",
      "R-squared (R2 score): -0.0451112119991155\n",
      "Adjusted R-squared: -0.045241868321458156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    mask = (y_true > 0) & (y_pred > 0)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0:  # If all values are non-positive, handle this case\n",
    "        return 0  # Return a default value or handle it as needed\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "944d5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Creating and fitting the XGBoost Regressor model\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18884097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.583902464901764\n",
      "Mean Squared Error (MSE): 3537.627026675266\n",
      "Root Mean Squared Error (RMSE): 59.477954123147725\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.490507381886914\n",
      "R-squared (R2 score): -0.2855366215338426\n",
      "Adjusted R-squared: -0.28569733504000183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    mask = (y_true > 0) & (y_pred > 0)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0:  # If all values are non-positive, handle this case\n",
    "        return 0  # Return a default value or handle it as needed\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b565b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to sanitize feature names\n",
    "def sanitize_feature_names(feature_names):\n",
    "    sanitized_names = []\n",
    "    for name in feature_names:\n",
    "        # Replace non-alphanumeric characters with underscores\n",
    "        sanitized = re.sub(r'\\W+', '_', name)\n",
    "        # Ensure the name doesn't start with a number\n",
    "        if re.match(r'^\\d', sanitized):\n",
    "            sanitized = '_' + sanitized\n",
    "        sanitized_names.append(sanitized)\n",
    "    return sanitized_names\n",
    "\n",
    "# Sanitize feature names\n",
    "X_train.columns = sanitize_feature_names(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5cc7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2179\n",
      "[LightGBM] [Info] Number of data points in the train set: 210000, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 15.852305\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Creating and fitting the LGBM Regressor model\n",
    "lgbm_model = LGBMRegressor()\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = lgbm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc0dbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 6.990165794133198\n",
      "Mean Squared Error (MSE): 2917.1599871615995\n",
      "Root Mean Squared Error (RMSE): 54.01073955392204\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.47445235974788597\n",
      "R-squared (R2 score): -0.060065395840743996\n",
      "Adjusted R-squared: -0.06019792168533655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    mask = (y_true > 0) & (y_pred > 0)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    if len(y_true) == 0:  # If all values are non-positive, handle this case\n",
    "        return 0  # Return a default value or handle it as needed\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d525ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Set of Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28471c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial Regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Creating polynomial features\n",
    "poly_degree = 3  # Define the degree of the polynomial\n",
    "poly = PolynomialFeatures(degree=poly_degree)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Creating and fitting the Polynomial Regression model\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "y_pred = poly_model.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d332d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 8.832486569300418\n",
      "Mean Squared Error (MSE): 28214.08833702033\n",
      "Root Mean Squared Error (RMSE): 167.9704984127282\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.6121489749885518\n",
      "R-squared (R2 score): -9.252704292153155\n",
      "Adjusted R-squared: -9.253986051090864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4256\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed24fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_model = Ridge(alpha=1.0)  # You can adjust the alpha (regularization strength) as needed\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred = ridge_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd79f14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.385367541776701\n",
      "Mean Squared Error (MSE): 2713.8488996146802\n",
      "Root Mean Squared Error (RMSE): 52.09461488114371\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5551813772960797\n",
      "R-squared (R2 score): 0.013815724648962635\n",
      "Adjusted R-squared: 0.013692435175947426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4256\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83dd4d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principal Components Regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming X_train and X_test are your feature matrices, and y_train is the target variable\n",
    "\n",
    "# Step 1: Scale the data (recommended before applying PCA)\n",
    "# (You can use other scaling methods like StandardScaler or MinMaxScaler as needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 2: Perform PCA and then fit the model\n",
    "n_components = 10  # Number of components (you can change this number)\n",
    "pca = PCA(n_components=n_components)\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "# Create a pipeline to chain PCA and Linear Regression\n",
    "pipeline = make_pipeline(pca, linear_regression)\n",
    "\n",
    "# Fit the model using the pipeline\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict using the test data\n",
    "y_pred = pipeline.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5d2e7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 8.426113521421964\n",
      "Mean Squared Error (MSE): 2707.727131280174\n",
      "Root Mean Squared Error (RMSE): 52.035825459775054\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.6521126076695455\n",
      "R-squared (R2 score): 0.016040311165068655\n",
      "Adjusted R-squared: 0.01591729980244938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4256\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8d5ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Alpha (regularization strength) needs to be set. This is a hyperparameter that can be tuned.\n",
    "alpha = 0.1  # You can change the value of alpha as needed\n",
    "\n",
    "lasso_model = Lasso(alpha=alpha)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_pred = lasso_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c74a9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.399792651247587\n",
      "Mean Squared Error (MSE): 2718.42768674855\n",
      "Root Mean Squared Error (RMSE): 52.13854319741347\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5568195240599011\n",
      "R-squared (R2 score): 0.012151841345716452\n",
      "Adjusted R-squared: 0.012028343859553314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc665522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordinal Regression\n",
    "from mord import LogisticIT\n",
    "import pandas as pd\n",
    "\n",
    "num_classes = 10  # You can change this based on your data or required number of classes\n",
    "y_train_ordinal = pd.qcut(y_train, q=num_classes, labels=False)\n",
    "\n",
    "ordinal_model = LogisticIT()\n",
    "ordinal_model.fit(X_train, y_train_ordinal)\n",
    "y_pred = ordinal_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44947db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 11.664683333333333\n",
      "Mean Squared Error (MSE): 2855.47295\n",
      "Root Mean Squared Error (RMSE): 53.43662554840079\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 1.3323076577690345\n",
      "R-squared (R2 score): -0.03764897241702214\n",
      "Adjusted R-squared: -0.03777869583502991\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1064963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poisson Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming X_train and y_train are your training data\n",
    "poisson_model = sm.GLM(y_train, X_train, family=sm.families.Poisson())\n",
    "poisson_results = poisson_model.fit()\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = poisson_results.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1206c959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1.6442646048939778e+40\n",
      "Mean Squared Error (MSE): 3.244327309088579e+85\n",
      "Root Mean Squared Error (RMSE): 5.695899673527071e+42\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.6610646463096236\n",
      "R-squared (R2 score): -1.178954575094205e+82\n",
      "Adjusted R-squared: -1.1791019640679548e+82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "227aa54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative Binomial Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming X_train and y_train are your training features and target respectively\n",
    "\n",
    "# Fit the Negative Binomial Regression model\n",
    "nb_model = sm.GLM(y_train, X_train, family=sm.families.NegativeBinomial())\n",
    "nb_result = nb_model.fit()\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred = nb_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ec308c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1.6442646048939778e+40\n",
      "Mean Squared Error (MSE): 3.244327309088579e+85\n",
      "Root Mean Squared Error (RMSE): 5.695899673527071e+42\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.6610646463096236\n",
      "R-squared (R2 score): -1.178954575094205e+82\n",
      "Adjusted R-squared: -1.1791019640679548e+82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "075ea816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11540\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  trip_distance                  with p-value 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11540\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  passenger_count                with p-value 4.31624e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11540\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  dropoff_latitude               with p-value 7.85613e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11540\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  longitude_difference           with p-value 0.00192423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11540\\2891218742.py:15: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    }
   ],
   "source": [
    "#Stepwise regression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "# Assuming X_train and y_train are your training data\n",
    "selected_features = stepwise_selection(X_train, y_train)\n",
    "\n",
    "# After obtaining selected features, fit the model using sklearn LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train[selected_features], y_train)\n",
    "y_pred = lr_model.predict(X_test[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63903214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.398881793755651\n",
      "Mean Squared Error (MSE): 2718.215486272104\n",
      "Root Mean Squared Error (RMSE): 52.13650819025095\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5567265497304519\n",
      "R-squared (R2 score): 0.0122289527770576\n",
      "Adjusted R-squared: 0.012105464931108756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11540\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "223c9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regression \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create a DecisionTreeRegressor model\n",
    "dt_model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the model with training data\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "500e151e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 9.211533333333334\n",
      "Mean Squared Error (MSE): 14628.6503\n",
      "Root Mean Squared Error (RMSE): 120.94895741592815\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.528846799741553\n",
      "R-squared (R2 score): -4.315898352895608\n",
      "Adjusted R-squared: -4.31656292879984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6b5cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4fccf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.423382000000002\n",
      "Mean Squared Error (MSE): 3729.342195331667\n",
      "Root Mean Squared Error (RMSE): 61.06834036824373\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.5110228990118234\n",
      "R-squared (R2 score): -0.35520390651129974\n",
      "Adjusted R-squared: -0.3553733295893573\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4542806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Nearest Neighbors Regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Create a K-Nearest Neighbors Regression model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)  # You can set the number of neighbors (K) as needed\n",
    "\n",
    "# Fit the KNN model with the training data\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the KNN model\n",
    "y_pred = knn_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfaf35cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 11.387129999999999\n",
      "Mean Squared Error (MSE): 3175.184586\n",
      "Root Mean Squared Error (RMSE): 56.34877626000409\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.7804062247978638\n",
      "R-squared (R2 score): -0.15382883346776843\n",
      "Adjusted R-squared: -0.15397308130499665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eca0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Robust Regression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a RANSACRegressor model\n",
    "ransac_model = RANSACRegressor(base_estimator=LinearRegression(), random_state=0)\n",
    "\n",
    "# Fit the RANSAC model to the training data\n",
    "ransac_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = ransac_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c93764bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 6.831701106324882\n",
      "Mean Squared Error (MSE): 15299.536967902046\n",
      "Root Mean Squared Error (RMSE): 123.69129705804708\n",
      "Root Mean Squared Logarithmic Error (RMSLE): 0.48550542242178957\n",
      "R-squared (R2 score): 0.00559415286833409\n",
      "Adjusted R-squared: 0.0054076644743180635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16484\\4288965996.py:18: RuntimeWarning: invalid value encountered in log1p\n",
      "  return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared (R2 score)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y_pred) - np.log1p(y_true))))\n",
    "rmsle_val = rmsle(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of samples\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle_val)\n",
    "print(\"R-squared (R2 score):\", r2)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf5068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
